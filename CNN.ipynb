{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643b2392",
   "metadata": {},
   "source": [
    "# CNNの全体の構造\n",
    "CNNとは、畳み込みニューラルネットワーク（convolutionalneural network）の略で、画像認識や音声認識など至る所で使われている。CNNではこれまでのニューラルネットワークにさらに「Convolutionレイヤ（畳み込み層）」と「Polingレイヤ（プーリング層）」を組み合わせることで作成できる。\n",
    "<br>\n",
    "これまでのニューラルネットワークでは、隣接する層の全てのニューロン間で結合があった。これを**全結合(fully-connected)**と呼び、全結合層をAffineレイヤとして実装した。全結合のニューラルネットワークでは、Affineレイヤの後にReLUレイヤ（またはSigmoidレイヤ）を続けて組み合わせ、最後にSoftmaxレイヤで出力を行う。一方、CNNでは、この全結合ニューラルネットワークのAffine-ReLUという並びをConvolution-ReLU-Poolingという形に置き換える。（Poolingレイヤは省略される場合もある。）また、出力に近い層ではAffine-ReLUが使用され、出力層ではAffine-Softmaxの組み合わせが用いられることが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54bca10",
   "metadata": {},
   "source": [
    "# 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a792616",
   "metadata": {},
   "source": [
    "## 全結合層の問題点\n",
    "全結合層の問題点は、データの形状が無視されてしまうことである。例えば、入力データが画像の場合には、縦、横、チャンネル方向の3次元のデータが与えられている。しかし、全結合層に入力するときには、このデータを1次元のデータにして入力する必要がある。本来、この3次元というデータの形状は、それ自体が情報を持つことが多い。よって全結合層ではこの情報を生かし切れない。\n",
    "一方で、CNNではデータの形状を維持するため、画像などの形状を有するデータを正しく学習できる可能性がある。なお、CNNでは畳み込み層の入出力データを**特徴マップ（feature map）**と言う場合があり、畳み込み層の入力データを**入力特徴マップ（input feature map）**、出力データを**出力特徴マップ（output feature map）**と言う。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49058877",
   "metadata": {},
   "source": [
    "## 畳み込み演算\n",
    "畳み込み層では、「畳み込み演算」を行う。これは、画像処理で言う「フィルター演算」にあたる。この演算では、以下の画像のように、フィルターをずらしながら積和計算を行っていく。\n",
    "<img src='https://s3-ap-northeast-1.amazonaws.com/dragonarrow/uploads%2F1565688214362-ConvolutionCaluculationFlow.png'>\n",
    "CNNでは、このフィルターの値が重みパラメータとなる。また、バイアスは常に1×1の形状で存在しており。フィルター適用後の全ての要素に加算される。また、この図の奥行きがある場合を考えることで、3次元の畳み込み演算についても考えることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfa80b",
   "metadata": {},
   "source": [
    "## パディング\n",
    "畳み込み層の処理の前に、入力データの周囲に0などの固定のデータを埋めることがあり、それを**パディング**と言う。これは、出力サイズを調整するために用いられる。もし畳み込み演算を行う度にデータのサイズが縮小されてしまうと、ある時点でサイズが1になってしまい、それ以上演算をできなくなってしまう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0190e3",
   "metadata": {},
   "source": [
    "## ストライド\n",
    "フィルターを適用する位置の間隔を、**ストライド（stride）**という。入力サイズを$(H,W)$、フィルターサイズを$(FH,FW)$、出力サイズを$(OH,OW)$、パディングを$P$、ストライドを$S$とおくと、出力サイズは以下のように計算できる。<br>\n",
    "$\\displaystyle{\n",
    "OH = \\frac{H+2P-FH}{S}+1 \\\\\n",
    "OW = \\frac{W+2P-FH}{S}+1\n",
    "}$\n",
    "<br>\n",
    "注意すべき点としては、この式が割り切れるような値を設定しなければならないということである。フレームワークによっては、割り切れないときは最も近い整数に丸める処理を行ったりする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa116f",
   "metadata": {},
   "source": [
    "## バッチ処理\n",
    "畳み込み演算においても、バッチ処理を使用することができる。各層を流れるデータを(batch_num, channel, height, width)といった順番の4次元のデータとする。このとき、(N,C,H,W)といった形のN個の入力データは、(FN,C,FH,FW)といった形のフィルターを経て、(N,FN,OH,W)というデータになり、(FN,1,1)のバイアスを加算することで出力データとなる。このとき、N個のデータがまとめてバッチとして畳み込み演算されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25fcf58",
   "metadata": {},
   "source": [
    "# プーリング層\n",
    "プーリングは、縦・横方向の空間を小さくする演算。\n",
    "<img src='https://s3-ap-northeast-1.amazonaws.com/dragonarrow/uploads%2F1565693901156-pooling.png'>\n",
    "この画像は、2×2のMaxプーリングをストライド2で行っている例。Maxプーリングは、指定範囲内の最大値をとる演算で、ほかにも平均をとるAverageプーリングがある。画像認識の分野では主にMaxプーリングが使用される。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c2dc8",
   "metadata": {},
   "source": [
    "## プーリング層の特徴\n",
    "プーリング層の特徴として、以下の3つがある。\n",
    "1. 学習するパラメータがない\n",
    "1. チャンネル数は変化しない\n",
    "    - チャンネルごとに独立して計算が行われるため、チャンネル数は変化しない。\n",
    "1. 微小な位置変化に対してロバスト（頑健）\n",
    "    - 入力データの小さなズレに対して、プーリングはズレを吸収することが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a9491",
   "metadata": {},
   "source": [
    "# Convolution/Poolingレイヤの実装\n",
    "ここでは、以前に誤差逆伝播法を実装した際と同じように、```forward```と```backward```というメソッドを持たせ、モジュールの形で実装する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce2f11",
   "metadata": {},
   "source": [
    "## 4次元配列\n",
    "CNNでは、各層を4次元のデータが流れる。例えば、(10,1,28,28)という形状のデータは、高さ28、横幅28、1チャンネルで10個のデータを表す。pythonでは、以下のようにnumpy配列で4次元配列を定義することでこのような形のデータを作ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db7a92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8032f8",
   "metadata": {},
   "source": [
    "## im2colによる展開\n",
    "Numpyでは演算速度の観点から、for文は非推奨とされている。そのため、im2colという関数を使用する。im2colは、フィルターにとって都合のいいように入力データを展開する。具体的には、3次元（正確にはバッチ数を含めた4次元）の入力データを、2次元の行列へと展開する。展開した後は、フィルターも1列に展開して、2つの行列の積を計算して出力データのサイズに整形する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8554c",
   "metadata": {},
   "source": [
    "## Convolutionレイヤの実装\n",
    "ここで使用する```im2col```という関数は、以下のインタフェースを持つ。\n",
    "<br>\n",
    "<br>\n",
    "```im2col(input_data, filter_h, filter_w, stride=1, pad=0)```\n",
    "\n",
    "- ```input_data``` （データ数,チャンネル,高さ,横幅）の4次元配列からなる入力データ\n",
    "- ```filter_h``` フィルターの高さ\n",
    "- ```stride``` ストライド\n",
    "- ```pad``` パディング\n",
    "\n",
    "<br>\n",
    "この関数を使用して畳み込み層をConlvolutionという名前のクラスで実装したのが以下である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f446b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import im2col\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45bbafe",
   "metadata": {},
   "source": [
    "## Poolingレイヤの実装\n",
    "Poolingレイヤの実装に関しては、チャンネルごとに独立していることから、プーリングの適用領域をim2colで展開し、同様に行列計算に持ち込む。以下がPoolingレイヤの実装である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd998a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac45736",
   "metadata": {},
   "source": [
    "# CNNの実装\n",
    "2つのレイヤの実装が完了したため、実際に手書き文字認識を行うCNNをSimpleConvNetという名前のクラスで実装してみる。これは、以下の引数を取るものとする。<br>\n",
    "\n",
    "- input_dim ―― 入力データの (チャンネル, 高さ, 幅) の次元\n",
    "- conv_param ―― 畳み込み層のハイパーパラメータ(ディクショナリ)。ディクショナリのキーは下記のとおり\n",
    "    - filter_num ―― フィルターの数 \n",
    "\n",
    "    - filter_size ―― フィルターのサイズ\n",
    "\n",
    "    - stride ―― ストライド \n",
    "\n",
    "    - pad ―― パディング \n",
    "\n",
    "- hidden_size ―― 隠れ層(全結合)のニューロンの数\n",
    "- output_size ―― 出力層(全結合)のニューロンの数\n",
    "- weight_init_std ―― 初期化の際の重みの標準偏差\n",
    "\n",
    "<br>\n",
    "実装は下記。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a32a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"単純なConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "        引数のxは入力データ、tは教師ラベル\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c61b4",
   "metadata": {},
   "source": [
    "このCNNネットワークを用いてMNISTデータセットを学習したのが以下のコード。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e99032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2993041560423055\n",
      "=== epoch:1, train acc:0.161, test acc:0.176 ===\n",
      "train loss:2.297909009309171\n",
      "train loss:2.2949591099473405\n",
      "train loss:2.2887315801366004\n",
      "train loss:2.2796434606496403\n",
      "train loss:2.2704794309933307\n",
      "train loss:2.254400130940676\n",
      "train loss:2.2398239774232884\n",
      "train loss:2.215239001981079\n",
      "train loss:2.1949568027211908\n",
      "train loss:2.169835059230362\n",
      "train loss:2.1381118363928224\n",
      "train loss:2.1023176158151884\n",
      "train loss:2.0749559832132634\n",
      "train loss:1.9902079906496706\n",
      "train loss:1.9949707549804492\n",
      "train loss:1.8318747080182889\n",
      "train loss:1.8689428671616153\n",
      "train loss:1.8596137602909228\n",
      "train loss:1.7140818473921595\n",
      "train loss:1.6705747612233077\n",
      "train loss:1.5696225168744737\n",
      "train loss:1.502527169960635\n",
      "train loss:1.419303321458336\n",
      "train loss:1.3458605009056348\n",
      "train loss:1.1319073110816376\n",
      "train loss:1.2897557445324295\n",
      "train loss:1.078606653117976\n",
      "train loss:1.1292775184166643\n",
      "train loss:1.0992097599305082\n",
      "train loss:0.9557279827807175\n",
      "train loss:0.7697658810040011\n",
      "train loss:0.8906089026552095\n",
      "train loss:0.9410972084103689\n",
      "train loss:0.8422213718597749\n",
      "train loss:0.7621695252060594\n",
      "train loss:0.6930560955041106\n",
      "train loss:0.6666009765314805\n",
      "train loss:0.7795916530568586\n",
      "train loss:0.8264245953922245\n",
      "train loss:0.5541117011150961\n",
      "train loss:0.6744515994109698\n",
      "train loss:0.5865933423544258\n",
      "train loss:0.5820210353317022\n",
      "train loss:0.8726259567206821\n",
      "train loss:0.8189030885380568\n",
      "train loss:0.5858974395331615\n",
      "train loss:0.5648381959356923\n",
      "train loss:0.7283461849137766\n",
      "train loss:0.7092266070618883\n",
      "train loss:0.6113280705163668\n",
      "train loss:0.4346066162085116\n",
      "train loss:0.3589834616351269\n",
      "train loss:0.6668792930172434\n",
      "train loss:0.5339496651106527\n",
      "train loss:0.4855213129039766\n",
      "train loss:0.5414761562161321\n",
      "train loss:0.6506325564953164\n",
      "train loss:0.3629246713703981\n",
      "train loss:0.4847026050378869\n",
      "train loss:0.7161500500743394\n",
      "train loss:0.3572991758905922\n",
      "train loss:0.6797772183583137\n",
      "train loss:0.47625103043974826\n",
      "train loss:0.7234777068262218\n",
      "train loss:0.6876510515964334\n",
      "train loss:0.41461866582111995\n",
      "train loss:0.5494539950027907\n",
      "train loss:0.39916846287275853\n",
      "train loss:0.46036952869697423\n",
      "train loss:0.36543870450806126\n",
      "train loss:0.6566811896285443\n",
      "train loss:0.46411371613048014\n",
      "train loss:0.4866682082596544\n",
      "train loss:0.48740516220518243\n",
      "train loss:0.42811581261758136\n",
      "train loss:0.4785227691281829\n",
      "train loss:0.44195892803193926\n",
      "train loss:0.4008943527790011\n",
      "train loss:0.380252879863607\n",
      "train loss:0.46612385412529284\n",
      "train loss:0.6193710605708936\n",
      "train loss:0.27135979190669657\n",
      "train loss:0.347091829553833\n",
      "train loss:0.4745222481126527\n",
      "train loss:0.4046568309512708\n",
      "train loss:0.31127307914216634\n",
      "train loss:0.26342970951099515\n",
      "train loss:0.48508060970394695\n",
      "train loss:0.2524180487517802\n",
      "train loss:0.4041947030923991\n",
      "train loss:0.34518878078283954\n",
      "train loss:0.37529354567341877\n",
      "train loss:0.48885467080207706\n",
      "train loss:0.33593875666838324\n",
      "train loss:0.4666434228005689\n",
      "train loss:0.404068495296643\n",
      "train loss:0.39096722100372\n",
      "train loss:0.3376168276494225\n",
      "train loss:0.45056502892749495\n",
      "train loss:0.28288478097450165\n",
      "train loss:0.37855562866997367\n",
      "train loss:0.4975183611004796\n",
      "train loss:0.5070496334688928\n",
      "train loss:0.4851870692456392\n",
      "train loss:0.27273125112046925\n",
      "train loss:0.24859370774502046\n",
      "train loss:0.5518304803200177\n",
      "train loss:0.3424805495212584\n",
      "train loss:0.5155929838719474\n",
      "train loss:0.46868125889474754\n",
      "train loss:0.37618237640462854\n",
      "train loss:0.4321651250704467\n",
      "train loss:0.4173607338168314\n",
      "train loss:0.5379661460256119\n",
      "train loss:0.33937395034140183\n",
      "train loss:0.3053906103888215\n",
      "train loss:0.3475067238336066\n",
      "train loss:0.45372555218176314\n",
      "train loss:0.4735122718534383\n",
      "train loss:0.40190141308419003\n",
      "train loss:0.441316744529809\n",
      "train loss:0.47108157581834254\n",
      "train loss:0.32387762254400904\n",
      "train loss:0.513392340192096\n",
      "train loss:0.5681813684892338\n",
      "train loss:0.32418582785316447\n",
      "train loss:0.2978654288016091\n",
      "train loss:0.4241912677704299\n",
      "train loss:0.24950042210655268\n",
      "train loss:0.45259158427533797\n",
      "train loss:0.30245891148834114\n",
      "train loss:0.3150396663359758\n",
      "train loss:0.5038688464513458\n",
      "train loss:0.21964889098778728\n",
      "train loss:0.2585224156283326\n",
      "train loss:0.21267439514590908\n",
      "train loss:0.24982485304443128\n",
      "train loss:0.5013497604588615\n",
      "train loss:0.26764382413966\n",
      "train loss:0.4164924978904476\n",
      "train loss:0.4458191418245526\n",
      "train loss:0.28764149162095437\n",
      "train loss:0.3801768471792819\n",
      "train loss:0.26543955627613575\n",
      "train loss:0.2924166021523576\n",
      "train loss:0.363753860448489\n",
      "train loss:0.3831851196959207\n",
      "train loss:0.43429057812373756\n",
      "train loss:0.3969823196910833\n",
      "train loss:0.33020598570925425\n",
      "train loss:0.3999656624084673\n",
      "train loss:0.32356730439433506\n",
      "train loss:0.4224241261679975\n",
      "train loss:0.32221729001928845\n",
      "train loss:0.29209649945793287\n",
      "train loss:0.5547324780801756\n",
      "train loss:0.29819501879294896\n",
      "train loss:0.2962832365067128\n",
      "train loss:0.323724688154717\n",
      "train loss:0.30763166305254386\n",
      "train loss:0.5167743217205535\n",
      "train loss:0.4899946862777403\n",
      "train loss:0.2203199598103973\n",
      "train loss:0.5774006537637179\n",
      "train loss:0.4123929776035143\n",
      "train loss:0.5127637452008911\n",
      "train loss:0.22305821286157215\n",
      "train loss:0.3082884367644263\n",
      "train loss:0.27866732290947693\n",
      "train loss:0.3892813430403499\n",
      "train loss:0.4259235803555573\n",
      "train loss:0.30224164727505687\n",
      "train loss:0.3439833221024385\n",
      "train loss:0.4253380765585224\n",
      "train loss:0.40010056360780655\n",
      "train loss:0.4149417864900338\n",
      "train loss:0.2804820844366212\n",
      "train loss:0.3554527337270244\n",
      "train loss:0.27208251529701\n",
      "train loss:0.40251827399399026\n",
      "train loss:0.35453323502128775\n",
      "train loss:0.37502249135128546\n",
      "train loss:0.3422598509452991\n",
      "train loss:0.32249945887927595\n",
      "train loss:0.43985181615203284\n",
      "train loss:0.30280917284757175\n",
      "train loss:0.3545659582967315\n",
      "train loss:0.2893626132762028\n",
      "train loss:0.2509324852786894\n",
      "train loss:0.30604584253294914\n",
      "train loss:0.3516947931862881\n",
      "train loss:0.38380445784728295\n",
      "train loss:0.3721691070217421\n",
      "train loss:0.3293511441933473\n",
      "train loss:0.5019109604838267\n",
      "train loss:0.3329783150804709\n",
      "train loss:0.27831538761413366\n",
      "train loss:0.42925823128306606\n",
      "train loss:0.2419231730517072\n",
      "train loss:0.3256618718687044\n",
      "train loss:0.30405302939985834\n",
      "train loss:0.3277261149704281\n",
      "train loss:0.3039872416212253\n",
      "train loss:0.2789224757157268\n",
      "train loss:0.2902661702337108\n",
      "train loss:0.3506621470345342\n",
      "train loss:0.36966781543586313\n",
      "train loss:0.17160619407860042\n",
      "train loss:0.20132712646164808\n",
      "train loss:0.3030981581273662\n",
      "train loss:0.3515792289633033\n",
      "train loss:0.3940577567905278\n",
      "train loss:0.2691104133747901\n",
      "train loss:0.370896543903526\n",
      "train loss:0.3285659363510748\n",
      "train loss:0.3175984449424154\n",
      "train loss:0.32425725013481854\n",
      "train loss:0.34651623622851047\n",
      "train loss:0.1948731162982827\n",
      "train loss:0.17955384495012747\n",
      "train loss:0.21053666402467536\n",
      "train loss:0.3447178583411812\n",
      "train loss:0.3537685548498058\n",
      "train loss:0.19545544711463475\n",
      "train loss:0.3422229773691282\n",
      "train loss:0.3580523703780838\n",
      "train loss:0.3161034337097781\n",
      "train loss:0.17963599554555792\n",
      "train loss:0.2609450213501252\n",
      "train loss:0.4596488032513171\n",
      "train loss:0.2961942435372922\n",
      "train loss:0.2307359037442266\n",
      "train loss:0.31717497796428196\n",
      "train loss:0.2629356930890328\n",
      "train loss:0.25282635322911984\n",
      "train loss:0.28571735433107165\n",
      "train loss:0.31115546918956194\n",
      "train loss:0.2600273868864517\n",
      "train loss:0.21200883268998763\n",
      "train loss:0.28179377909487263\n",
      "train loss:0.34042498223594675\n",
      "train loss:0.19653558827448087\n",
      "train loss:0.22039161475450847\n",
      "train loss:0.4386509603509144\n",
      "train loss:0.2018759005923702\n",
      "train loss:0.3718001637437514\n",
      "train loss:0.23114472063571662\n",
      "train loss:0.3884636113464564\n",
      "train loss:0.23723367117075828\n",
      "train loss:0.4133409347048735\n",
      "train loss:0.26049727581180626\n",
      "train loss:0.17977150923283516\n",
      "train loss:0.3623879223539817\n",
      "train loss:0.3781948682674689\n",
      "train loss:0.25567674007445484\n",
      "train loss:0.29938804652844814\n",
      "train loss:0.2218922598244556\n",
      "train loss:0.41461642920442315\n",
      "train loss:0.18884817342892174\n",
      "train loss:0.2736462661260933\n",
      "train loss:0.15467915719704922\n",
      "train loss:0.19503799882558287\n",
      "train loss:0.24533196612285096\n",
      "train loss:0.15558308286108707\n",
      "train loss:0.2607580407992409\n",
      "train loss:0.35390047538199987\n",
      "train loss:0.2607743119190548\n",
      "train loss:0.3425177750325142\n",
      "train loss:0.15310369434348733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.28049385904828134\n",
      "train loss:0.20319388613662073\n",
      "train loss:0.18855575460011612\n",
      "train loss:0.3126087831136989\n",
      "train loss:0.2015827568911306\n",
      "train loss:0.25502807364327745\n",
      "train loss:0.16653425185598816\n",
      "train loss:0.18169107083228686\n",
      "train loss:0.22370475934372366\n",
      "train loss:0.19725778690616314\n",
      "train loss:0.22816265441472694\n",
      "train loss:0.26023040367127687\n",
      "train loss:0.23468586633600355\n",
      "train loss:0.2518394699035678\n",
      "train loss:0.3261952601742461\n",
      "train loss:0.32911142951724714\n",
      "train loss:0.1450668432761913\n",
      "train loss:0.2242813707487117\n",
      "train loss:0.30378228471944857\n",
      "train loss:0.25393645406955284\n",
      "train loss:0.18458275556994821\n",
      "train loss:0.3281167741374992\n",
      "train loss:0.43057948276973845\n",
      "train loss:0.3674064810058807\n",
      "train loss:0.1849062442707893\n",
      "train loss:0.3010198302453827\n",
      "train loss:0.35334438517480876\n",
      "train loss:0.2596776663819139\n",
      "train loss:0.19027172262290415\n",
      "train loss:0.14261108870274794\n",
      "train loss:0.22554735913664953\n",
      "train loss:0.18451418119810867\n",
      "train loss:0.26856730100906373\n",
      "train loss:0.2510602589204235\n",
      "train loss:0.4482715094604053\n",
      "train loss:0.30410504263065957\n",
      "train loss:0.12414691723199547\n",
      "train loss:0.17561496650711197\n",
      "train loss:0.2745370570471611\n",
      "train loss:0.45867477906772686\n",
      "train loss:0.21341412347411587\n",
      "train loss:0.37535711568748775\n",
      "train loss:0.1620830565195736\n",
      "train loss:0.3398982454200329\n",
      "train loss:0.18684387269452254\n",
      "train loss:0.278375650890926\n",
      "train loss:0.23937267376445873\n",
      "train loss:0.33729864962569167\n",
      "train loss:0.2928240219035237\n",
      "train loss:0.5607884573927585\n",
      "train loss:0.35678795878381936\n",
      "train loss:0.4670253055772438\n",
      "train loss:0.21304022938821635\n",
      "train loss:0.257898459427199\n",
      "train loss:0.15761821908629448\n",
      "train loss:0.33528480109581943\n",
      "train loss:0.24253125759292182\n",
      "train loss:0.1997128633153299\n",
      "train loss:0.19532405867992392\n",
      "train loss:0.22967499407613734\n",
      "train loss:0.16777009212049765\n",
      "train loss:0.16521584781852122\n",
      "train loss:0.1868570102116605\n",
      "train loss:0.2804469710564003\n",
      "train loss:0.3130857514260711\n",
      "train loss:0.1861760056862647\n",
      "train loss:0.25183375972332833\n",
      "train loss:0.269383392525119\n",
      "train loss:0.172136860253101\n",
      "train loss:0.22160087647429966\n",
      "train loss:0.13551892370457871\n",
      "train loss:0.17820763926827649\n",
      "train loss:0.18473234909641792\n",
      "train loss:0.20185318860968826\n",
      "train loss:0.12136456016521317\n",
      "train loss:0.21567995049847488\n",
      "train loss:0.267504598094905\n",
      "train loss:0.3935272269141726\n",
      "train loss:0.43569011429884197\n",
      "train loss:0.26675324642019727\n",
      "train loss:0.25581483183567466\n",
      "train loss:0.38778543481605693\n",
      "train loss:0.26950322239224156\n",
      "train loss:0.33971733348760047\n",
      "train loss:0.23856515915205798\n",
      "train loss:0.15397351504233714\n",
      "train loss:0.21971392200183135\n",
      "train loss:0.2563503798392279\n",
      "train loss:0.27569862233302084\n",
      "train loss:0.2876237979536783\n",
      "train loss:0.16931564374500901\n",
      "train loss:0.2366796391530247\n",
      "train loss:0.20396648281859486\n",
      "train loss:0.209734232192632\n",
      "train loss:0.21828463790280928\n",
      "train loss:0.2333980206577207\n",
      "train loss:0.2786269225589955\n",
      "train loss:0.2073204480220212\n",
      "train loss:0.2632670067205701\n",
      "train loss:0.315617403243573\n",
      "train loss:0.2184631729020708\n",
      "train loss:0.23974910269969452\n",
      "train loss:0.21829849446811644\n",
      "train loss:0.19948618986476638\n",
      "train loss:0.136878315520669\n",
      "train loss:0.1805427779885368\n",
      "train loss:0.2371871941093785\n",
      "train loss:0.19812188759646607\n",
      "train loss:0.13355947205060334\n",
      "train loss:0.22996604483538172\n",
      "train loss:0.14568296921653082\n",
      "train loss:0.3976860682344674\n",
      "train loss:0.17696245745329633\n",
      "train loss:0.2051167384149121\n",
      "train loss:0.13576389226300298\n",
      "train loss:0.20945738155753385\n",
      "train loss:0.2751168766066111\n",
      "train loss:0.12554414607637412\n",
      "train loss:0.21601305089861966\n",
      "train loss:0.3374311056960164\n",
      "train loss:0.3574143599454562\n",
      "train loss:0.17364234306978366\n",
      "train loss:0.3443407441534989\n",
      "train loss:0.20051552099007577\n",
      "train loss:0.16742886895724965\n",
      "train loss:0.14346474982273852\n",
      "train loss:0.17264318635209808\n",
      "train loss:0.21402248411081637\n",
      "train loss:0.2665897009127369\n",
      "train loss:0.19687952677527562\n",
      "train loss:0.528791203571284\n",
      "train loss:0.11375219507252783\n",
      "train loss:0.15781434473276262\n",
      "train loss:0.22283103686554728\n",
      "train loss:0.31817709843717223\n",
      "train loss:0.10564531076031351\n",
      "train loss:0.23341378309309882\n",
      "train loss:0.13983268548660058\n",
      "train loss:0.2394402809958517\n",
      "train loss:0.2432391479098502\n",
      "train loss:0.17516946700853872\n",
      "train loss:0.436084171241252\n",
      "train loss:0.14823122620473117\n",
      "train loss:0.2682020263693637\n",
      "train loss:0.22472176811804367\n",
      "train loss:0.25969322406747447\n",
      "train loss:0.24506060110955352\n",
      "train loss:0.1561096668277191\n",
      "train loss:0.19532725140429652\n",
      "train loss:0.28455270852700315\n",
      "train loss:0.21106539205452043\n",
      "train loss:0.15868979548916248\n",
      "train loss:0.19723693512252094\n",
      "train loss:0.21049326382475797\n",
      "train loss:0.2974672961218814\n",
      "train loss:0.17793110805942322\n",
      "train loss:0.26666938633963067\n",
      "train loss:0.3175101390297083\n",
      "train loss:0.12143299420667608\n",
      "train loss:0.14035967256738813\n",
      "train loss:0.18870971615034318\n",
      "train loss:0.22872949330889303\n",
      "train loss:0.21581340843159816\n",
      "train loss:0.16201366917454718\n",
      "train loss:0.15666320006682685\n",
      "train loss:0.23969922605003377\n",
      "train loss:0.1303282136384748\n",
      "train loss:0.24367844375079276\n",
      "train loss:0.2164275773751596\n",
      "train loss:0.24568659317708494\n",
      "train loss:0.3300535343759645\n",
      "train loss:0.35307866339403693\n",
      "train loss:0.1968963282578191\n",
      "train loss:0.14070735133960205\n",
      "train loss:0.2867200985059079\n",
      "train loss:0.19298061163583383\n",
      "train loss:0.2624491587060248\n",
      "train loss:0.18137859658153382\n",
      "train loss:0.14314744624725648\n",
      "train loss:0.19501843672350347\n",
      "train loss:0.11394465468901073\n",
      "train loss:0.1316355473704503\n",
      "train loss:0.18273524790534304\n",
      "train loss:0.21719849290690255\n",
      "train loss:0.21544549028094986\n",
      "train loss:0.17283914790115176\n",
      "train loss:0.15307899153481952\n",
      "train loss:0.2605024952019829\n",
      "train loss:0.2056066548129012\n",
      "train loss:0.15692731529296233\n",
      "train loss:0.1990426418748579\n",
      "train loss:0.13015315588713\n",
      "train loss:0.285897534820523\n",
      "train loss:0.29448068551789053\n",
      "train loss:0.1780733476609842\n",
      "train loss:0.1410553397762015\n",
      "train loss:0.23400786236548538\n",
      "train loss:0.29137208563183514\n",
      "train loss:0.1293076946058286\n",
      "train loss:0.1648315137037678\n",
      "train loss:0.11971242004929318\n",
      "train loss:0.18802378768946604\n",
      "train loss:0.204819124014589\n",
      "train loss:0.08553704371090175\n",
      "train loss:0.2041650052720782\n",
      "train loss:0.2235763501644541\n",
      "train loss:0.17489771929206108\n",
      "train loss:0.16545380265687717\n",
      "train loss:0.1216368692008833\n",
      "train loss:0.11280796852411248\n",
      "train loss:0.16238249674462957\n",
      "train loss:0.15315715397074345\n",
      "train loss:0.10929477836647788\n",
      "train loss:0.12298139814991664\n",
      "train loss:0.23231367058167776\n",
      "train loss:0.14663269166720522\n",
      "train loss:0.2354738902742309\n",
      "train loss:0.08296653886378622\n",
      "train loss:0.1634771046483421\n",
      "train loss:0.3285596572315754\n",
      "train loss:0.13918093583004543\n",
      "train loss:0.1899218898662551\n",
      "train loss:0.19786123785882448\n",
      "train loss:0.15913946671505907\n",
      "train loss:0.25167798184790824\n",
      "train loss:0.30258706574131905\n",
      "train loss:0.1918687333758508\n",
      "train loss:0.31618887084115266\n",
      "train loss:0.14785591972676465\n",
      "train loss:0.21651224403099087\n",
      "train loss:0.11710477370007151\n",
      "train loss:0.2645314225629875\n",
      "train loss:0.22147171642956187\n",
      "train loss:0.23585685182918287\n",
      "train loss:0.09362936454344684\n",
      "train loss:0.24605294142333936\n",
      "train loss:0.24617242067567102\n",
      "train loss:0.1273005059436188\n",
      "train loss:0.15578068993533928\n",
      "train loss:0.13690959447338902\n",
      "train loss:0.10497051853290315\n",
      "train loss:0.25276486799229925\n",
      "train loss:0.15999504895788375\n",
      "train loss:0.14700713134789734\n",
      "train loss:0.20708624411376422\n",
      "train loss:0.13996652812251908\n",
      "train loss:0.09767342572617911\n",
      "train loss:0.23247451492315643\n",
      "train loss:0.2500331817127935\n",
      "train loss:0.13411505870270615\n",
      "train loss:0.18528130150946254\n",
      "train loss:0.1992187458156322\n",
      "train loss:0.29297124240879113\n",
      "train loss:0.21776230957189557\n",
      "train loss:0.18921766421082534\n",
      "train loss:0.10582715018729719\n",
      "train loss:0.07347495790921736\n",
      "train loss:0.14492836634863213\n",
      "train loss:0.05868511168413737\n",
      "train loss:0.2202366246304056\n",
      "train loss:0.2333992653534551\n",
      "train loss:0.13177388493508685\n",
      "train loss:0.20612789051483527\n",
      "train loss:0.15464948537049494\n",
      "train loss:0.20525831125221242\n",
      "train loss:0.09591399187720359\n",
      "train loss:0.12000811395401983\n",
      "train loss:0.27902499324903046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1185735528873793\n",
      "train loss:0.19620187738042888\n",
      "train loss:0.11980145379812278\n",
      "train loss:0.09289199909299004\n",
      "train loss:0.3297404487367902\n",
      "train loss:0.09651721801068536\n",
      "train loss:0.14499856704260855\n",
      "train loss:0.19817660179820984\n",
      "train loss:0.21975132971476938\n",
      "train loss:0.11039950752550323\n",
      "train loss:0.1266275997296851\n",
      "train loss:0.14636962882696178\n",
      "train loss:0.14496877479326187\n",
      "train loss:0.1852088378323651\n",
      "train loss:0.13929001172803157\n",
      "train loss:0.13853990082549156\n",
      "train loss:0.15675599861018247\n",
      "train loss:0.1912110070010608\n",
      "train loss:0.29583660128872347\n",
      "train loss:0.130796184694573\n",
      "train loss:0.23921047689677333\n",
      "train loss:0.29498214369079506\n",
      "train loss:0.19500230759845205\n",
      "train loss:0.1649400958170583\n",
      "train loss:0.15926872105155565\n",
      "train loss:0.17285004080657282\n",
      "train loss:0.11366648177083777\n",
      "train loss:0.09792621893117642\n",
      "train loss:0.1994528175303309\n",
      "train loss:0.07286817805319283\n",
      "train loss:0.18275826209476023\n",
      "train loss:0.13322278306062985\n",
      "train loss:0.15353082658148398\n",
      "train loss:0.14944619302508128\n",
      "train loss:0.10772903369363035\n",
      "train loss:0.10924908217154149\n",
      "train loss:0.17706233500489574\n",
      "train loss:0.13211688598665527\n",
      "train loss:0.1223322556104681\n",
      "train loss:0.0840822428061051\n",
      "train loss:0.17180139960494056\n",
      "train loss:0.23553118087878688\n",
      "train loss:0.16664579423510356\n",
      "train loss:0.1177505025500505\n",
      "train loss:0.14789129847566257\n",
      "train loss:0.12287603399354459\n",
      "train loss:0.2845277157824289\n",
      "train loss:0.3419252209718763\n",
      "train loss:0.17678596442543015\n",
      "train loss:0.265929161845269\n",
      "train loss:0.08487060820885645\n",
      "train loss:0.048551784282168275\n",
      "train loss:0.18755998942344504\n",
      "train loss:0.06920824787076042\n",
      "train loss:0.124420051332811\n",
      "train loss:0.17379800116527544\n",
      "train loss:0.19729549857092554\n",
      "train loss:0.1074914510842948\n",
      "train loss:0.21688551460930797\n",
      "train loss:0.1337451296647607\n",
      "train loss:0.20421391538479636\n",
      "train loss:0.0569187155186101\n",
      "train loss:0.11609166009034931\n",
      "=== epoch:2, train acc:0.954, test acc:0.953 ===\n",
      "train loss:0.2407465287457289\n",
      "train loss:0.1784481132807678\n",
      "train loss:0.24186250964882636\n",
      "train loss:0.1183523309549569\n",
      "train loss:0.1516933329898218\n",
      "train loss:0.11235822441671825\n",
      "train loss:0.28435143520549233\n",
      "train loss:0.15250074955588255\n",
      "train loss:0.18048921089197378\n",
      "train loss:0.16099982182164785\n",
      "train loss:0.14643553981789045\n",
      "train loss:0.1498829193852444\n",
      "train loss:0.428299538525607\n",
      "train loss:0.3286882444028813\n",
      "train loss:0.15589996902476563\n",
      "train loss:0.3662815288982257\n",
      "train loss:0.1381744711697995\n",
      "train loss:0.1939316183395711\n",
      "train loss:0.1073710502714059\n",
      "train loss:0.20003778802951616\n",
      "train loss:0.2182028051254938\n",
      "train loss:0.13756833344095465\n",
      "train loss:0.1727951497748334\n",
      "train loss:0.16729646461506345\n",
      "train loss:0.08739468510635735\n",
      "train loss:0.09172411824835168\n",
      "train loss:0.10944528100059772\n",
      "train loss:0.06934642542512737\n",
      "train loss:0.1574858027700652\n",
      "train loss:0.05590251571308121\n",
      "train loss:0.16074719440522606\n",
      "train loss:0.2088875345442881\n",
      "train loss:0.1111004307804084\n",
      "train loss:0.14995706931342656\n",
      "train loss:0.11994628527668157\n",
      "train loss:0.10294692002346972\n",
      "train loss:0.20308401222976324\n",
      "train loss:0.12464320782918344\n",
      "train loss:0.10553219648292737\n",
      "train loss:0.11447281944378246\n",
      "train loss:0.11348117142951944\n",
      "train loss:0.12451276971763926\n",
      "train loss:0.1767981486141254\n",
      "train loss:0.12693702916794133\n",
      "train loss:0.07022804224210828\n",
      "train loss:0.11093388505694367\n",
      "train loss:0.16968077171611132\n",
      "train loss:0.16724936536507642\n",
      "train loss:0.17812887349163095\n",
      "train loss:0.1449323824738208\n",
      "train loss:0.11003534701195625\n",
      "train loss:0.07848387729989503\n",
      "train loss:0.10996132977669794\n",
      "train loss:0.20084623892929054\n",
      "train loss:0.08236540475066349\n",
      "train loss:0.113510875874027\n",
      "train loss:0.07331445436130073\n",
      "train loss:0.1225590472952391\n",
      "train loss:0.0761126191190183\n",
      "train loss:0.14107979680015917\n",
      "train loss:0.11809040020122465\n",
      "train loss:0.07329281970821436\n",
      "train loss:0.1187048326893786\n",
      "train loss:0.3302899841675764\n",
      "train loss:0.12448758263363474\n",
      "train loss:0.06457179126385994\n",
      "train loss:0.08878248119183367\n",
      "train loss:0.09888498733661613\n",
      "train loss:0.08559044469628184\n",
      "train loss:0.1447289972936818\n",
      "train loss:0.1471287762311224\n",
      "train loss:0.2345092528427401\n",
      "train loss:0.09797302333198309\n",
      "train loss:0.13590852317609284\n",
      "train loss:0.09562550838915841\n",
      "train loss:0.24792913957465867\n",
      "train loss:0.11396769758157514\n",
      "train loss:0.2683651070704565\n",
      "train loss:0.17776720176110306\n",
      "train loss:0.15407601317422737\n",
      "train loss:0.08568223970250168\n",
      "train loss:0.11575685227668032\n",
      "train loss:0.08916432143529318\n",
      "train loss:0.13733486535661638\n",
      "train loss:0.15109619082725106\n",
      "train loss:0.1203957484254887\n",
      "train loss:0.1074600173624923\n",
      "train loss:0.1006398879261966\n",
      "train loss:0.13855510179465555\n",
      "train loss:0.09801425628609209\n",
      "train loss:0.15395377442537272\n",
      "train loss:0.13453748074786237\n",
      "train loss:0.1103911049818815\n",
      "train loss:0.11194984918047667\n",
      "train loss:0.09092495315016225\n",
      "train loss:0.20621330408342387\n",
      "train loss:0.20296784845738666\n",
      "train loss:0.10005714667957431\n",
      "train loss:0.23131444701525491\n",
      "train loss:0.05963223918575081\n",
      "train loss:0.15081786600006772\n",
      "train loss:0.1027560855999909\n",
      "train loss:0.051882817384959735\n",
      "train loss:0.06649405055442811\n",
      "train loss:0.1337655649610664\n",
      "train loss:0.04457372390464692\n",
      "train loss:0.07090397943380461\n",
      "train loss:0.07470873591365403\n",
      "train loss:0.03887702827082945\n",
      "train loss:0.18922255798018595\n",
      "train loss:0.20450599655675436\n",
      "train loss:0.09728546163544095\n",
      "train loss:0.13686632343952515\n",
      "train loss:0.12725701042122448\n",
      "train loss:0.1497814980643236\n",
      "train loss:0.09226653777913536\n",
      "train loss:0.07639560798690702\n",
      "train loss:0.0736545110834532\n",
      "train loss:0.19015193272473915\n",
      "train loss:0.04388527767190219\n",
      "train loss:0.2551608757110393\n",
      "train loss:0.18548288467472418\n",
      "train loss:0.16386003937110286\n",
      "train loss:0.11690581456832082\n",
      "train loss:0.24140839750210227\n",
      "train loss:0.12084251820167932\n",
      "train loss:0.05044318128294718\n",
      "train loss:0.09387785827478387\n",
      "train loss:0.10900740983747628\n",
      "train loss:0.1669313555485655\n",
      "train loss:0.10085880784273439\n",
      "train loss:0.11936375812442471\n",
      "train loss:0.11556274642506788\n",
      "train loss:0.08658264608952901\n",
      "train loss:0.21582806749900812\n",
      "train loss:0.1310015357243674\n",
      "train loss:0.18062751978996158\n",
      "train loss:0.09573504920334025\n",
      "train loss:0.13639080286748798\n",
      "train loss:0.10397169715538254\n",
      "train loss:0.18351255098615918\n",
      "train loss:0.11230466395108867\n",
      "train loss:0.06422719898348439\n",
      "train loss:0.1336548381463419\n",
      "train loss:0.12743838737424285\n",
      "train loss:0.16086845231222174\n",
      "train loss:0.09610186681747164\n",
      "train loss:0.17599632300612394\n",
      "train loss:0.06239913207794068\n",
      "train loss:0.1312564290508157\n",
      "train loss:0.10869892657339922\n",
      "train loss:0.1240669835620706\n",
      "train loss:0.08070751713862741\n",
      "train loss:0.17538732253487044\n",
      "train loss:0.1623427098593495\n",
      "train loss:0.07946670852628232\n",
      "train loss:0.11056871117788056\n",
      "train loss:0.1413846141774011\n",
      "train loss:0.1327767140695182\n",
      "train loss:0.05509386849408616\n",
      "train loss:0.20989938461530638\n",
      "train loss:0.07700085884104886\n",
      "train loss:0.1340234664745007\n",
      "train loss:0.08391990037771371\n",
      "train loss:0.17778436493876174\n",
      "train loss:0.16744619830122642\n",
      "train loss:0.07699791075319343\n",
      "train loss:0.10931531779812681\n",
      "train loss:0.16663912065475445\n",
      "train loss:0.2138031635506685\n",
      "train loss:0.13371030448324833\n",
      "train loss:0.06710130281353922\n",
      "train loss:0.07015980741543087\n",
      "train loss:0.05740413194867278\n",
      "train loss:0.08759862813438879\n",
      "train loss:0.11932806518871632\n",
      "train loss:0.12237232799236601\n",
      "train loss:0.12250698229300813\n",
      "train loss:0.14815399999958875\n",
      "train loss:0.12266756624283576\n",
      "train loss:0.0957804201051177\n",
      "train loss:0.1796729250022371\n",
      "train loss:0.04365901193713846\n",
      "train loss:0.2463980514155618\n",
      "train loss:0.10973277167169743\n",
      "train loss:0.18683082133281878\n",
      "train loss:0.18042277271349172\n",
      "train loss:0.08961218204527661\n",
      "train loss:0.14086496064263848\n",
      "train loss:0.06208144361648715\n",
      "train loss:0.1362920746372324\n",
      "train loss:0.10738132492703541\n",
      "train loss:0.1636281219517921\n",
      "train loss:0.10532129470409207\n",
      "train loss:0.12051809394459312\n",
      "train loss:0.12820659158963582\n",
      "train loss:0.056170555003530256\n",
      "train loss:0.07919922021666802\n",
      "train loss:0.050458197137163\n",
      "train loss:0.06151631174906255\n",
      "train loss:0.07236673496972268\n",
      "train loss:0.0652402199708373\n",
      "train loss:0.07651679658807371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11256830703902622\n",
      "train loss:0.05543183913177554\n",
      "train loss:0.09898862716731242\n",
      "train loss:0.16418783316035315\n",
      "train loss:0.11295825595011989\n",
      "train loss:0.11813290959877946\n",
      "train loss:0.17907553264511958\n",
      "train loss:0.11731770024113632\n",
      "train loss:0.15221432898662599\n",
      "train loss:0.1582354903492018\n",
      "train loss:0.08145895892743345\n",
      "train loss:0.07822949345132373\n",
      "train loss:0.054079120055556915\n",
      "train loss:0.06782807997983617\n",
      "train loss:0.12538704820545332\n",
      "train loss:0.03231716406884286\n",
      "train loss:0.1468728723253658\n",
      "train loss:0.09071391992464138\n",
      "train loss:0.08923776128109777\n",
      "train loss:0.06404701034687492\n",
      "train loss:0.05708191819402328\n",
      "train loss:0.05975544161018798\n",
      "train loss:0.16326455028744735\n",
      "train loss:0.13754115744586193\n",
      "train loss:0.03471197492016099\n",
      "train loss:0.05189356994554514\n",
      "train loss:0.11258693934971348\n",
      "train loss:0.09925946670944416\n",
      "train loss:0.08874486141845633\n",
      "train loss:0.09578750094004454\n",
      "train loss:0.09034237215563777\n",
      "train loss:0.020774927751932862\n",
      "train loss:0.11017447235073648\n",
      "train loss:0.11091152569315543\n",
      "train loss:0.12395250218514148\n",
      "train loss:0.05104159014337297\n",
      "train loss:0.14545777188197428\n",
      "train loss:0.06205404018224505\n",
      "train loss:0.054272546230202744\n",
      "train loss:0.14177910076922562\n",
      "train loss:0.0472206696891843\n",
      "train loss:0.06650670125644056\n",
      "train loss:0.0462145658136289\n",
      "train loss:0.1251459565333402\n",
      "train loss:0.11040694820212632\n",
      "train loss:0.14835081725072558\n",
      "train loss:0.07141830189208365\n",
      "train loss:0.08646086688119223\n",
      "train loss:0.08370632619284861\n",
      "train loss:0.08491586980907957\n",
      "train loss:0.04933419952762755\n",
      "train loss:0.061645356668624036\n",
      "train loss:0.10483347810968079\n",
      "train loss:0.1340747747679636\n",
      "train loss:0.07017322482270635\n",
      "train loss:0.13921373328189857\n",
      "train loss:0.08445620143070734\n",
      "train loss:0.1549260969121576\n",
      "train loss:0.09359669384530893\n",
      "train loss:0.18142174399176866\n",
      "train loss:0.050932711126800374\n",
      "train loss:0.07804157907155694\n",
      "train loss:0.155751065889698\n",
      "train loss:0.07811943029545149\n",
      "train loss:0.1002322587552357\n",
      "train loss:0.16610078211169507\n",
      "train loss:0.1487997154974126\n",
      "train loss:0.08675683795750679\n",
      "train loss:0.04260082919090072\n",
      "train loss:0.1250363069051947\n",
      "train loss:0.16075734842089315\n",
      "train loss:0.16534441646800435\n",
      "train loss:0.05998735378279223\n",
      "train loss:0.15381070227708882\n",
      "train loss:0.14933460119935943\n",
      "train loss:0.07192934454332053\n",
      "train loss:0.07222567904078493\n",
      "train loss:0.08934705421288287\n",
      "train loss:0.04386271912196429\n",
      "train loss:0.11013952730450295\n",
      "train loss:0.07908566503247147\n",
      "train loss:0.05243750781882472\n",
      "train loss:0.04060297193897298\n",
      "train loss:0.07166940305514256\n",
      "train loss:0.10792012988422012\n",
      "train loss:0.09171381050682793\n",
      "train loss:0.09648973334392352\n",
      "train loss:0.12472098229948898\n",
      "train loss:0.10754501274753908\n",
      "train loss:0.1311335877610227\n",
      "train loss:0.06872876375798033\n",
      "train loss:0.1217956648963302\n",
      "train loss:0.10918850491706225\n",
      "train loss:0.11997221956222116\n",
      "train loss:0.11704160818963619\n",
      "train loss:0.1185653803901676\n",
      "train loss:0.07213554403077137\n",
      "train loss:0.0670130411265455\n",
      "train loss:0.07184986391562999\n",
      "train loss:0.06064147664334921\n",
      "train loss:0.0987411340279449\n",
      "train loss:0.11929199602068224\n",
      "train loss:0.03653810151303928\n",
      "train loss:0.11169773052910482\n",
      "train loss:0.07013768339787814\n",
      "train loss:0.13434243723158135\n",
      "train loss:0.1207316442617063\n",
      "train loss:0.06718149005135554\n",
      "train loss:0.1271659083374197\n",
      "train loss:0.08227163305181849\n",
      "train loss:0.07942269775958179\n",
      "train loss:0.15379748595695272\n",
      "train loss:0.16679154808844415\n",
      "train loss:0.14378752151038612\n",
      "train loss:0.1377952698594614\n",
      "train loss:0.0776774118783555\n",
      "train loss:0.05878176851869373\n",
      "train loss:0.05461676521484856\n",
      "train loss:0.03917519341402924\n",
      "train loss:0.16052742433074788\n",
      "train loss:0.10227476688612754\n",
      "train loss:0.13216633192836055\n",
      "train loss:0.03640270665933822\n",
      "train loss:0.1038227150674237\n",
      "train loss:0.07721200356914598\n",
      "train loss:0.09247706356673253\n",
      "train loss:0.14159666897624373\n",
      "train loss:0.14612617495623423\n",
      "train loss:0.06513685238739254\n",
      "train loss:0.052359528192642356\n",
      "train loss:0.0729750865728146\n",
      "train loss:0.06667783663929028\n",
      "train loss:0.12746726633602612\n",
      "train loss:0.09791249254713669\n",
      "train loss:0.07758890682628933\n",
      "train loss:0.09296439475897339\n",
      "train loss:0.06012558678156364\n",
      "train loss:0.06570441542683503\n",
      "train loss:0.11415142031962061\n",
      "train loss:0.13491983093740742\n",
      "train loss:0.035714556481154666\n",
      "train loss:0.07146824217870827\n",
      "train loss:0.09188274224158074\n",
      "train loss:0.11669172676430878\n",
      "train loss:0.05961567599678794\n",
      "train loss:0.10021969575629398\n",
      "train loss:0.08259139295122987\n",
      "train loss:0.04111238746265214\n",
      "train loss:0.08853722121916117\n",
      "train loss:0.14116296715933477\n",
      "train loss:0.16315351752381635\n",
      "train loss:0.08922341284804049\n",
      "train loss:0.03364917210295667\n",
      "train loss:0.153833580049326\n",
      "train loss:0.09003688051627369\n",
      "train loss:0.06903886061402767\n",
      "train loss:0.028164393050525455\n",
      "train loss:0.05898280288673856\n",
      "train loss:0.10853352505980426\n",
      "train loss:0.06318164156794429\n",
      "train loss:0.13075308392606913\n",
      "train loss:0.07509072205971118\n",
      "train loss:0.11402874135742755\n",
      "train loss:0.07926113094690918\n",
      "train loss:0.11498733054586968\n",
      "train loss:0.173562160287304\n",
      "train loss:0.036336802459543044\n",
      "train loss:0.054826904334751125\n",
      "train loss:0.047148312224164005\n",
      "train loss:0.09765439207722809\n",
      "train loss:0.04439460265050862\n",
      "train loss:0.0594169260820521\n",
      "train loss:0.1025485514790164\n",
      "train loss:0.1171753557990608\n",
      "train loss:0.07919135434593062\n",
      "train loss:0.045603469814898226\n",
      "train loss:0.06787862536727882\n",
      "train loss:0.10702473601481871\n",
      "train loss:0.1065733362680445\n",
      "train loss:0.11118261993080025\n",
      "train loss:0.11265057433048536\n",
      "train loss:0.1390652991647491\n",
      "train loss:0.13414184000482712\n",
      "train loss:0.07820067376995447\n",
      "train loss:0.04269122628426796\n",
      "train loss:0.15467808572211367\n",
      "train loss:0.09074977435456301\n",
      "train loss:0.06137025641411676\n",
      "train loss:0.2298420139417438\n",
      "train loss:0.05592482244117693\n",
      "train loss:0.10763531847540586\n",
      "train loss:0.13503898520096247\n",
      "train loss:0.14955162987070775\n",
      "train loss:0.08853133241137418\n",
      "train loss:0.09153220099231349\n",
      "train loss:0.08665603718823575\n",
      "train loss:0.06812435927907975\n",
      "train loss:0.06539030190014054\n",
      "train loss:0.14186608810183216\n",
      "train loss:0.058270142425204376\n",
      "train loss:0.0724834432665175\n",
      "train loss:0.09664950224281943\n",
      "train loss:0.06894912708487173\n",
      "train loss:0.14167799855384344\n",
      "train loss:0.14884101551432521\n",
      "train loss:0.11121923859718809\n",
      "train loss:0.05472344296840425\n",
      "train loss:0.0696193274640987\n",
      "train loss:0.07760365289248054\n",
      "train loss:0.12755908819205192\n",
      "train loss:0.028531198268724953\n",
      "train loss:0.0830242746848392\n",
      "train loss:0.0891050640583839\n",
      "train loss:0.09963050234898117\n",
      "train loss:0.12342849747121684\n",
      "train loss:0.03078325567680189\n",
      "train loss:0.1179948927464867\n",
      "train loss:0.05449603434617419\n",
      "train loss:0.10732363116376542\n",
      "train loss:0.05767003522164612\n",
      "train loss:0.09074592637820666\n",
      "train loss:0.13679715885637614\n",
      "train loss:0.07062580925634325\n",
      "train loss:0.15728474224520445\n",
      "train loss:0.05868723874762607\n",
      "train loss:0.10578119944288472\n",
      "train loss:0.1471323092079569\n",
      "train loss:0.04305333537300681\n",
      "train loss:0.159894394718128\n",
      "train loss:0.05866542320387869\n",
      "train loss:0.04430652384376723\n",
      "train loss:0.09525118889270556\n",
      "train loss:0.06429587065739628\n",
      "train loss:0.07596686699337903\n",
      "train loss:0.020640164779347443\n",
      "train loss:0.08893451142074875\n",
      "train loss:0.13725945818667706\n",
      "train loss:0.09610710783407321\n",
      "train loss:0.175128861068466\n",
      "train loss:0.09661548122998781\n",
      "train loss:0.05096716064548857\n",
      "train loss:0.040350336656374386\n",
      "train loss:0.06420272665818276\n",
      "train loss:0.051307065899610864\n",
      "train loss:0.11084672006536885\n",
      "train loss:0.08843827168314623\n",
      "train loss:0.09197892973717449\n",
      "train loss:0.043644586529162366\n",
      "train loss:0.13181634047506605\n",
      "train loss:0.18188694435144498\n",
      "train loss:0.13451722648439834\n",
      "train loss:0.08687588825917945\n",
      "train loss:0.06141731178588807\n",
      "train loss:0.059327168678158355\n",
      "train loss:0.0690529335639627\n",
      "train loss:0.14804502674731299\n",
      "train loss:0.08370947947260897\n",
      "train loss:0.020475579431773534\n",
      "train loss:0.07121945041326998\n",
      "train loss:0.08151900429966316\n",
      "train loss:0.042332231416346414\n",
      "train loss:0.04909292221211564\n",
      "train loss:0.08587888678472108\n",
      "train loss:0.04139318607256612\n",
      "train loss:0.04572037696072167\n",
      "train loss:0.08253218141222658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09918434262158782\n",
      "train loss:0.020821382318473663\n",
      "train loss:0.04849263756722185\n",
      "train loss:0.03928761115106956\n",
      "train loss:0.07854568834653644\n",
      "train loss:0.08169115682957169\n",
      "train loss:0.04267909635065403\n",
      "train loss:0.09377610898393098\n",
      "train loss:0.0666806477369286\n",
      "train loss:0.0849910749749128\n",
      "train loss:0.15833182027399817\n",
      "train loss:0.08031356058670953\n",
      "train loss:0.05219875675555052\n",
      "train loss:0.19087890353211823\n",
      "train loss:0.11309524043464812\n",
      "train loss:0.09300176050899314\n",
      "train loss:0.05675467960825186\n",
      "train loss:0.025017554750870762\n",
      "train loss:0.11694666350990275\n",
      "train loss:0.048619827993676576\n",
      "train loss:0.04451772046694358\n",
      "train loss:0.08667769523814652\n",
      "train loss:0.056749973948215605\n",
      "train loss:0.11063180922577448\n",
      "train loss:0.12429970258073574\n",
      "train loss:0.10378205664648607\n",
      "train loss:0.1072692479558852\n",
      "train loss:0.1770898825460898\n",
      "train loss:0.05234439548035968\n",
      "train loss:0.06770717626493004\n",
      "train loss:0.12207485305670263\n",
      "train loss:0.05162291299161134\n",
      "train loss:0.021123114284421252\n",
      "train loss:0.23631144500205956\n",
      "train loss:0.09438904247031386\n",
      "train loss:0.1333579548192246\n",
      "train loss:0.10867900731158635\n",
      "train loss:0.04785147169247437\n",
      "train loss:0.03264259610120367\n",
      "train loss:0.07891191897558021\n",
      "train loss:0.08234597788004047\n",
      "train loss:0.05360876629763554\n",
      "train loss:0.06837224890544075\n",
      "train loss:0.0986847974994461\n",
      "train loss:0.04357643525577322\n",
      "train loss:0.06524719301580062\n",
      "train loss:0.042733467990836216\n",
      "train loss:0.09338364554201681\n",
      "train loss:0.07902729404513721\n",
      "train loss:0.07013459658440521\n",
      "train loss:0.09581431842382558\n",
      "train loss:0.06597737956571686\n",
      "train loss:0.161677105693032\n",
      "train loss:0.03486849341159564\n",
      "train loss:0.10036932638843388\n",
      "train loss:0.07159591217546457\n",
      "train loss:0.03231221355212221\n",
      "train loss:0.1283471146724887\n",
      "train loss:0.04781281852478154\n",
      "train loss:0.05410691215302364\n",
      "train loss:0.08107210141342762\n",
      "train loss:0.06896947930763987\n",
      "train loss:0.04484509045890233\n",
      "train loss:0.044432772194317904\n",
      "train loss:0.08452013639229257\n",
      "train loss:0.037398658147224616\n",
      "train loss:0.07831156652625261\n",
      "train loss:0.11835552209195577\n",
      "train loss:0.055883806204000096\n",
      "train loss:0.10961662847221029\n",
      "train loss:0.030018238873347466\n",
      "train loss:0.0885362311752845\n",
      "train loss:0.07615138832012502\n",
      "train loss:0.12958663743792523\n",
      "train loss:0.10584846349251363\n",
      "train loss:0.06356955110102264\n",
      "train loss:0.12623476514814258\n",
      "train loss:0.03507472259102649\n",
      "train loss:0.11017830139609075\n",
      "train loss:0.06830859501326872\n",
      "train loss:0.09264613119033728\n",
      "train loss:0.07180351161112297\n",
      "train loss:0.0442011239404866\n",
      "train loss:0.08695499784732577\n",
      "train loss:0.07454446445238001\n",
      "train loss:0.03849202797133297\n",
      "train loss:0.043697144610688125\n",
      "train loss:0.02833132220307697\n",
      "train loss:0.07479346523487897\n",
      "train loss:0.08267544068295475\n",
      "train loss:0.015483031937578322\n",
      "train loss:0.08727796203183182\n",
      "train loss:0.1052621822155924\n",
      "train loss:0.06205546417861984\n",
      "train loss:0.06281787601319185\n",
      "train loss:0.11033060644660933\n",
      "train loss:0.09927013700731273\n",
      "train loss:0.24517979376704008\n",
      "train loss:0.06370131533730233\n",
      "train loss:0.052729490428927425\n",
      "train loss:0.12716991738383915\n",
      "train loss:0.04101837799435261\n",
      "train loss:0.09604168374531216\n",
      "train loss:0.024888802059492\n",
      "train loss:0.027379399934430566\n",
      "train loss:0.20103835323350605\n",
      "train loss:0.0648368753996234\n",
      "train loss:0.06027770079480595\n",
      "train loss:0.09743076593356563\n",
      "train loss:0.04299427093975373\n",
      "train loss:0.15303234385694353\n",
      "train loss:0.049348550550400064\n",
      "train loss:0.05530924278051938\n",
      "train loss:0.056865915877131246\n",
      "train loss:0.05293351883787801\n",
      "train loss:0.04612739743276948\n",
      "train loss:0.13180820834156542\n",
      "train loss:0.06813744059832721\n",
      "train loss:0.11170910091229773\n",
      "train loss:0.04728089744401134\n",
      "train loss:0.10571926041353388\n",
      "train loss:0.05367441629069369\n",
      "train loss:0.12209096295971283\n",
      "train loss:0.08184428178819765\n",
      "train loss:0.03200355304976119\n",
      "train loss:0.05556008208378434\n",
      "train loss:0.13081755160126296\n",
      "train loss:0.05867599195579528\n",
      "train loss:0.021753635361762183\n",
      "train loss:0.05260106051040186\n",
      "train loss:0.09869532851167548\n",
      "=== epoch:3, train acc:0.978, test acc:0.978 ===\n",
      "train loss:0.031037961650645766\n",
      "train loss:0.06496590147219973\n",
      "train loss:0.15217723879615877\n",
      "train loss:0.054859817773116666\n",
      "train loss:0.1748360307289465\n",
      "train loss:0.08914376892536525\n",
      "train loss:0.06075997563057629\n",
      "train loss:0.08568023716513826\n",
      "train loss:0.09736403642101286\n",
      "train loss:0.0947484071924145\n",
      "train loss:0.05707607597476963\n",
      "train loss:0.06419797648108118\n",
      "train loss:0.023923604248109714\n",
      "train loss:0.07646621425772718\n",
      "train loss:0.09860921990045961\n",
      "train loss:0.07245402039157596\n",
      "train loss:0.05776830777951477\n",
      "train loss:0.030573559370779504\n",
      "train loss:0.0651871341455861\n",
      "train loss:0.06057972321700593\n",
      "train loss:0.023713400258703828\n",
      "train loss:0.035292475718172844\n",
      "train loss:0.05295790558576014\n",
      "train loss:0.11284782420684798\n",
      "train loss:0.08682635101853663\n",
      "train loss:0.07561800357962233\n",
      "train loss:0.09143671931020021\n",
      "train loss:0.043488164690927505\n",
      "train loss:0.028257067671763714\n",
      "train loss:0.07358245936315541\n",
      "train loss:0.018928545400840907\n",
      "train loss:0.047257109361779764\n",
      "train loss:0.03629116348180071\n",
      "train loss:0.22551075825321243\n",
      "train loss:0.042488686656368735\n",
      "train loss:0.060127861274713146\n",
      "train loss:0.03787173379999019\n",
      "train loss:0.06995271981803412\n",
      "train loss:0.12179862444711226\n",
      "train loss:0.07571114247467282\n",
      "train loss:0.09564445462951833\n",
      "train loss:0.05869712086626028\n",
      "train loss:0.1321834985032259\n",
      "train loss:0.07301237100141494\n",
      "train loss:0.04288489854279285\n",
      "train loss:0.09570576698771184\n",
      "train loss:0.053137336745439176\n",
      "train loss:0.043909459335727555\n",
      "train loss:0.07027863558788985\n",
      "train loss:0.10214203593848686\n",
      "train loss:0.03264935230360337\n",
      "train loss:0.09094560554088599\n",
      "train loss:0.11221590790480443\n",
      "train loss:0.05042315618842664\n",
      "train loss:0.06834493541992481\n",
      "train loss:0.15610949944115668\n",
      "train loss:0.06215512574893924\n",
      "train loss:0.0616054300254698\n",
      "train loss:0.10926008237943391\n",
      "train loss:0.020157286049020947\n",
      "train loss:0.07916536909961389\n",
      "train loss:0.03938890940376299\n",
      "train loss:0.06787636729381083\n",
      "train loss:0.06459755919608885\n",
      "train loss:0.03150628356713559\n",
      "train loss:0.06658688449386402\n",
      "train loss:0.03982381246960601\n",
      "train loss:0.09437949347256362\n",
      "train loss:0.050533222123128115\n",
      "train loss:0.02264580724008052\n",
      "train loss:0.043517416633722605\n",
      "train loss:0.06879118187302481\n",
      "train loss:0.14934718858537135\n",
      "train loss:0.035600621520547264\n",
      "train loss:0.018352861498477285\n",
      "train loss:0.06535925106261627\n",
      "train loss:0.06299269809194581\n",
      "train loss:0.1305118683181002\n",
      "train loss:0.07521033783050174\n",
      "train loss:0.08704285156879077\n",
      "train loss:0.06444080284220177\n",
      "train loss:0.14251372368771242\n",
      "train loss:0.035920130000945204\n",
      "train loss:0.07052612963186701\n",
      "train loss:0.06891343104941368\n",
      "train loss:0.09386482062339514\n",
      "train loss:0.06821131256688083\n",
      "train loss:0.022572135108931714\n",
      "train loss:0.04220494286492358\n",
      "train loss:0.10033045709763154\n",
      "train loss:0.05304870909705246\n",
      "train loss:0.06772304887877714\n",
      "train loss:0.03675242846715812\n",
      "train loss:0.1108375808286126\n",
      "train loss:0.061897574142291474\n",
      "train loss:0.05412170407399855\n",
      "train loss:0.06643510168348656\n",
      "train loss:0.0937219661520559\n",
      "train loss:0.04855032819048812\n",
      "train loss:0.08577986310753824\n",
      "train loss:0.0729755391333558\n",
      "train loss:0.029389667865504024\n",
      "train loss:0.07545080671628007\n",
      "train loss:0.12228374763885039\n",
      "train loss:0.0529968347951515\n",
      "train loss:0.07877430997156612\n",
      "train loss:0.09525781946788775\n",
      "train loss:0.10273732426692711\n",
      "train loss:0.08933727058103036\n",
      "train loss:0.04237760206963594\n",
      "train loss:0.03876615106059542\n",
      "train loss:0.10986229916106216\n",
      "train loss:0.1027959398450781\n",
      "train loss:0.04974249067523677\n",
      "train loss:0.055433907909923044\n",
      "train loss:0.08679152057841756\n",
      "train loss:0.06516228334799704\n",
      "train loss:0.05455431737382302\n",
      "train loss:0.06959023285234084\n",
      "train loss:0.06886773845144761\n",
      "train loss:0.03416430087694197\n",
      "train loss:0.07372230158224417\n",
      "train loss:0.05002106360883843\n",
      "train loss:0.04296667679033704\n",
      "train loss:0.09703900147526748\n",
      "train loss:0.055589474524777555\n",
      "train loss:0.10352579033165182\n",
      "train loss:0.04881331212890444\n",
      "train loss:0.07015107690946852\n",
      "train loss:0.055504419868183594\n",
      "train loss:0.09221883870182802\n",
      "train loss:0.23237375299947768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12388629018728915\n",
      "train loss:0.04769396917603937\n",
      "train loss:0.09059190632973257\n",
      "train loss:0.06088484960250242\n",
      "train loss:0.014898938881111094\n",
      "train loss:0.08450227984186542\n",
      "train loss:0.07374140602367187\n",
      "train loss:0.029154169098124957\n",
      "train loss:0.06680709264992109\n",
      "train loss:0.02977103443035916\n",
      "train loss:0.04564433486568619\n",
      "train loss:0.07442249529624516\n",
      "train loss:0.05602756536709983\n",
      "train loss:0.05167848229162348\n",
      "train loss:0.062030454670415625\n",
      "train loss:0.06468301617133049\n",
      "train loss:0.1360497515565252\n",
      "train loss:0.05201305060352188\n",
      "train loss:0.03886023715887319\n",
      "train loss:0.06553169628744007\n",
      "train loss:0.20007142940811193\n",
      "train loss:0.06686161661000989\n",
      "train loss:0.024106874042089648\n",
      "train loss:0.04547863531633872\n",
      "train loss:0.011592424546612105\n",
      "train loss:0.030526307219647685\n",
      "train loss:0.032836248122632014\n",
      "train loss:0.11078551549200145\n",
      "train loss:0.04406689310396142\n",
      "train loss:0.10284791738579296\n",
      "train loss:0.05428841747648669\n",
      "train loss:0.07877770023470218\n",
      "train loss:0.04199888055438898\n",
      "train loss:0.0469672641480256\n",
      "train loss:0.03952588315828237\n",
      "train loss:0.11065753803419205\n",
      "train loss:0.13888002782337974\n",
      "train loss:0.03149341729237341\n",
      "train loss:0.026206104570402323\n",
      "train loss:0.09556220159066406\n",
      "train loss:0.015679013949814843\n",
      "train loss:0.03819002124475307\n",
      "train loss:0.038893352196716406\n",
      "train loss:0.03485478394829532\n",
      "train loss:0.13257812797842358\n",
      "train loss:0.01806751470172423\n",
      "train loss:0.03565086913340916\n",
      "train loss:0.0385078348326791\n",
      "train loss:0.026271673398402497\n",
      "train loss:0.121593969400973\n",
      "train loss:0.03641265690782742\n",
      "train loss:0.038559849589651606\n",
      "train loss:0.06018817701088319\n",
      "train loss:0.05279273067959618\n",
      "train loss:0.022014936218056978\n",
      "train loss:0.05444937431814881\n",
      "train loss:0.04754161630420397\n",
      "train loss:0.13725681083971475\n",
      "train loss:0.0321018738039969\n",
      "train loss:0.0484183203248589\n",
      "train loss:0.02954804281072769\n",
      "train loss:0.053238998026397415\n",
      "train loss:0.06783382388687328\n",
      "train loss:0.06333517520306352\n",
      "train loss:0.031602778768267885\n",
      "train loss:0.018685157270708182\n",
      "train loss:0.020107245623640926\n",
      "train loss:0.1725106791187972\n",
      "train loss:0.02968175111950492\n",
      "train loss:0.05362169959407344\n",
      "train loss:0.029033591647685507\n",
      "train loss:0.03087957012379347\n",
      "train loss:0.039281038087616627\n",
      "train loss:0.09767250792894265\n",
      "train loss:0.02989511368607603\n",
      "train loss:0.04098056333379494\n",
      "train loss:0.10360042347609666\n",
      "train loss:0.024614187040352634\n",
      "train loss:0.017333879481448673\n",
      "train loss:0.025610192982618258\n",
      "train loss:0.029444660159411145\n",
      "train loss:0.11510315031753686\n",
      "train loss:0.05996233674906315\n",
      "train loss:0.03671193223179695\n",
      "train loss:0.19866956259449317\n",
      "train loss:0.11123596920403798\n",
      "train loss:0.02807430839432151\n",
      "train loss:0.10096978898320401\n",
      "train loss:0.030763904885230883\n",
      "train loss:0.02275979178066824\n",
      "train loss:0.09201817776502173\n",
      "train loss:0.12551695446810598\n",
      "train loss:0.042892986922345104\n",
      "train loss:0.02661407739298531\n",
      "train loss:0.03265743319825418\n",
      "train loss:0.06088956838706304\n",
      "train loss:0.04454179409099347\n",
      "train loss:0.06919985709020969\n",
      "train loss:0.03008516107982076\n",
      "train loss:0.10595658258472071\n",
      "train loss:0.07579774125739636\n",
      "train loss:0.03510053941519007\n",
      "train loss:0.04321364523287282\n",
      "train loss:0.07150529272371631\n",
      "train loss:0.07013072692411723\n",
      "train loss:0.029763486265824778\n",
      "train loss:0.09456099919341839\n",
      "train loss:0.08485908376405604\n",
      "train loss:0.03439368152960991\n",
      "train loss:0.047885679309965484\n",
      "train loss:0.028381749992833397\n",
      "train loss:0.051520206848028945\n",
      "train loss:0.0224603726770965\n",
      "train loss:0.09186596451928701\n",
      "train loss:0.12843162212861162\n",
      "train loss:0.044122973089693394\n",
      "train loss:0.05121064654867763\n",
      "train loss:0.06916853569945663\n",
      "train loss:0.09452115924357382\n",
      "train loss:0.20337611763108965\n",
      "train loss:0.09500617324960775\n",
      "train loss:0.04257818315953025\n",
      "train loss:0.02995448151797124\n",
      "train loss:0.09433427852273595\n",
      "train loss:0.09667292496063029\n",
      "train loss:0.06768522293327224\n",
      "train loss:0.02693486080520959\n",
      "train loss:0.11289268777947198\n",
      "train loss:0.04922172721414595\n",
      "train loss:0.1573149404372187\n",
      "train loss:0.09868507255368852\n",
      "train loss:0.05782566360769334\n",
      "train loss:0.057460703117736045\n",
      "train loss:0.047732597527719155\n",
      "train loss:0.09426094486614199\n",
      "train loss:0.07012697091676162\n",
      "train loss:0.0700780427319254\n",
      "train loss:0.07459965680886263\n",
      "train loss:0.03184228708016153\n",
      "train loss:0.012966757928402427\n",
      "train loss:0.06736982920957107\n",
      "train loss:0.02519624454808389\n",
      "train loss:0.032725139771387426\n",
      "train loss:0.044744385575001135\n",
      "train loss:0.08162029045576209\n",
      "train loss:0.016748913560820623\n",
      "train loss:0.10577707337571685\n",
      "train loss:0.02697561311724028\n",
      "train loss:0.024845630453035263\n",
      "train loss:0.04149886802276499\n",
      "train loss:0.0756799664936537\n",
      "train loss:0.022167900529645346\n",
      "train loss:0.08539654965243032\n",
      "train loss:0.04992770652767011\n",
      "train loss:0.05080315819174701\n",
      "train loss:0.02270581976055666\n",
      "train loss:0.0060746764439145754\n",
      "train loss:0.06901155517221334\n",
      "train loss:0.06685279667214054\n",
      "train loss:0.02597417962723165\n",
      "train loss:0.0442063349898142\n",
      "train loss:0.13319361141048602\n",
      "train loss:0.1217889978214523\n",
      "train loss:0.046241524238292614\n",
      "train loss:0.08133833229144603\n",
      "train loss:0.14216205197453194\n",
      "train loss:0.05186658212420351\n",
      "train loss:0.06918512422463655\n",
      "train loss:0.023955168798724173\n",
      "train loss:0.04918406586334252\n",
      "train loss:0.02041021409967665\n",
      "train loss:0.03137205980577152\n",
      "train loss:0.09445280040481346\n",
      "train loss:0.0353195359269051\n",
      "train loss:0.05382284652402518\n",
      "train loss:0.07983675409590242\n",
      "train loss:0.04054240788291482\n",
      "train loss:0.04795006004150528\n",
      "train loss:0.10750573796287438\n",
      "train loss:0.05670835443016288\n",
      "train loss:0.06888486419826938\n",
      "train loss:0.12427507257847535\n",
      "train loss:0.023798834502698887\n",
      "train loss:0.11275944551270879\n",
      "train loss:0.08469676400828563\n",
      "train loss:0.03287421674035804\n",
      "train loss:0.030599168965772434\n",
      "train loss:0.034565777982514624\n",
      "train loss:0.02942088448828673\n",
      "train loss:0.07014972139969636\n",
      "train loss:0.023292658284533516\n",
      "train loss:0.01989661261616418\n",
      "train loss:0.04722122187173231\n",
      "train loss:0.01595295150824587\n",
      "train loss:0.04224041190928572\n",
      "train loss:0.06228018604861359\n",
      "train loss:0.03611382635488566\n",
      "train loss:0.05230653314416877\n",
      "train loss:0.01749756413765522\n",
      "train loss:0.036663227462880796\n",
      "train loss:0.06108293427238361\n",
      "train loss:0.0897678177220482\n",
      "train loss:0.03295781515854363\n",
      "train loss:0.1256357605701492\n",
      "train loss:0.04796532031628896\n",
      "train loss:0.04198449989432274\n",
      "train loss:0.05357851938591259\n",
      "train loss:0.07679191344754777\n",
      "train loss:0.1447438625303274\n",
      "train loss:0.09119246741547354\n",
      "train loss:0.05303155740816602\n",
      "train loss:0.05795808184026947\n",
      "train loss:0.09428539610221368\n",
      "train loss:0.024024989542223353\n",
      "train loss:0.05738269930707746\n",
      "train loss:0.03299955056259661\n",
      "train loss:0.03629709027774287\n",
      "train loss:0.04278386783315754\n",
      "train loss:0.050833803391821746\n",
      "train loss:0.03647375581998864\n",
      "train loss:0.03681936334040488\n",
      "train loss:0.008459093675824975\n",
      "train loss:0.021175143993166716\n",
      "train loss:0.06405562375751245\n",
      "train loss:0.05580661198782869\n",
      "train loss:0.033676952089426615\n",
      "train loss:0.03812111519091752\n",
      "train loss:0.10516612249007273\n",
      "train loss:0.035211545530963374\n",
      "train loss:0.01536937445620389\n",
      "train loss:0.08641085661627143\n",
      "train loss:0.05811477177495527\n",
      "train loss:0.0195013180138307\n",
      "train loss:0.027313047910923025\n",
      "train loss:0.11298213229236378\n",
      "train loss:0.08717418710181125\n",
      "train loss:0.03163477725985598\n",
      "train loss:0.028222409208402174\n",
      "train loss:0.051122157642984785\n",
      "train loss:0.03841754222550055\n",
      "train loss:0.049987669487183674\n",
      "train loss:0.010300378260800536\n",
      "train loss:0.06423601552482994\n",
      "train loss:0.071507197117285\n",
      "train loss:0.08309862583330548\n",
      "train loss:0.056453443190510814\n",
      "train loss:0.05570884768332517\n",
      "train loss:0.04006068427047488\n",
      "train loss:0.03867947967917136\n",
      "train loss:0.024841094811509902\n",
      "train loss:0.033269007000821464\n",
      "train loss:0.04975263171926853\n",
      "train loss:0.06591257375149852\n",
      "train loss:0.0820166556038771\n",
      "train loss:0.03267553936382684\n",
      "train loss:0.0810560161253252\n",
      "train loss:0.013797297408301174\n",
      "train loss:0.02237595702541974\n",
      "train loss:0.03312865700370542\n",
      "train loss:0.026507088093752875\n",
      "train loss:0.08301202055509244\n",
      "train loss:0.06104049579534051\n",
      "train loss:0.043981654254783564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1357984097301195\n",
      "train loss:0.07063124381688231\n",
      "train loss:0.05400285329644814\n",
      "train loss:0.07636459828212822\n",
      "train loss:0.061527824444361424\n",
      "train loss:0.032532226112124\n",
      "train loss:0.05120381695979349\n",
      "train loss:0.06409641569790997\n",
      "train loss:0.24029479376026125\n",
      "train loss:0.023537200978528926\n",
      "train loss:0.00999033878894101\n",
      "train loss:0.04449964105507708\n",
      "train loss:0.03310508049324294\n",
      "train loss:0.06512568061082187\n",
      "train loss:0.0561573148013712\n",
      "train loss:0.08443428160153968\n",
      "train loss:0.10734376614384492\n",
      "train loss:0.03750661787691026\n",
      "train loss:0.03585029254035079\n",
      "train loss:0.02654098504758361\n",
      "train loss:0.020494911684684362\n",
      "train loss:0.057254522580931805\n",
      "train loss:0.04879734957056879\n",
      "train loss:0.1078048913785279\n",
      "train loss:0.04183058769025064\n",
      "train loss:0.030345158917952718\n",
      "train loss:0.055981813510696234\n",
      "train loss:0.10307344193213348\n",
      "train loss:0.03400133093495653\n",
      "train loss:0.06375432024878633\n",
      "train loss:0.035934338822243846\n",
      "train loss:0.04151433453964306\n",
      "train loss:0.033210035019568714\n",
      "train loss:0.04060674912130975\n",
      "train loss:0.06353082523295894\n",
      "train loss:0.05139215685834807\n",
      "train loss:0.09400397872962733\n",
      "train loss:0.029635290873553644\n",
      "train loss:0.08434307460512427\n",
      "train loss:0.07816107193453953\n",
      "train loss:0.05343272865921514\n",
      "train loss:0.09251772680167834\n",
      "train loss:0.034467546160302454\n",
      "train loss:0.05899476013861512\n",
      "train loss:0.01827650116887546\n",
      "train loss:0.038949563831544846\n",
      "train loss:0.04577154669116757\n",
      "train loss:0.021886023140613598\n",
      "train loss:0.06102734118902552\n",
      "train loss:0.05523760818197004\n",
      "train loss:0.011303474617679226\n",
      "train loss:0.0342102547899987\n",
      "train loss:0.029468741804739507\n",
      "train loss:0.04992293231104241\n",
      "train loss:0.07278884371016747\n",
      "train loss:0.05420694199392621\n",
      "train loss:0.057646787960589495\n",
      "train loss:0.01298071979950734\n",
      "train loss:0.08907361599841795\n",
      "train loss:0.017598617702368296\n",
      "train loss:0.08301881473035114\n",
      "train loss:0.02748012571850955\n",
      "train loss:0.02453769948329841\n",
      "train loss:0.05741987294761519\n",
      "train loss:0.04124871172144423\n",
      "train loss:0.08463224175536364\n",
      "train loss:0.11832940902522009\n",
      "train loss:0.030722021666239538\n",
      "train loss:0.02676104347360432\n",
      "train loss:0.03611405619426158\n",
      "train loss:0.034587695831129875\n",
      "train loss:0.0821129979869016\n",
      "train loss:0.03247628041485642\n",
      "train loss:0.11307074759025035\n",
      "train loss:0.08133464127078606\n",
      "train loss:0.026321503032501806\n",
      "train loss:0.043238466163908945\n",
      "train loss:0.04427308799955288\n",
      "train loss:0.08826787312852731\n",
      "train loss:0.05179619264564308\n",
      "train loss:0.06948059106829907\n",
      "train loss:0.07845799735166108\n",
      "train loss:0.044485496943689196\n",
      "train loss:0.08951508418251915\n",
      "train loss:0.0817371086006255\n",
      "train loss:0.07672200432438622\n",
      "train loss:0.012796897383933699\n",
      "train loss:0.021040480334934313\n",
      "train loss:0.06743772068165957\n",
      "train loss:0.0414343226551249\n",
      "train loss:0.022769543833638366\n",
      "train loss:0.02983744054840417\n",
      "train loss:0.20263954692756048\n",
      "train loss:0.05280663912341898\n",
      "train loss:0.07695397935390486\n",
      "train loss:0.04278337665561211\n",
      "train loss:0.07914954983197486\n",
      "train loss:0.060950916037294106\n",
      "train loss:0.04150747762760273\n",
      "train loss:0.020478590609218278\n",
      "train loss:0.09917948609847466\n",
      "train loss:0.02480917360748696\n",
      "train loss:0.0416751608528979\n",
      "train loss:0.017198401630559013\n",
      "train loss:0.026099649071542604\n",
      "train loss:0.10346484411252717\n",
      "train loss:0.12496289748250805\n",
      "train loss:0.0649635709717984\n",
      "train loss:0.028563041419684958\n",
      "train loss:0.02500739181067012\n",
      "train loss:0.03224511859351581\n",
      "train loss:0.03574747158828\n",
      "train loss:0.03699252921764193\n",
      "train loss:0.02272761657993722\n",
      "train loss:0.03790642285373556\n",
      "train loss:0.012239638349829725\n",
      "train loss:0.06342564794012344\n",
      "train loss:0.0848006842246101\n",
      "train loss:0.028464584630220887\n",
      "train loss:0.0612385653842057\n",
      "train loss:0.03445239764041102\n",
      "train loss:0.017935516198629823\n",
      "train loss:0.036179603648117925\n",
      "train loss:0.03924455694061907\n",
      "train loss:0.048922524778630135\n",
      "train loss:0.025056385394805144\n",
      "train loss:0.02153477081794404\n",
      "train loss:0.0541378719561877\n",
      "train loss:0.02450794539041742\n",
      "train loss:0.023329867533643613\n",
      "train loss:0.043540867658597764\n",
      "train loss:0.04294618508212109\n",
      "train loss:0.02947720513210637\n",
      "train loss:0.09270841622752904\n",
      "train loss:0.0264570412190153\n",
      "train loss:0.028290064215933133\n",
      "train loss:0.037207719189806476\n",
      "train loss:0.07453869975060835\n",
      "train loss:0.08126419308291119\n",
      "train loss:0.01055101016318752\n",
      "train loss:0.03580123243340089\n",
      "train loss:0.06125179730136498\n",
      "train loss:0.02007114311551964\n",
      "train loss:0.053602442874530226\n",
      "train loss:0.043664164751167904\n",
      "train loss:0.04056122141137842\n",
      "train loss:0.037912752361618236\n",
      "train loss:0.03375704699408117\n",
      "train loss:0.03698859629064381\n",
      "train loss:0.06823439749515203\n",
      "train loss:0.03283849027457726\n",
      "train loss:0.051594838707840124\n",
      "train loss:0.08097356715271851\n",
      "train loss:0.02169270102277455\n",
      "train loss:0.09016025479691056\n",
      "train loss:0.0467405199071264\n",
      "train loss:0.026999565037986062\n",
      "train loss:0.03468018027494813\n",
      "train loss:0.11140606198959072\n",
      "train loss:0.09958186484765186\n",
      "train loss:0.078251921191327\n",
      "train loss:0.07039061315551647\n",
      "train loss:0.033389948303219556\n",
      "train loss:0.02342647137123681\n",
      "train loss:0.07877725703612244\n",
      "train loss:0.05196599839776387\n",
      "train loss:0.033824445658703725\n",
      "train loss:0.07433661148169056\n",
      "train loss:0.07958782908056822\n",
      "train loss:0.008561780161461726\n",
      "train loss:0.06341872792131503\n",
      "train loss:0.05754845900953015\n",
      "train loss:0.025739633303895726\n",
      "train loss:0.02874401332019051\n",
      "train loss:0.04863184603508236\n",
      "train loss:0.05780765212777633\n",
      "train loss:0.16797098184806167\n",
      "train loss:0.07884358136976764\n",
      "train loss:0.024306552146247124\n",
      "train loss:0.12980125872950127\n",
      "train loss:0.13809117772187918\n",
      "train loss:0.0319125267305057\n",
      "train loss:0.03562387958103585\n",
      "train loss:0.02102609254477788\n",
      "train loss:0.03330143176009011\n",
      "train loss:0.06082774327557194\n",
      "train loss:0.022559702589978747\n",
      "train loss:0.03663221360449667\n",
      "train loss:0.02710089031096834\n",
      "train loss:0.058444635636061976\n",
      "train loss:0.0368658581901736\n",
      "train loss:0.08324369904084797\n",
      "train loss:0.03595392389724841\n",
      "train loss:0.029563819996268254\n",
      "train loss:0.08661693273156837\n",
      "train loss:0.08722979342398665\n",
      "train loss:0.07401187223887148\n",
      "train loss:0.03864066493138041\n",
      "train loss:0.031139236036592303\n",
      "train loss:0.043598508817172206\n",
      "train loss:0.13979159030379806\n",
      "train loss:0.03672077627769388\n",
      "train loss:0.09118887630947572\n",
      "train loss:0.03423940634642758\n",
      "train loss:0.026963969647508308\n",
      "=== epoch:4, train acc:0.98, test acc:0.985 ===\n",
      "train loss:0.026238817791534284\n",
      "train loss:0.01097081836479657\n",
      "train loss:0.04353525896540191\n",
      "train loss:0.03016377938256931\n",
      "train loss:0.010364242980906364\n",
      "train loss:0.012801412586059378\n",
      "train loss:0.02501118700572015\n",
      "train loss:0.0784878935648201\n",
      "train loss:0.024351240679756105\n",
      "train loss:0.05886504584990581\n",
      "train loss:0.15153369460003444\n",
      "train loss:0.01885268761432338\n",
      "train loss:0.032166998865626045\n",
      "train loss:0.08607310106401972\n",
      "train loss:0.022013153266659414\n",
      "train loss:0.02802906143006304\n",
      "train loss:0.05084235161677816\n",
      "train loss:0.018933396158648415\n",
      "train loss:0.016561632996108033\n",
      "train loss:0.026058026992815987\n",
      "train loss:0.022666604415460236\n",
      "train loss:0.056288734165014426\n",
      "train loss:0.03792201350880942\n",
      "train loss:0.02240904021672928\n",
      "train loss:0.027261652973040052\n",
      "train loss:0.03209492644377984\n",
      "train loss:0.03210905191184947\n",
      "train loss:0.009060522924585385\n",
      "train loss:0.06617398270128823\n",
      "train loss:0.05709873733229264\n",
      "train loss:0.012104257966415786\n",
      "train loss:0.04543869789918155\n",
      "train loss:0.03019079791932636\n",
      "train loss:0.035795961793249495\n",
      "train loss:0.017041965260235027\n",
      "train loss:0.025501856678365575\n",
      "train loss:0.050477702130545005\n",
      "train loss:0.07665193599157977\n",
      "train loss:0.04977255429852329\n",
      "train loss:0.01355977709512227\n",
      "train loss:0.013683976924775942\n",
      "train loss:0.16474236776783335\n",
      "train loss:0.038369829812240276\n",
      "train loss:0.03329538199104831\n",
      "train loss:0.04150649569801078\n",
      "train loss:0.08954412487802209\n",
      "train loss:0.02687212920491736\n",
      "train loss:0.04643529381199441\n",
      "train loss:0.03937214169140739\n",
      "train loss:0.05669831387046001\n",
      "train loss:0.009932608834293442\n",
      "train loss:0.01453650492606637\n",
      "train loss:0.04843397366640912\n",
      "train loss:0.053185316958250864\n",
      "train loss:0.02276400225631708\n",
      "train loss:0.02664618034127502\n",
      "train loss:0.028195792382325186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018923468324431984\n",
      "train loss:0.03245375010609859\n",
      "train loss:0.11600632924053363\n",
      "train loss:0.03166660567531376\n",
      "train loss:0.032655351611160933\n",
      "train loss:0.056768899023185215\n",
      "train loss:0.0497652458471623\n",
      "train loss:0.043412471294005585\n",
      "train loss:0.015490020445072961\n",
      "train loss:0.07748199931499156\n",
      "train loss:0.02637293651821007\n",
      "train loss:0.08620462625928131\n",
      "train loss:0.05048933578038404\n",
      "train loss:0.06236344324620138\n",
      "train loss:0.021666327286596804\n",
      "train loss:0.06328485528076168\n",
      "train loss:0.04236456206919966\n",
      "train loss:0.01722839909217017\n",
      "train loss:0.04982937732543473\n",
      "train loss:0.03445262949439039\n",
      "train loss:0.017666791838255366\n",
      "train loss:0.041480067628636264\n",
      "train loss:0.05620819120556046\n",
      "train loss:0.028502057386272137\n",
      "train loss:0.03600015493734985\n",
      "train loss:0.011287306292295105\n",
      "train loss:0.04817415350616718\n",
      "train loss:0.03318573434043943\n",
      "train loss:0.06389059415491456\n",
      "train loss:0.04056489190505955\n",
      "train loss:0.03700131560802464\n",
      "train loss:0.007236605876025968\n",
      "train loss:0.06454357747224992\n",
      "train loss:0.014668560794982627\n",
      "train loss:0.0362679984889849\n",
      "train loss:0.02698090786134487\n",
      "train loss:0.007893125657255511\n",
      "train loss:0.060304312373451976\n",
      "train loss:0.012944375778071582\n",
      "train loss:0.10040695914983759\n",
      "train loss:0.13724854715350432\n",
      "train loss:0.0457410996370436\n",
      "train loss:0.04158161184214192\n",
      "train loss:0.044150149013175086\n",
      "train loss:0.03223987296361901\n",
      "train loss:0.038175608157509165\n",
      "train loss:0.031056407496248255\n",
      "train loss:0.01570686666917921\n",
      "train loss:0.030627644194483293\n",
      "train loss:0.04317162091149427\n",
      "train loss:0.02270376480818748\n",
      "train loss:0.07141962635316924\n",
      "train loss:0.0442701446712269\n",
      "train loss:0.04243366472331956\n",
      "train loss:0.03299995306190344\n",
      "train loss:0.04383577745058406\n",
      "train loss:0.028691605031147024\n",
      "train loss:0.020070090926079726\n",
      "train loss:0.018446148299206207\n",
      "train loss:0.06397270398910158\n",
      "train loss:0.06363171925371967\n",
      "train loss:0.025702162758531072\n",
      "train loss:0.0227465125332643\n",
      "train loss:0.06964857775664875\n",
      "train loss:0.029233625217112078\n",
      "train loss:0.03457466399721515\n",
      "train loss:0.0195440512456413\n",
      "train loss:0.0703004343356086\n",
      "train loss:0.040946324152467434\n",
      "train loss:0.07120223951279026\n",
      "train loss:0.04916328388106974\n",
      "train loss:0.029878861491042807\n",
      "train loss:0.08531617009997765\n",
      "train loss:0.018230243845298054\n",
      "train loss:0.02191531201830183\n",
      "train loss:0.022113007074322698\n",
      "train loss:0.07534624654886095\n",
      "train loss:0.042910942018195036\n",
      "train loss:0.05884936740757699\n",
      "train loss:0.009807021942031697\n",
      "train loss:0.0641148856762717\n",
      "train loss:0.03628944751538324\n",
      "train loss:0.020194925778653987\n",
      "train loss:0.015006038761049462\n",
      "train loss:0.06476843304560637\n",
      "train loss:0.05608436647805382\n",
      "train loss:0.06907269639167608\n",
      "train loss:0.027356480874589896\n",
      "train loss:0.053397408416803446\n",
      "train loss:0.05795251619712366\n",
      "train loss:0.029433139253967143\n",
      "train loss:0.04980040535733127\n",
      "train loss:0.03813256934776307\n",
      "train loss:0.036972480695458526\n",
      "train loss:0.034037516507579746\n",
      "train loss:0.021644162541607934\n",
      "train loss:0.08504329399137403\n",
      "train loss:0.021108522030273157\n",
      "train loss:0.15177592103591178\n",
      "train loss:0.028824453829002786\n",
      "train loss:0.09040651383815894\n",
      "train loss:0.06014171686194411\n",
      "train loss:0.023765420029950177\n",
      "train loss:0.08791207187128862\n",
      "train loss:0.0629812845660478\n",
      "train loss:0.03758494092101633\n",
      "train loss:0.07850704871930723\n",
      "train loss:0.016233786445594627\n",
      "train loss:0.036962754657645466\n",
      "train loss:0.03098583465657182\n",
      "train loss:0.14022084088831732\n",
      "train loss:0.013212049957392195\n",
      "train loss:0.12924081104030713\n",
      "train loss:0.1117472768434842\n",
      "train loss:0.05324140703974039\n",
      "train loss:0.007150037982225502\n",
      "train loss:0.016931097124371085\n",
      "train loss:0.10238243994591406\n",
      "train loss:0.040357062693230625\n",
      "train loss:0.03506684667905444\n",
      "train loss:0.04674548554940723\n",
      "train loss:0.09823136135920628\n",
      "train loss:0.05269199125686098\n",
      "train loss:0.0701354351664154\n",
      "train loss:0.03208627580092961\n",
      "train loss:0.08397913710492022\n",
      "train loss:0.025640417324977443\n",
      "train loss:0.027426869332024362\n",
      "train loss:0.019574188243284114\n",
      "train loss:0.013250058179654219\n",
      "train loss:0.07634329440136278\n",
      "train loss:0.0967036330237863\n",
      "train loss:0.02107647121493628\n",
      "train loss:0.04579159891557291\n",
      "train loss:0.05015543089786955\n",
      "train loss:0.014378311844819242\n",
      "train loss:0.024561338623684037\n",
      "train loss:0.10814114917682431\n",
      "train loss:0.031616680948467965\n",
      "train loss:0.06397547206785306\n",
      "train loss:0.0850584038909242\n",
      "train loss:0.02141661656411743\n",
      "train loss:0.025459788119817278\n",
      "train loss:0.0416187391609088\n",
      "train loss:0.03220387144463967\n",
      "train loss:0.02847118168071777\n",
      "train loss:0.03467086659853782\n",
      "train loss:0.05994786532948782\n",
      "train loss:0.07664660708246479\n",
      "train loss:0.059766107478038934\n",
      "train loss:0.04155448770818354\n",
      "train loss:0.02360219813807252\n",
      "train loss:0.07189258216860504\n",
      "train loss:0.03745548769706503\n",
      "train loss:0.13095489553693584\n",
      "train loss:0.021740739498969278\n",
      "train loss:0.010286584218872566\n",
      "train loss:0.07270549601430325\n",
      "train loss:0.03767688193719554\n",
      "train loss:0.06529708981762743\n",
      "train loss:0.07813683084483813\n",
      "train loss:0.011455913801270918\n",
      "train loss:0.019719789197711286\n",
      "train loss:0.03028217130008777\n",
      "train loss:0.06767011619520229\n",
      "train loss:0.021191696635521628\n",
      "train loss:0.040783898338247776\n",
      "train loss:0.008632192128361593\n",
      "train loss:0.011671177537165399\n",
      "train loss:0.0917637117483656\n",
      "train loss:0.03148602059908885\n",
      "train loss:0.026514111046295242\n",
      "train loss:0.01994430599606778\n",
      "train loss:0.020914950400396023\n",
      "train loss:0.08284647498217418\n",
      "train loss:0.010451960585797039\n",
      "train loss:0.046834311952584834\n",
      "train loss:0.029988341163173768\n",
      "train loss:0.036009537388524984\n",
      "train loss:0.0802145503941595\n",
      "train loss:0.033378010801070855\n",
      "train loss:0.05233155818771661\n",
      "train loss:0.0439542834286978\n",
      "train loss:0.03728442418802768\n",
      "train loss:0.019016064244313596\n",
      "train loss:0.07393826329534799\n",
      "train loss:0.07640986369740163\n",
      "train loss:0.01635955403426863\n",
      "train loss:0.06705902672342193\n",
      "train loss:0.048582470352359165\n",
      "train loss:0.02561655320392618\n",
      "train loss:0.061454407299581904\n",
      "train loss:0.0067170314231708985\n",
      "train loss:0.05682557257584522\n",
      "train loss:0.03881416528536136\n",
      "train loss:0.09098676666597266\n",
      "train loss:0.01856896644373757\n",
      "train loss:0.030119189711007542\n",
      "train loss:0.06495171116483699\n",
      "train loss:0.01746108120318938\n",
      "train loss:0.007683484582203265\n",
      "train loss:0.028172734856222938\n",
      "train loss:0.14498426412366758\n",
      "train loss:0.07223904748827913\n",
      "train loss:0.031152065895817947\n",
      "train loss:0.025686589200137354\n",
      "train loss:0.0167078762377809\n",
      "train loss:0.07613410819815603\n",
      "train loss:0.009950825276386651\n",
      "train loss:0.02264762780010284\n",
      "train loss:0.013846684186166955\n",
      "train loss:0.18551950509801857\n",
      "train loss:0.04398422241414728\n",
      "train loss:0.02650024667375947\n",
      "train loss:0.092402589338895\n",
      "train loss:0.02778167741731287\n",
      "train loss:0.014523805305257678\n",
      "train loss:0.03801967072163346\n",
      "train loss:0.013631900336224093\n",
      "train loss:0.04191567968987697\n",
      "train loss:0.0526139375032876\n",
      "train loss:0.020685232251846253\n",
      "train loss:0.014397613425507915\n",
      "train loss:0.02083252818229515\n",
      "train loss:0.0329330720159697\n",
      "train loss:0.03718899756942095\n",
      "train loss:0.10918261855664232\n",
      "train loss:0.013007766435197653\n",
      "train loss:0.0672316884453358\n",
      "train loss:0.03941847570781326\n",
      "train loss:0.017097192857166293\n",
      "train loss:0.01748675873928484\n",
      "train loss:0.05665259803970157\n",
      "train loss:0.019951596328129737\n",
      "train loss:0.01860643345422214\n",
      "train loss:0.14010467281758707\n",
      "train loss:0.04665704620624135\n",
      "train loss:0.0415312586657915\n",
      "train loss:0.04306117774740804\n",
      "train loss:0.04111814848394431\n",
      "train loss:0.05489851397464772\n",
      "train loss:0.053872514466482266\n",
      "train loss:0.011100968710798385\n",
      "train loss:0.06775981095868853\n",
      "train loss:0.017966375660400335\n",
      "train loss:0.18627931373382747\n",
      "train loss:0.07255881708487542\n",
      "train loss:0.060290427384980146\n",
      "train loss:0.03524941105868171\n",
      "train loss:0.008321727866593416\n",
      "train loss:0.041766486160764976\n",
      "train loss:0.013076316490091826\n",
      "train loss:0.020124152819562167\n",
      "train loss:0.030286840407306045\n",
      "train loss:0.05922320605075723\n",
      "train loss:0.021874613220383456\n",
      "train loss:0.023229640943880036\n",
      "train loss:0.021708736720771848\n",
      "train loss:0.05292835104460983\n",
      "train loss:0.036117384295236525\n",
      "train loss:0.04733700993019358\n",
      "train loss:0.01418227984661835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11096944045042317\n",
      "train loss:0.05244527468847659\n",
      "train loss:0.05049708015621721\n",
      "train loss:0.03216343235187092\n",
      "train loss:0.04182523149416217\n",
      "train loss:0.023126557718239554\n",
      "train loss:0.06350464335446257\n",
      "train loss:0.036215944438885296\n",
      "train loss:0.06807444850728\n",
      "train loss:0.05795214754321435\n",
      "train loss:0.06447208280720566\n",
      "train loss:0.02613702158823754\n",
      "train loss:0.1011328942038738\n",
      "train loss:0.047784286863993095\n",
      "train loss:0.015342277325607064\n",
      "train loss:0.049759847313968555\n",
      "train loss:0.02272783473865566\n",
      "train loss:0.025145368295753038\n",
      "train loss:0.012774627041587267\n",
      "train loss:0.0416859684820561\n",
      "train loss:0.023930264300175693\n",
      "train loss:0.035269038368110864\n",
      "train loss:0.06473285374872106\n",
      "train loss:0.11459765231592192\n",
      "train loss:0.044052361941622424\n",
      "train loss:0.018312094249786495\n",
      "train loss:0.029782232665059485\n",
      "train loss:0.08086373080114867\n",
      "train loss:0.02904832543816531\n",
      "train loss:0.11346256585318294\n",
      "train loss:0.06338020771222448\n",
      "train loss:0.08249016994098594\n",
      "train loss:0.014791672423377356\n",
      "train loss:0.030246700924580865\n",
      "train loss:0.026241775390621384\n",
      "train loss:0.06567613795943607\n",
      "train loss:0.02558656060835547\n",
      "train loss:0.03238568887289811\n",
      "train loss:0.13595828084850667\n",
      "train loss:0.08776765279313979\n",
      "train loss:0.10680182422973131\n",
      "train loss:0.006368130324594207\n",
      "train loss:0.06160114914699392\n",
      "train loss:0.013523302772693377\n",
      "train loss:0.044811673795665585\n",
      "train loss:0.03330702973009345\n",
      "train loss:0.02244118706162993\n",
      "train loss:0.046744328488532084\n",
      "train loss:0.024219309567258877\n",
      "train loss:0.01024179808022033\n",
      "train loss:0.03484300898942401\n",
      "train loss:0.017012207196842887\n",
      "train loss:0.06433529193973438\n",
      "train loss:0.01564051728986844\n",
      "train loss:0.03254548811709582\n",
      "train loss:0.023584726606927293\n",
      "train loss:0.01840426281921765\n",
      "train loss:0.06878702684191029\n",
      "train loss:0.06533931765009879\n",
      "train loss:0.048935542953777514\n",
      "train loss:0.009931753927653504\n",
      "train loss:0.010828951529774972\n",
      "train loss:0.028016889626436493\n",
      "train loss:0.013899942455270573\n",
      "train loss:0.0478416271482105\n",
      "train loss:0.07176578161351176\n",
      "train loss:0.024253181176527132\n",
      "train loss:0.050622171464588875\n",
      "train loss:0.023983298220127177\n",
      "train loss:0.04397206646710812\n",
      "train loss:0.027941243409605573\n",
      "train loss:0.01071440393777086\n",
      "train loss:0.021356496406659233\n",
      "train loss:0.07000516558110263\n",
      "train loss:0.08081645780632142\n",
      "train loss:0.03633930264730252\n",
      "train loss:0.09110537079187131\n",
      "train loss:0.02106811458191904\n",
      "train loss:0.02322053768156637\n",
      "train loss:0.017234120894510926\n",
      "train loss:0.01643608875685023\n",
      "train loss:0.033213630696486064\n",
      "train loss:0.012772408377295137\n",
      "train loss:0.045747103754955026\n",
      "train loss:0.06662759617311394\n",
      "train loss:0.010035826966218703\n",
      "train loss:0.0049517480258593535\n",
      "train loss:0.01798062890077946\n",
      "train loss:0.014256690886732808\n",
      "train loss:0.16183939685522625\n",
      "train loss:0.0369997023168562\n",
      "train loss:0.027549341716157055\n",
      "train loss:0.015951925357921382\n",
      "train loss:0.19149908631340448\n",
      "train loss:0.04961899670284762\n",
      "train loss:0.018681648839334212\n",
      "train loss:0.07213776716628668\n",
      "train loss:0.09465727465187895\n",
      "train loss:0.0521014919730872\n",
      "train loss:0.03058293421059589\n",
      "train loss:0.013429542414573453\n",
      "train loss:0.04350940175726701\n",
      "train loss:0.018571209710698634\n",
      "train loss:0.0702176770861345\n",
      "train loss:0.020828215075107518\n",
      "train loss:0.12652773862539926\n",
      "train loss:0.02452633195102304\n",
      "train loss:0.009135657504169932\n",
      "train loss:0.019000908447377382\n",
      "train loss:0.040909703623030425\n",
      "train loss:0.024292689133765043\n",
      "train loss:0.04958085108310297\n",
      "train loss:0.04081437372188664\n",
      "train loss:0.030444901220970353\n",
      "train loss:0.02403683899844156\n",
      "train loss:0.05872747870876636\n",
      "train loss:0.07349016305721666\n",
      "train loss:0.0429357212244497\n",
      "train loss:0.021785524768945925\n",
      "train loss:0.03598482156572433\n",
      "train loss:0.07286046311978178\n",
      "train loss:0.026370894280946647\n",
      "train loss:0.01962429170736277\n",
      "train loss:0.023055296343409283\n",
      "train loss:0.010157096731764802\n",
      "train loss:0.050876313293042166\n",
      "train loss:0.08813898646016828\n",
      "train loss:0.04665896516314844\n",
      "train loss:0.03510659316270487\n",
      "train loss:0.011916237881423573\n",
      "train loss:0.01512468534851208\n",
      "train loss:0.08796165977396987\n",
      "train loss:0.08101279450964785\n",
      "train loss:0.020563708407844734\n",
      "train loss:0.1259232002931543\n",
      "train loss:0.011922841437848814\n",
      "train loss:0.06666685122877088\n",
      "train loss:0.02741686392915708\n",
      "train loss:0.053649824938449026\n",
      "train loss:0.042362952490969226\n",
      "train loss:0.05077864681409363\n",
      "train loss:0.05645073062154748\n",
      "train loss:0.017341426681175033\n",
      "train loss:0.018522505931593543\n",
      "train loss:0.14667191780046623\n",
      "train loss:0.02904931666192966\n",
      "train loss:0.05730526029828519\n",
      "train loss:0.005615657757979824\n",
      "train loss:0.06196757639869599\n",
      "train loss:0.06934613105095899\n",
      "train loss:0.07977517659104508\n",
      "train loss:0.020020801859396222\n",
      "train loss:0.038185479108096616\n",
      "train loss:0.039853443524122886\n",
      "train loss:0.028009295946804343\n",
      "train loss:0.006995122724391407\n",
      "train loss:0.014061959267967074\n",
      "train loss:0.02428912423217206\n",
      "train loss:0.05357068318907521\n",
      "train loss:0.03923086919175325\n",
      "train loss:0.04335624112941197\n",
      "train loss:0.02196152013902621\n",
      "train loss:0.032711878817839976\n",
      "train loss:0.03173600372106898\n",
      "train loss:0.046401079496080036\n",
      "train loss:0.012255774493269955\n",
      "train loss:0.027540453652743598\n",
      "train loss:0.02082844529562194\n",
      "train loss:0.070047886642204\n",
      "train loss:0.04247344193090718\n",
      "train loss:0.0290654761549645\n",
      "train loss:0.05234057908257249\n",
      "train loss:0.02917406810548784\n",
      "train loss:0.017556811380658472\n",
      "train loss:0.010565601824540593\n",
      "train loss:0.037711961692594616\n",
      "train loss:0.019125131985033735\n",
      "train loss:0.09080356428354701\n",
      "train loss:0.031899055691278\n",
      "train loss:0.055961537071753026\n",
      "train loss:0.05898006684123677\n",
      "train loss:0.04143745955969694\n",
      "train loss:0.05770663311612927\n",
      "train loss:0.022008142418852437\n",
      "train loss:0.03350675482408718\n",
      "train loss:0.06922167377998942\n",
      "train loss:0.06046000708429675\n",
      "train loss:0.06270021557090324\n",
      "train loss:0.031164794592441168\n",
      "train loss:0.03440530911086184\n",
      "train loss:0.03926258205219042\n",
      "train loss:0.023449612852895277\n",
      "train loss:0.05188450764418656\n",
      "train loss:0.034117380136511374\n",
      "train loss:0.026303045395073284\n",
      "train loss:0.04367276140924041\n",
      "train loss:0.04932461675029447\n",
      "train loss:0.026606321067005972\n",
      "train loss:0.01133643591737475\n",
      "train loss:0.03404698256132522\n",
      "train loss:0.048871516556414286\n",
      "train loss:0.012406524475501479\n",
      "train loss:0.02765333517695889\n",
      "train loss:0.09535716513565508\n",
      "train loss:0.03550121359713415\n",
      "train loss:0.010363054567066947\n",
      "train loss:0.00922976221304308\n",
      "train loss:0.008751785135732923\n",
      "train loss:0.01920815853981762\n",
      "train loss:0.024667923386942226\n",
      "train loss:0.1278139938448006\n",
      "train loss:0.01577676011122828\n",
      "train loss:0.05225171360410839\n",
      "train loss:0.04855077268783106\n",
      "train loss:0.017951398891719608\n",
      "train loss:0.041740414054660946\n",
      "train loss:0.046075329068272115\n",
      "train loss:0.020529332795531242\n",
      "train loss:0.00775591730422427\n",
      "train loss:0.013962706690243543\n",
      "train loss:0.05217215443096435\n",
      "train loss:0.016206789600816972\n",
      "train loss:0.017823754286094316\n",
      "train loss:0.031755742397357935\n",
      "train loss:0.010149361005017628\n",
      "train loss:0.047214817949661585\n",
      "train loss:0.00886280414170673\n",
      "train loss:0.017404679007403768\n",
      "train loss:0.019111674830190863\n",
      "train loss:0.01117776453029484\n",
      "train loss:0.02517676182137383\n",
      "train loss:0.03224111770479847\n",
      "train loss:0.01554017359288356\n",
      "train loss:0.08020245861776659\n",
      "train loss:0.07081375731771089\n",
      "train loss:0.006463474949133203\n",
      "train loss:0.14227208462063873\n",
      "train loss:0.022187703675653953\n",
      "train loss:0.06762994027280524\n",
      "train loss:0.08411594173992318\n",
      "train loss:0.034829684422927734\n",
      "train loss:0.009566686415350785\n",
      "train loss:0.03185471874307086\n",
      "train loss:0.05301014451385361\n",
      "train loss:0.03427872148030085\n",
      "train loss:0.07443796732153414\n",
      "train loss:0.00845021900171662\n",
      "train loss:0.01841978024380272\n",
      "train loss:0.02343021773123652\n",
      "train loss:0.027071074546531553\n",
      "train loss:0.030939541199237412\n",
      "train loss:0.040033456217844564\n",
      "train loss:0.008828302218192342\n",
      "train loss:0.04901970323449633\n",
      "train loss:0.06314414199327309\n",
      "train loss:0.045631898003361114\n",
      "train loss:0.03506302508738894\n",
      "train loss:0.010915369648647573\n",
      "train loss:0.024517742368972147\n",
      "train loss:0.022079476485521082\n",
      "train loss:0.013573187523149916\n",
      "train loss:0.05767904643406945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01290133566355204\n",
      "train loss:0.013450575759883787\n",
      "train loss:0.05721827248586951\n",
      "train loss:0.04141210778133197\n",
      "train loss:0.014781063442322774\n",
      "train loss:0.017280286718775757\n",
      "train loss:0.011641543737482577\n",
      "train loss:0.03137124148306077\n",
      "train loss:0.0596379135434721\n",
      "train loss:0.03261978390262075\n",
      "train loss:0.04234830459483835\n",
      "train loss:0.015205932036303358\n",
      "train loss:0.05868883900605899\n",
      "train loss:0.04507954594641717\n",
      "train loss:0.02932670169844718\n",
      "train loss:0.12616597343593017\n",
      "train loss:0.027586579937915513\n",
      "train loss:0.03793197421286948\n",
      "train loss:0.03757629576192492\n",
      "=== epoch:5, train acc:0.982, test acc:0.988 ===\n",
      "train loss:0.03441886603586832\n",
      "train loss:0.059116811643427136\n",
      "train loss:0.0447964845436103\n",
      "train loss:0.010495882271599685\n",
      "train loss:0.04647199548453147\n",
      "train loss:0.04611305313604061\n",
      "train loss:0.09476520878053002\n",
      "train loss:0.022839032475687093\n",
      "train loss:0.03692495773903948\n",
      "train loss:0.0264740422781269\n",
      "train loss:0.02300567150768067\n",
      "train loss:0.07865276778996061\n",
      "train loss:0.018624235797195157\n",
      "train loss:0.07443301334850375\n",
      "train loss:0.01349994079266827\n",
      "train loss:0.032961492752514795\n",
      "train loss:0.030302207711542017\n",
      "train loss:0.02338569387628537\n",
      "train loss:0.024049438413951244\n",
      "train loss:0.012276329774822679\n",
      "train loss:0.12535466454174776\n",
      "train loss:0.022784958362569566\n",
      "train loss:0.10532730394362622\n",
      "train loss:0.0026101996058833167\n",
      "train loss:0.024402514672513708\n",
      "train loss:0.024405258322132875\n",
      "train loss:0.013677439960434553\n",
      "train loss:0.014983647691645554\n",
      "train loss:0.010211063981002235\n",
      "train loss:0.060448288494334826\n",
      "train loss:0.054658408493300455\n",
      "train loss:0.022868093042781742\n",
      "train loss:0.03512859336109235\n",
      "train loss:0.044272571679041445\n",
      "train loss:0.06201095812959632\n",
      "train loss:0.014752324044922695\n",
      "train loss:0.06287221152365025\n",
      "train loss:0.01665195932897831\n",
      "train loss:0.0704663928963121\n",
      "train loss:0.04064693903474827\n",
      "train loss:0.020022110855135725\n",
      "train loss:0.034869275808160724\n",
      "train loss:0.09308182695880216\n",
      "train loss:0.01347631229503261\n",
      "train loss:0.031971115258779756\n",
      "train loss:0.1155438540264574\n",
      "train loss:0.04100720824350306\n",
      "train loss:0.01506048463476679\n",
      "train loss:0.02992190573910761\n",
      "train loss:0.024525508927360322\n",
      "train loss:0.013104649855177085\n",
      "train loss:0.01873815554035859\n",
      "train loss:0.04282015877124989\n",
      "train loss:0.026648806156514566\n",
      "train loss:0.011802809993658403\n",
      "train loss:0.008973567628439896\n",
      "train loss:0.020582870060229155\n",
      "train loss:0.03974045762477521\n",
      "train loss:0.05865270367579671\n",
      "train loss:0.031412545505996835\n",
      "train loss:0.028915697482876226\n",
      "train loss:0.009453281152816156\n",
      "train loss:0.06448107124453614\n",
      "train loss:0.014452192088891236\n",
      "train loss:0.0269237117913803\n",
      "train loss:0.01955608880211747\n",
      "train loss:0.03845526234091992\n",
      "train loss:0.025801581505237745\n",
      "train loss:0.008848120209167185\n",
      "train loss:0.01543488475944911\n",
      "train loss:0.044688970389266724\n",
      "train loss:0.03168523678294182\n",
      "train loss:0.04617563349330757\n",
      "train loss:0.004070393282349541\n",
      "train loss:0.004547821022513943\n",
      "train loss:0.06955453385763319\n",
      "train loss:0.029185454575979188\n",
      "train loss:0.03832363747817828\n",
      "train loss:0.026459796902247427\n",
      "train loss:0.042232999440890456\n",
      "train loss:0.11727164495493236\n",
      "train loss:0.04472554372218438\n",
      "train loss:0.038049900386310946\n",
      "train loss:0.05845506257957301\n",
      "train loss:0.027546178224250983\n",
      "train loss:0.04441489199393411\n",
      "train loss:0.013097117957270593\n",
      "train loss:0.009808585178756837\n",
      "train loss:0.043392023480659334\n",
      "train loss:0.027259993191927415\n",
      "train loss:0.01736526743583048\n",
      "train loss:0.0514298049836876\n",
      "train loss:0.03179731943894684\n",
      "train loss:0.004138519159202539\n",
      "train loss:0.033919790367894304\n",
      "train loss:0.017840138793793096\n",
      "train loss:0.012201750282444938\n",
      "train loss:0.008339516240690835\n",
      "train loss:0.028892305086359503\n",
      "train loss:0.03773068322537118\n",
      "train loss:0.024652188374443718\n",
      "train loss:0.03779243439986389\n",
      "train loss:0.07215988779138366\n",
      "train loss:0.11212663897703458\n",
      "train loss:0.03243825918609847\n",
      "train loss:0.0612035813048575\n",
      "train loss:0.050964822659821864\n",
      "train loss:0.07049560743613127\n",
      "train loss:0.011321011375685924\n",
      "train loss:0.06919027936295279\n",
      "train loss:0.01426621206771244\n",
      "train loss:0.042188113075942085\n",
      "train loss:0.03023171025296842\n",
      "train loss:0.13317666103373663\n",
      "train loss:0.06279263289050772\n",
      "train loss:0.043932898199463846\n",
      "train loss:0.01935090676001461\n",
      "train loss:0.023065271341771044\n",
      "train loss:0.03501451819254453\n",
      "train loss:0.013959298199338522\n",
      "train loss:0.012881787674255723\n",
      "train loss:0.024164715390128794\n",
      "train loss:0.044007509457191986\n",
      "train loss:0.011919394384224706\n",
      "train loss:0.057894515129912734\n",
      "train loss:0.049232094265696545\n",
      "train loss:0.04003211783556535\n",
      "train loss:0.019464569751538475\n",
      "train loss:0.010197424145559977\n",
      "train loss:0.05605445956132902\n",
      "train loss:0.07203085627651512\n",
      "train loss:0.02921295927919119\n",
      "train loss:0.02719459822006753\n",
      "train loss:0.023702224532708042\n",
      "train loss:0.008106916207768431\n",
      "train loss:0.013984634120485579\n",
      "train loss:0.01212987685181537\n",
      "train loss:0.01925536248795313\n",
      "train loss:0.02364757014645561\n",
      "train loss:0.006493564234340932\n",
      "train loss:0.01629548905135663\n",
      "train loss:0.08646906793178184\n",
      "train loss:0.013920100521795892\n",
      "train loss:0.047877459375090095\n",
      "train loss:0.016199922089020498\n",
      "train loss:0.06083584875230454\n",
      "train loss:0.02073279465619534\n",
      "train loss:0.10138940712004951\n",
      "train loss:0.01735027962225345\n",
      "train loss:0.05465242478697133\n",
      "train loss:0.018908534442979404\n",
      "train loss:0.012606285039526882\n",
      "train loss:0.03415082195256925\n",
      "train loss:0.008295188359754884\n",
      "train loss:0.008150031644795918\n",
      "train loss:0.05609657711210164\n",
      "train loss:0.031239038765264158\n",
      "train loss:0.01383329571198293\n",
      "train loss:0.02380128983151228\n",
      "train loss:0.0173203050692948\n",
      "train loss:0.01658219383836721\n",
      "train loss:0.045828320154247565\n",
      "train loss:0.021435906333959483\n",
      "train loss:0.03410858270043531\n",
      "train loss:0.03294102336809186\n",
      "train loss:0.004578615958980202\n",
      "train loss:0.014326792604045291\n",
      "train loss:0.03874576488249002\n",
      "train loss:0.04132893040814243\n",
      "train loss:0.038949554619776935\n",
      "train loss:0.01742794988253533\n",
      "train loss:0.009029915311359979\n",
      "train loss:0.1414049824618923\n",
      "train loss:0.020571102088176463\n",
      "train loss:0.08515726173094179\n",
      "train loss:0.01004697647768848\n",
      "train loss:0.01559694648315907\n",
      "train loss:0.03748405034577254\n",
      "train loss:0.020502143320628677\n",
      "train loss:0.07538720134065319\n",
      "train loss:0.007367379029327426\n",
      "train loss:0.016648630808980772\n",
      "train loss:0.010884820354836374\n",
      "train loss:0.04292651732332835\n",
      "train loss:0.01705050431533516\n",
      "train loss:0.01901002919199846\n",
      "train loss:0.03145144128420359\n",
      "train loss:0.06843640948929237\n",
      "train loss:0.05679693074901989\n",
      "train loss:0.11646471652401236\n",
      "train loss:0.025896872018725273\n",
      "train loss:0.03386735644007647\n",
      "train loss:0.055317689298243614\n",
      "train loss:0.0062075515382607116\n",
      "train loss:0.013780685649111484\n",
      "train loss:0.029584624287561305\n",
      "train loss:0.004043113666270922\n",
      "train loss:0.00446514482642714\n",
      "train loss:0.053506647900567514\n",
      "train loss:0.023202852533626042\n",
      "train loss:0.0019498121291626536\n",
      "train loss:0.013174287255390695\n",
      "train loss:0.010185522000899389\n",
      "train loss:0.017371130421536377\n",
      "train loss:0.0235695764771791\n",
      "train loss:0.06844304997731834\n",
      "train loss:0.016196499987582307\n",
      "train loss:0.01564088735634742\n",
      "train loss:0.03459750990013047\n",
      "train loss:0.013702406472657736\n",
      "train loss:0.019511051283493695\n",
      "train loss:0.010361012284359976\n",
      "train loss:0.009722568315605076\n",
      "train loss:0.027853329412471654\n",
      "train loss:0.033977137530966456\n",
      "train loss:0.04304519980097657\n",
      "train loss:0.0026475261986312797\n",
      "train loss:0.00556900712344675\n",
      "train loss:0.01453454781213658\n",
      "train loss:0.04221836385347491\n",
      "train loss:0.01779848712703768\n",
      "train loss:0.02991325376236215\n",
      "train loss:0.03718191149243613\n",
      "train loss:0.059103360144364674\n",
      "train loss:0.024551264505202283\n",
      "train loss:0.011535448974958474\n",
      "train loss:0.011944891769743511\n",
      "train loss:0.02728963237918879\n",
      "train loss:0.0278210368677374\n",
      "train loss:0.01327815703443443\n",
      "train loss:0.024831073346680523\n",
      "train loss:0.03656085056424258\n",
      "train loss:0.013178519323249259\n",
      "train loss:0.03176977617994712\n",
      "train loss:0.04371250502038345\n",
      "train loss:0.020492179806069332\n",
      "train loss:0.03250462913653915\n",
      "train loss:0.04976884743931673\n",
      "train loss:0.019682994813922026\n",
      "train loss:0.009152866227348167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004061575409485057\n",
      "train loss:0.025474096720297296\n",
      "train loss:0.0351033938725896\n",
      "train loss:0.04454768248614987\n",
      "train loss:0.025980290654554105\n",
      "train loss:0.010981025796663935\n",
      "train loss:0.04799710423393586\n",
      "train loss:0.021833595530387506\n",
      "train loss:0.013310762062828132\n",
      "train loss:0.041931075799759326\n",
      "train loss:0.015475329268632215\n",
      "train loss:0.007750005678831494\n",
      "train loss:0.025695620128785367\n",
      "train loss:0.06998430155674157\n",
      "train loss:0.03025259870693989\n",
      "train loss:0.010274144713251077\n",
      "train loss:0.0857699317773219\n",
      "train loss:0.016852453020068197\n",
      "train loss:0.0744818503939849\n",
      "train loss:0.022324334751422644\n",
      "train loss:0.018447515341453325\n",
      "train loss:0.019942198280996144\n",
      "train loss:0.06390352453289493\n",
      "train loss:0.017241021719430455\n",
      "train loss:0.04818178334799121\n",
      "train loss:0.05762171895226574\n",
      "train loss:0.03668760362768928\n",
      "train loss:0.009479507948493207\n",
      "train loss:0.027736930566165774\n",
      "train loss:0.08839318835050265\n",
      "train loss:0.026156536653779344\n",
      "train loss:0.04044826022513887\n",
      "train loss:0.03391536186507459\n",
      "train loss:0.04631219290770165\n",
      "train loss:0.016402671847957864\n",
      "train loss:0.06624002291749591\n",
      "train loss:0.058542922472266924\n",
      "train loss:0.04024308948816614\n",
      "train loss:0.025643305495799486\n",
      "train loss:0.02529499795481685\n",
      "train loss:0.019451237616741366\n",
      "train loss:0.00823673094647939\n",
      "train loss:0.022876809274527905\n",
      "train loss:0.01828885918927013\n",
      "train loss:0.051780110191537866\n",
      "train loss:0.051589861481844954\n",
      "train loss:0.015900582694102855\n",
      "train loss:0.181950583232486\n",
      "train loss:0.02042566878594976\n",
      "train loss:0.010010258400688926\n",
      "train loss:0.04990525852841292\n",
      "train loss:0.06011873669241577\n",
      "train loss:0.11738283207003121\n",
      "train loss:0.06492609122832364\n",
      "train loss:0.05167371656843561\n",
      "train loss:0.02717852189535784\n",
      "train loss:0.05130737661239746\n",
      "train loss:0.05478451389071275\n",
      "train loss:0.07019964186088189\n",
      "train loss:0.09037275865082794\n",
      "train loss:0.019801923613184627\n",
      "train loss:0.021045648960340748\n",
      "train loss:0.01029061642725657\n",
      "train loss:0.05289771321792618\n",
      "train loss:0.05024880453013655\n",
      "train loss:0.01875548939315258\n",
      "train loss:0.11547103294695205\n",
      "train loss:0.025968150622863742\n",
      "train loss:0.01455451972338297\n",
      "train loss:0.01237270761821088\n",
      "train loss:0.01267228769741293\n",
      "train loss:0.0192320397055693\n",
      "train loss:0.01686853593307709\n",
      "train loss:0.02316571204151554\n",
      "train loss:0.037349753750772235\n",
      "train loss:0.00848687555876792\n",
      "train loss:0.01583649260574093\n",
      "train loss:0.02535912470782315\n",
      "train loss:0.01590662703230336\n",
      "train loss:0.015104806715027855\n",
      "train loss:0.01169146171109546\n",
      "train loss:0.013938058873661965\n",
      "train loss:0.022083419790722272\n",
      "train loss:0.01578018819896147\n",
      "train loss:0.011792479673684565\n",
      "train loss:0.13529561017646322\n",
      "train loss:0.01392939282772399\n",
      "train loss:0.01290680758581587\n",
      "train loss:0.02060313547712684\n",
      "train loss:0.05695949546572323\n",
      "train loss:0.020195797962594596\n",
      "train loss:0.017603750177799967\n",
      "train loss:0.044392214339009\n",
      "train loss:0.036177503600584006\n",
      "train loss:0.008666630659073502\n",
      "train loss:0.011124216811847077\n",
      "train loss:0.07729450416605714\n",
      "train loss:0.03676159085516098\n",
      "train loss:0.06328847710397989\n",
      "train loss:0.04253270831786536\n",
      "train loss:0.1320597476852462\n",
      "train loss:0.01546935126365488\n",
      "train loss:0.029208574372802425\n",
      "train loss:0.011636397112530443\n",
      "train loss:0.019284658859670564\n",
      "train loss:0.008498641742577383\n",
      "train loss:0.012419923058779507\n",
      "train loss:0.03227494964676934\n",
      "train loss:0.020575183345855508\n",
      "train loss:0.040598238080699484\n",
      "train loss:0.013695998522771462\n",
      "train loss:0.03277034853575544\n",
      "train loss:0.006530909488478172\n",
      "train loss:0.01537913535177557\n",
      "train loss:0.02792227608065919\n",
      "train loss:0.012704030701959879\n",
      "train loss:0.05914168589578278\n",
      "train loss:0.03511731201084067\n",
      "train loss:0.0385998718938335\n",
      "train loss:0.015026484568181661\n",
      "train loss:0.03173242637189554\n",
      "train loss:0.007478764758451967\n",
      "train loss:0.04371558105993754\n",
      "train loss:0.01813047173891915\n",
      "train loss:0.014476463030064867\n",
      "train loss:0.014495287622909771\n",
      "train loss:0.05182867302398513\n",
      "train loss:0.03250006751691147\n",
      "train loss:0.04025929496985385\n",
      "train loss:0.04765037936634229\n",
      "train loss:0.022033508908314983\n",
      "train loss:0.015363072834188925\n",
      "train loss:0.06474965546838912\n",
      "train loss:0.09088354125518469\n",
      "train loss:0.04753733290942475\n",
      "train loss:0.04636170141278398\n",
      "train loss:0.010967746364277785\n",
      "train loss:0.030041159426531558\n",
      "train loss:0.04648627431105425\n",
      "train loss:0.012003537844885084\n",
      "train loss:0.033323936683353754\n",
      "train loss:0.005086194397517716\n",
      "train loss:0.0671275768740314\n",
      "train loss:0.03448051735988712\n",
      "train loss:0.010465953172819436\n",
      "train loss:0.009576946097821186\n",
      "train loss:0.010180891138511235\n",
      "train loss:0.02651784307829685\n",
      "train loss:0.004721576616132714\n",
      "train loss:0.055113176920040245\n",
      "train loss:0.026730157859895232\n",
      "train loss:0.01835840349965425\n",
      "train loss:0.014986907025560815\n",
      "train loss:0.01750639308816386\n",
      "train loss:0.03522503690322956\n",
      "train loss:0.0164293584938811\n",
      "train loss:0.019279760805305076\n",
      "train loss:0.02515628046033678\n",
      "train loss:0.04137811464700844\n",
      "train loss:0.040299032913006225\n",
      "train loss:0.03190600223820966\n",
      "train loss:0.03764694153383074\n",
      "train loss:0.05132848957249485\n",
      "train loss:0.03661393858011019\n",
      "train loss:0.05906552734001636\n",
      "train loss:0.010644348492402889\n",
      "train loss:0.02670143747120278\n",
      "train loss:0.017446479625098855\n",
      "train loss:0.01022110205429503\n",
      "train loss:0.013635335236482757\n",
      "train loss:0.0831901861837398\n",
      "train loss:0.017106250991798133\n",
      "train loss:0.009755189486855184\n",
      "train loss:0.035749843152053526\n",
      "train loss:0.011345122986963005\n",
      "train loss:0.023171712233595997\n",
      "train loss:0.0066411603394566365\n",
      "train loss:0.014000276682040404\n",
      "train loss:0.03446871031015388\n",
      "train loss:0.015342375661715485\n",
      "train loss:0.031886685308896705\n",
      "train loss:0.006668931019753453\n",
      "train loss:0.021708658103766865\n",
      "train loss:0.012282920007869076\n",
      "train loss:0.07738716994709989\n",
      "train loss:0.01725262788366356\n",
      "train loss:0.026113560184525896\n",
      "train loss:0.08041931775474774\n",
      "train loss:0.013537127795802946\n",
      "train loss:0.023059113965857973\n",
      "train loss:0.018055605433327928\n",
      "train loss:0.018206335622964764\n",
      "train loss:0.0450798147037835\n",
      "train loss:0.03861126176600922\n",
      "train loss:0.0387958411861237\n",
      "train loss:0.03987782980698138\n",
      "train loss:0.02870314707560108\n",
      "train loss:0.03955869857128393\n",
      "train loss:0.012269056453091929\n",
      "train loss:0.06287084101454504\n",
      "train loss:0.02353794056909935\n",
      "train loss:0.04497461749485418\n",
      "train loss:0.0096006216906468\n",
      "train loss:0.014927634839748962\n",
      "train loss:0.021305665287354524\n",
      "train loss:0.027920806386408765\n",
      "train loss:0.01634670666345805\n",
      "train loss:0.020947136295481\n",
      "train loss:0.02705585456880328\n",
      "train loss:0.008384824992980723\n",
      "train loss:0.014652005904958713\n",
      "train loss:0.011317283109957768\n",
      "train loss:0.02503633432524856\n",
      "train loss:0.04216428518603449\n",
      "train loss:0.01770430800706338\n",
      "train loss:0.024369365148755328\n",
      "train loss:0.014608284122967578\n",
      "train loss:0.04438309182528112\n",
      "train loss:0.02466172716966649\n",
      "train loss:0.03973623104032988\n",
      "train loss:0.026444470719338392\n",
      "train loss:0.04078440054324259\n",
      "train loss:0.0097390927233371\n",
      "train loss:0.04039312696515758\n",
      "train loss:0.004489331328152877\n",
      "train loss:0.05649276958534727\n",
      "train loss:0.005623319092103704\n",
      "train loss:0.015635812008218827\n",
      "train loss:0.014528431547299808\n",
      "train loss:0.04605708052258551\n",
      "train loss:0.021737687249838333\n",
      "train loss:0.01861988028011\n",
      "train loss:0.01732991825172047\n",
      "train loss:0.022496206943591113\n",
      "train loss:0.022511031005268804\n",
      "train loss:0.019283016259150222\n",
      "train loss:0.018855975146179\n",
      "train loss:0.009447998198001793\n",
      "train loss:0.03399218858827426\n",
      "train loss:0.029093504801917174\n",
      "train loss:0.013563414984907016\n",
      "train loss:0.02547261417249587\n",
      "train loss:0.0075321968923679015\n",
      "train loss:0.12341739580285427\n",
      "train loss:0.06387115032702191\n",
      "train loss:0.0248375648915913\n",
      "train loss:0.006850745544134438\n",
      "train loss:0.030057944315415672\n",
      "train loss:0.018381896420851723\n",
      "train loss:0.020027032250468486\n",
      "train loss:0.09279102584402606\n",
      "train loss:0.02924931275518841\n",
      "train loss:0.10150997861344084\n",
      "train loss:0.0018481841905626567\n",
      "train loss:0.015510120889704453\n",
      "train loss:0.030553599883992782\n",
      "train loss:0.03506329362214662\n",
      "train loss:0.05691142707630232\n",
      "train loss:0.02161926760906864\n",
      "train loss:0.010597453410512015\n",
      "train loss:0.023619598069295002\n",
      "train loss:0.011224137655397743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015605685831996919\n",
      "train loss:0.0264684512660385\n",
      "train loss:0.02336781663410706\n",
      "train loss:0.011004611059895466\n",
      "train loss:0.021422219244417645\n",
      "train loss:0.03602695404819679\n",
      "train loss:0.023269971659890757\n",
      "train loss:0.020122201205403666\n",
      "train loss:0.0343544351692218\n",
      "train loss:0.01755854655800791\n",
      "train loss:0.042585457156331524\n",
      "train loss:0.018931672464304102\n",
      "train loss:0.03163497856606874\n",
      "train loss:0.012625982586666395\n",
      "train loss:0.02557206396716243\n",
      "train loss:0.051437279865053774\n",
      "train loss:0.018725677756113637\n",
      "train loss:0.015713538100905835\n",
      "train loss:0.034553554504082616\n",
      "train loss:0.05757702849769573\n",
      "train loss:0.031199724784562538\n",
      "train loss:0.006086923911766802\n",
      "train loss:0.017654841046800613\n",
      "train loss:0.10763918570656746\n",
      "train loss:0.051286389502109654\n",
      "train loss:0.015158515256103422\n",
      "train loss:0.04274899292104461\n",
      "train loss:0.07715032259481418\n",
      "train loss:0.013798106009437752\n",
      "train loss:0.03147222084562551\n",
      "train loss:0.013316672393142244\n",
      "train loss:0.007734371720714998\n",
      "train loss:0.01568904090460757\n",
      "train loss:0.011041815773561456\n",
      "train loss:0.02385991971188794\n",
      "train loss:0.019847360902643652\n",
      "train loss:0.06879209207596443\n",
      "train loss:0.10552261608551992\n",
      "train loss:0.050283580415934115\n",
      "train loss:0.016861484022950644\n",
      "train loss:0.010949762656421067\n",
      "train loss:0.03164163180124777\n",
      "train loss:0.049538063662601356\n",
      "train loss:0.04128688341027268\n",
      "train loss:0.03592263520926389\n",
      "train loss:0.03811193630239141\n",
      "train loss:0.04315252268075022\n",
      "train loss:0.011853697332132294\n",
      "train loss:0.02683324829707569\n",
      "train loss:0.058986399581625146\n",
      "train loss:0.012607545327321674\n",
      "train loss:0.004961790061060165\n",
      "train loss:0.004712101092607173\n",
      "train loss:0.00969822962016722\n",
      "train loss:0.00912369324907552\n",
      "train loss:0.023393099361436444\n",
      "train loss:0.10552647298237475\n",
      "train loss:0.015328056206286064\n",
      "train loss:0.007674930985263495\n",
      "train loss:0.012119231281554977\n",
      "train loss:0.020781114736884324\n",
      "train loss:0.04182839372693536\n",
      "train loss:0.008150982340521095\n",
      "train loss:0.0065666954922443\n",
      "train loss:0.014861003567923999\n",
      "train loss:0.01504856980036248\n",
      "train loss:0.036898362793634766\n",
      "train loss:0.03146776766832237\n",
      "train loss:0.00969405317762724\n",
      "train loss:0.00879291103639744\n",
      "train loss:0.05710900213384322\n",
      "train loss:0.026119549827245556\n",
      "train loss:0.006652676858968897\n",
      "train loss:0.03327157572015475\n",
      "train loss:0.015031642478585412\n",
      "train loss:0.03737069475216473\n",
      "train loss:0.040147306633759074\n",
      "train loss:0.049705145372087346\n",
      "train loss:0.008099810263336869\n",
      "train loss:0.017403086147416272\n",
      "train loss:0.012925524044753991\n",
      "train loss:0.028929337107724752\n",
      "train loss:0.008570950799980171\n",
      "train loss:0.07242652851010999\n",
      "train loss:0.03981128112341179\n",
      "train loss:0.0199453837942276\n",
      "train loss:0.08730945572948844\n",
      "train loss:0.005861284497676634\n",
      "train loss:0.03788441377453413\n",
      "train loss:0.04415148167410189\n",
      "train loss:0.025402029687461636\n",
      "train loss:0.01141949138700463\n",
      "train loss:0.025614011439075247\n",
      "train loss:0.009707679819933635\n",
      "train loss:0.015751287240183823\n",
      "train loss:0.025843227310230435\n",
      "train loss:0.0056090747239091795\n",
      "train loss:0.009917219891756573\n",
      "=== epoch:6, train acc:0.984, test acc:0.984 ===\n",
      "train loss:0.006797876829913539\n",
      "train loss:0.012255839275329536\n",
      "train loss:0.025256273706930704\n",
      "train loss:0.02903183474892685\n",
      "train loss:0.031325899167471055\n",
      "train loss:0.0106143403085194\n",
      "train loss:0.01717939031630021\n",
      "train loss:0.01328780841677008\n",
      "train loss:0.0311781950577472\n",
      "train loss:0.040689014264488434\n",
      "train loss:0.02828997416861994\n",
      "train loss:0.015418980801689897\n",
      "train loss:0.010584812538374596\n",
      "train loss:0.006170922163823768\n",
      "train loss:0.01496283824097261\n",
      "train loss:0.018300279863041575\n",
      "train loss:0.016654949865332346\n",
      "train loss:0.022859877593514807\n",
      "train loss:0.0356702104429846\n",
      "train loss:0.03286468603689234\n",
      "train loss:0.022849385867376455\n",
      "train loss:0.011662985991818314\n",
      "train loss:0.025407413262437152\n",
      "train loss:0.035111183037485366\n",
      "train loss:0.033394423634328825\n",
      "train loss:0.060941396348809976\n",
      "train loss:0.014013658107093128\n",
      "train loss:0.03143734120957409\n",
      "train loss:0.018477813011217235\n",
      "train loss:0.024819149543474486\n",
      "train loss:0.004699362136012425\n",
      "train loss:0.016279685709301245\n",
      "train loss:0.012779556295422528\n",
      "train loss:0.02145214422709756\n",
      "train loss:0.04961156941849062\n",
      "train loss:0.023805887153564353\n",
      "train loss:0.03294567488951313\n",
      "train loss:0.03165956580172138\n",
      "train loss:0.014291979563422357\n",
      "train loss:0.012584382645458567\n",
      "train loss:0.006846027288016588\n",
      "train loss:0.022886409182919135\n",
      "train loss:0.020351020616106677\n",
      "train loss:0.007169923858749348\n",
      "train loss:0.05510862475416859\n",
      "train loss:0.022766001971946875\n",
      "train loss:0.005348114035657493\n",
      "train loss:0.030880617058049956\n",
      "train loss:0.019140512005929967\n",
      "train loss:0.011440174587551404\n",
      "train loss:0.009455012580842083\n",
      "train loss:0.05190888257110316\n",
      "train loss:0.02524670727364594\n",
      "train loss:0.0035820225774302367\n",
      "train loss:0.028193568890049328\n",
      "train loss:0.03859282993854038\n",
      "train loss:0.015564399539713081\n",
      "train loss:0.022087937135464218\n",
      "train loss:0.015550903885247437\n",
      "train loss:0.025558045981140542\n",
      "train loss:0.0035132334631029823\n",
      "train loss:0.013619958071847021\n",
      "train loss:0.008999104406264353\n",
      "train loss:0.012295804209023944\n",
      "train loss:0.003921683528482686\n",
      "train loss:0.05376830924097525\n",
      "train loss:0.03997037905649402\n",
      "train loss:0.020255849315071378\n",
      "train loss:0.04213536014095798\n",
      "train loss:0.011357033014480102\n",
      "train loss:0.008617299122477473\n",
      "train loss:0.04259813377261505\n",
      "train loss:0.012150674090831481\n",
      "train loss:0.013386633974490254\n",
      "train loss:0.013073861956083493\n",
      "train loss:0.03910691742276\n",
      "train loss:0.03165571148450279\n",
      "train loss:0.0535051177011677\n",
      "train loss:0.07704588124457797\n",
      "train loss:0.015382273898618182\n",
      "train loss:0.026685276995652013\n",
      "train loss:0.017325293751543795\n",
      "train loss:0.04664533008975741\n",
      "train loss:0.014988693823188284\n",
      "train loss:0.04336207916114872\n",
      "train loss:0.01944279909578701\n",
      "train loss:0.011843707621496375\n",
      "train loss:0.0608637562244088\n",
      "train loss:0.01938741422751203\n",
      "train loss:0.0328895034412058\n",
      "train loss:0.011553790441931677\n",
      "train loss:0.05867935730895657\n",
      "train loss:0.023215651439166513\n",
      "train loss:0.001472721691884085\n",
      "train loss:0.0038046316428650374\n",
      "train loss:0.020454208112221775\n",
      "train loss:0.022052999565367822\n",
      "train loss:0.02923449806409451\n",
      "train loss:0.056626103615508204\n",
      "train loss:0.03566954639302497\n",
      "train loss:0.02343206059695784\n",
      "train loss:0.008551337053628599\n",
      "train loss:0.03832501186842054\n",
      "train loss:0.011034401482951168\n",
      "train loss:0.01541223832719334\n",
      "train loss:0.008607478496323439\n",
      "train loss:0.012858653274478176\n",
      "train loss:0.021277770060802684\n",
      "train loss:0.050360545871408965\n",
      "train loss:0.003923993812910631\n",
      "train loss:0.013541135270513385\n",
      "train loss:0.026888949958722264\n",
      "train loss:0.02452156822232644\n",
      "train loss:0.01378320851602262\n",
      "train loss:0.12916778716247904\n",
      "train loss:0.006721218274041432\n",
      "train loss:0.045611001389206686\n",
      "train loss:0.03871822156834674\n",
      "train loss:0.03901103250097797\n",
      "train loss:0.06675458782837147\n",
      "train loss:0.014569225468448153\n",
      "train loss:0.009497658174489013\n",
      "train loss:0.011739865611670668\n",
      "train loss:0.019252755026114458\n",
      "train loss:0.011822892635145719\n",
      "train loss:0.09094761737693148\n",
      "train loss:0.011998514631005435\n",
      "train loss:0.037584063608446835\n",
      "train loss:0.030210610359440063\n",
      "train loss:0.03552427023234674\n",
      "train loss:0.00431718074237242\n",
      "train loss:0.026341277554156467\n",
      "train loss:0.02618431233869547\n",
      "train loss:0.050150636366650785\n",
      "train loss:0.021452259469767\n",
      "train loss:0.009354834902695626\n",
      "train loss:0.005407563540704758\n",
      "train loss:0.05617680404554786\n",
      "train loss:0.02057081643687845\n",
      "train loss:0.008760952541680106\n",
      "train loss:0.01127037534664031\n",
      "train loss:0.003104560570246356\n",
      "train loss:0.018691359809628317\n",
      "train loss:0.010966558976523497\n",
      "train loss:0.002780705850590784\n",
      "train loss:0.004596723967041903\n",
      "train loss:0.004426011360108652\n",
      "train loss:0.08707461119931117\n",
      "train loss:0.01348281418008403\n",
      "train loss:0.022414457491567657\n",
      "train loss:0.006164834895121168\n",
      "train loss:0.05002307212110967\n",
      "train loss:0.0203209757664101\n",
      "train loss:0.016847002191265857\n",
      "train loss:0.011719734104814649\n",
      "train loss:0.010985733016374795\n",
      "train loss:0.013082550275316813\n",
      "train loss:0.02099992524919189\n",
      "train loss:0.012222392023790399\n",
      "train loss:0.018972639661908052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011526581345386368\n",
      "train loss:0.02503380157223672\n",
      "train loss:0.039201457829751624\n",
      "train loss:0.015934628504494803\n",
      "train loss:0.012941782946856247\n",
      "train loss:0.03721461905794248\n",
      "train loss:0.09441787377225394\n",
      "train loss:0.011143936648100521\n",
      "train loss:0.02885711377170313\n",
      "train loss:0.012848545753469373\n",
      "train loss:0.01579448986350258\n",
      "train loss:0.0301365658402406\n",
      "train loss:0.037655010885946895\n",
      "train loss:0.029495667594738432\n",
      "train loss:0.015154140871256862\n",
      "train loss:0.009234417950505818\n",
      "train loss:0.007990963352978957\n",
      "train loss:0.06781420512857532\n",
      "train loss:0.037878446246850356\n",
      "train loss:0.009674065235273534\n",
      "train loss:0.008912175146421439\n",
      "train loss:0.0058399864653635\n",
      "train loss:0.02427905952117608\n",
      "train loss:0.0030822402585606277\n",
      "train loss:0.026613899496814045\n",
      "train loss:0.011365192917106012\n",
      "train loss:0.012339498764078756\n",
      "train loss:0.04681329931836127\n",
      "train loss:0.016399877668546926\n",
      "train loss:0.01634969063693947\n",
      "train loss:0.016562702832556765\n",
      "train loss:0.027599735007213168\n",
      "train loss:0.04495520658627219\n",
      "train loss:0.008322741911548286\n",
      "train loss:0.05058695227966952\n",
      "train loss:0.005798283212150042\n",
      "train loss:0.019986555951522038\n",
      "train loss:0.027462554817347412\n",
      "train loss:0.02352073893535288\n",
      "train loss:0.027160128434353666\n",
      "train loss:0.010073770025522793\n",
      "train loss:0.011519395128311018\n",
      "train loss:0.011907033678070975\n",
      "train loss:0.06725497749376566\n",
      "train loss:0.01181547732041607\n",
      "train loss:0.026791274083675147\n",
      "train loss:0.015989203953022658\n",
      "train loss:0.019322224275767585\n",
      "train loss:0.015316253801280998\n",
      "train loss:0.026417346586796845\n",
      "train loss:0.010836663941264894\n",
      "train loss:0.011702979382548868\n",
      "train loss:0.10639541581741435\n",
      "train loss:0.016592019470440204\n",
      "train loss:0.016593334922570292\n",
      "train loss:0.013303954013014017\n",
      "train loss:0.020442030821738944\n",
      "train loss:0.06638339470116851\n",
      "train loss:0.027533890821878394\n",
      "train loss:0.04049315556031905\n",
      "train loss:0.01945187721293295\n",
      "train loss:0.09065681471532366\n",
      "train loss:0.027088191605380604\n",
      "train loss:0.021638068960886866\n",
      "train loss:0.023593223384025322\n",
      "train loss:0.012219649012938021\n",
      "train loss:0.01646137244511972\n",
      "train loss:0.009661039984703034\n",
      "train loss:0.0075600860854084136\n",
      "train loss:0.04214434216233005\n",
      "train loss:0.012321949594980336\n",
      "train loss:0.007321364135167125\n",
      "train loss:0.023912938984113175\n",
      "train loss:0.05824107286574321\n",
      "train loss:0.016364576063820125\n",
      "train loss:0.05187644346993126\n",
      "train loss:0.023991457408794034\n",
      "train loss:0.013461978718618615\n",
      "train loss:0.03126682085543086\n",
      "train loss:0.013420749282618789\n",
      "train loss:0.004058998520841084\n",
      "train loss:0.04091491044713142\n",
      "train loss:0.01997214990700645\n",
      "train loss:0.04340883214167821\n",
      "train loss:0.017144372284430415\n",
      "train loss:0.007793788740801163\n",
      "train loss:0.012078389800486573\n",
      "train loss:0.015282274801707907\n",
      "train loss:0.008033858316524296\n",
      "train loss:0.021527441134665107\n",
      "train loss:0.04163525240454434\n",
      "train loss:0.10963565409824978\n",
      "train loss:0.008388418663555768\n",
      "train loss:0.03204066514580983\n",
      "train loss:0.009932861668150425\n",
      "train loss:0.01644842005709264\n",
      "train loss:0.011728889265228698\n",
      "train loss:0.024092245550465217\n",
      "train loss:0.017623938549452475\n",
      "train loss:0.07634640768155931\n",
      "train loss:0.017679484893571813\n",
      "train loss:0.0325874109972079\n",
      "train loss:0.027845286132586425\n",
      "train loss:0.026479517160537595\n",
      "train loss:0.038725692803649236\n",
      "train loss:0.01092248591950247\n",
      "train loss:0.01754463502426439\n",
      "train loss:0.02088985489091584\n",
      "train loss:0.022017256468544993\n",
      "train loss:0.03152892645659905\n",
      "train loss:0.03244026958779885\n",
      "train loss:0.025952758935257683\n",
      "train loss:0.01642501383907991\n",
      "train loss:0.06741745932092004\n",
      "train loss:0.030256227484009655\n",
      "train loss:0.013534858277779959\n",
      "train loss:0.015399782147070712\n",
      "train loss:0.006066616519329493\n",
      "train loss:0.027226176048547605\n",
      "train loss:0.00584910284710194\n",
      "train loss:0.005040274895592483\n",
      "train loss:0.003951637834683183\n",
      "train loss:0.016930197060753643\n",
      "train loss:0.01615221234267362\n",
      "train loss:0.04815364719829654\n",
      "train loss:0.008196074109427824\n",
      "train loss:0.03940533832782096\n",
      "train loss:0.049850938348330945\n",
      "train loss:0.004879905092988451\n",
      "train loss:0.051089108702762\n",
      "train loss:0.011806713170990748\n",
      "train loss:0.08293933240716282\n",
      "train loss:0.01885563478344006\n",
      "train loss:0.007679889887710887\n",
      "train loss:0.012059930570436988\n",
      "train loss:0.005471296177567134\n",
      "train loss:0.013743196981253154\n",
      "train loss:0.08815987027849839\n",
      "train loss:0.05351022904779413\n",
      "train loss:0.006282533580863179\n",
      "train loss:0.019113676874005964\n",
      "train loss:0.00467256968871816\n",
      "train loss:0.012655589538350992\n",
      "train loss:0.03639225025612101\n",
      "train loss:0.05707513381170973\n",
      "train loss:0.023408247407330426\n",
      "train loss:0.08296102737016132\n",
      "train loss:0.009233337517737696\n",
      "train loss:0.007142065739261624\n",
      "train loss:0.08104583427510292\n",
      "train loss:0.17701323944252775\n",
      "train loss:0.03524434618805036\n",
      "train loss:0.05277483508921912\n",
      "train loss:0.010139727752408702\n",
      "train loss:0.011422911228402189\n",
      "train loss:0.008640574641288664\n",
      "train loss:0.01342411218083302\n",
      "train loss:0.042351368944699874\n",
      "train loss:0.0462578356818266\n",
      "train loss:0.017745638177110085\n",
      "train loss:0.023548182823397937\n",
      "train loss:0.01726466657786735\n",
      "train loss:0.011073750001480132\n",
      "train loss:0.01936533099910784\n",
      "train loss:0.022827665978763335\n",
      "train loss:0.016182594161944855\n",
      "train loss:0.00966774450040022\n",
      "train loss:0.013866597457947756\n",
      "train loss:0.027479217005828557\n",
      "train loss:0.011680100059301734\n",
      "train loss:0.02885992155395251\n",
      "train loss:0.017319910043455643\n",
      "train loss:0.05610602222818473\n",
      "train loss:0.003997239470720042\n",
      "train loss:0.021932079958921786\n",
      "train loss:0.004872831613313201\n",
      "train loss:0.015096761143949453\n",
      "train loss:0.01147538758158016\n",
      "train loss:0.011532039211295208\n",
      "train loss:0.01265347624828776\n",
      "train loss:0.05895510520695794\n",
      "train loss:0.005819909583387415\n",
      "train loss:0.07038881306542029\n",
      "train loss:0.012226524041017437\n",
      "train loss:0.01254476365253907\n",
      "train loss:0.002711601544035071\n",
      "train loss:0.03568678562164964\n",
      "train loss:0.05183874877465366\n",
      "train loss:0.014205207919906941\n",
      "train loss:0.014754239872009755\n",
      "train loss:0.025659341480655483\n",
      "train loss:0.029704819887693797\n",
      "train loss:0.008302777890012072\n",
      "train loss:0.017295558910829803\n",
      "train loss:0.014798872928853153\n",
      "train loss:0.01722067841575996\n",
      "train loss:0.019454898750373296\n",
      "train loss:0.02240143315290536\n",
      "train loss:0.04699804547282166\n",
      "train loss:0.012388925177328923\n",
      "train loss:0.014423949042670853\n",
      "train loss:0.012694455238226227\n",
      "train loss:0.02652783313876893\n",
      "train loss:0.013359120742092927\n",
      "train loss:0.002945455059043906\n",
      "train loss:0.005559603846283806\n",
      "train loss:0.018400678179641382\n",
      "train loss:0.08090617551949521\n",
      "train loss:0.018338198122532855\n",
      "train loss:0.005633277295847798\n",
      "train loss:0.01041014483318388\n",
      "train loss:0.02559494601791092\n",
      "train loss:0.0018919248998405264\n",
      "train loss:0.01391508461367481\n",
      "train loss:0.012380462071913158\n",
      "train loss:0.014071277374176181\n",
      "train loss:0.008204037545347228\n",
      "train loss:0.011894588219656815\n",
      "train loss:0.03520180134897192\n",
      "train loss:0.09798465391427552\n",
      "train loss:0.011480462860351892\n",
      "train loss:0.08660940321714601\n",
      "train loss:0.013002621649436321\n",
      "train loss:0.003939095750205895\n",
      "train loss:0.017337356611083973\n",
      "train loss:0.06707747746951258\n",
      "train loss:0.044214757344472125\n",
      "train loss:0.01724858317156515\n",
      "train loss:0.03416913731282955\n",
      "train loss:0.013925929602851743\n",
      "train loss:0.07807795829054737\n",
      "train loss:0.02347519377390913\n",
      "train loss:0.006423520136078077\n",
      "train loss:0.02126681568022756\n",
      "train loss:0.01416094523757405\n",
      "train loss:0.02900454152709429\n",
      "train loss:0.007395675588199917\n",
      "train loss:0.011555071066859861\n",
      "train loss:0.00879244861041386\n",
      "train loss:0.02032427658336527\n",
      "train loss:0.028218591797151846\n",
      "train loss:0.0065188339899754245\n",
      "train loss:0.003106309292138929\n",
      "train loss:0.0035852631528771163\n",
      "train loss:0.08957452517765896\n",
      "train loss:0.04464869827244005\n",
      "train loss:0.007410539059117098\n",
      "train loss:0.010779952896730158\n",
      "train loss:0.020615619432418793\n",
      "train loss:0.006011036543103428\n",
      "train loss:0.02046057603544583\n",
      "train loss:0.024451437517345163\n",
      "train loss:0.023823452594751528\n",
      "train loss:0.024495277828310357\n",
      "train loss:0.0792253423519488\n",
      "train loss:0.004796963863541804\n",
      "train loss:0.0021071392646972655\n",
      "train loss:0.007770720613733104\n",
      "train loss:0.05176327966407152\n",
      "train loss:0.011927575599761809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009828206082710214\n",
      "train loss:0.014842452652653278\n",
      "train loss:0.006874268824366199\n",
      "train loss:0.005472986658873678\n",
      "train loss:0.06029793449805093\n",
      "train loss:0.0096573208417218\n",
      "train loss:0.11645526369593708\n",
      "train loss:0.015919578621410885\n",
      "train loss:0.16081971150026875\n",
      "train loss:0.009696602099093345\n",
      "train loss:0.08895885324989339\n",
      "train loss:0.033216408949373485\n",
      "train loss:0.009800144117308956\n",
      "train loss:0.003410750034398991\n",
      "train loss:0.044330069065241444\n",
      "train loss:0.025044814400732692\n",
      "train loss:0.006245466266146594\n",
      "train loss:0.027444655905330025\n",
      "train loss:0.027098108480654092\n",
      "train loss:0.01831203065676404\n",
      "train loss:0.020871754348546764\n",
      "train loss:0.04011967536741638\n",
      "train loss:0.00567078118753717\n",
      "train loss:0.018693600688025357\n",
      "train loss:0.04093564725719437\n",
      "train loss:0.03509186830118815\n",
      "train loss:0.021432257054288927\n",
      "train loss:0.07259257132651264\n",
      "train loss:0.025545882954976794\n",
      "train loss:0.014585358584449211\n",
      "train loss:0.0793798748118613\n",
      "train loss:0.026385068236077926\n",
      "train loss:0.05440455455369991\n",
      "train loss:0.016779707632384733\n",
      "train loss:0.023221632805466953\n",
      "train loss:0.0015939432690176124\n",
      "train loss:0.00994313172494559\n",
      "train loss:0.017748296253060843\n",
      "train loss:0.013954633818977748\n",
      "train loss:0.005688890743509079\n",
      "train loss:0.028703565324076804\n",
      "train loss:0.011486675352666143\n",
      "train loss:0.014690669936209459\n",
      "train loss:0.00889113078144129\n",
      "train loss:0.007950695083529498\n",
      "train loss:0.012325427656253878\n",
      "train loss:0.06652240841537554\n",
      "train loss:0.006382042849646943\n",
      "train loss:0.10167247782554878\n",
      "train loss:0.0038558963293300135\n",
      "train loss:0.009623754547492537\n",
      "train loss:0.006352148103925851\n",
      "train loss:0.061628769367926814\n",
      "train loss:0.024637125701679044\n",
      "train loss:0.012304478886124608\n",
      "train loss:0.017037044954989325\n",
      "train loss:0.06508334712550543\n",
      "train loss:0.028601257195542237\n",
      "train loss:0.02529379642239794\n",
      "train loss:0.00417017704637844\n",
      "train loss:0.0039212910587048625\n",
      "train loss:0.012703188080613137\n",
      "train loss:0.0126144619067326\n",
      "train loss:0.010850611662348844\n",
      "train loss:0.01146443202929364\n",
      "train loss:0.008883775540911439\n",
      "train loss:0.043505150851777\n",
      "train loss:0.018737539992877958\n",
      "train loss:0.017052688547252177\n",
      "train loss:0.004165870614846013\n",
      "train loss:0.009282434938672434\n",
      "train loss:0.013531779041807444\n",
      "train loss:0.009364897637601672\n",
      "train loss:0.02029879010195269\n",
      "train loss:0.0297559084669361\n",
      "train loss:0.008363552419644964\n",
      "train loss:0.006536754805952096\n",
      "train loss:0.011492807301862598\n",
      "train loss:0.020190773170594888\n",
      "train loss:0.018226285525669392\n",
      "train loss:0.05608071712005838\n",
      "train loss:0.0305491259112395\n",
      "train loss:0.011163127930073385\n",
      "train loss:0.014496917526714434\n",
      "train loss:0.014473996210192288\n",
      "train loss:0.033190446491351194\n",
      "train loss:0.011730387841032147\n",
      "train loss:0.006781323735558087\n",
      "train loss:0.03054965327831668\n",
      "train loss:0.014155022840609165\n",
      "train loss:0.06926938218351954\n",
      "train loss:0.00865237170538384\n",
      "train loss:0.00492377980330067\n",
      "train loss:0.007599610538578574\n",
      "train loss:0.10631056763123742\n",
      "train loss:0.023667853742093636\n",
      "train loss:0.020906348281386076\n",
      "train loss:0.012630643065996991\n",
      "train loss:0.012033635714858874\n",
      "train loss:0.01901081681745801\n",
      "train loss:0.015714705970967132\n",
      "train loss:0.06103244835536574\n",
      "train loss:0.026396180851998362\n",
      "train loss:0.008162965669446964\n",
      "train loss:0.029647465387810427\n",
      "train loss:0.0076985042195935206\n",
      "train loss:0.015214393808729531\n",
      "train loss:0.07151864354863167\n",
      "train loss:0.007844624078496542\n",
      "train loss:0.0075610799162825594\n",
      "train loss:0.018627790593536826\n",
      "train loss:0.01986622070556667\n",
      "train loss:0.007891465417894466\n",
      "train loss:0.03806741864748669\n",
      "train loss:0.004171110138886059\n",
      "train loss:0.05729820534918237\n",
      "train loss:0.02398267920973291\n",
      "train loss:0.003671175616402886\n",
      "train loss:0.025859771619127826\n",
      "train loss:0.011088749814287209\n",
      "train loss:0.028610369512279802\n",
      "train loss:0.04114363022203451\n",
      "train loss:0.004134398710542157\n",
      "train loss:0.031574802466852014\n",
      "train loss:0.009384526242211245\n",
      "train loss:0.04819967072099379\n",
      "train loss:0.0066026504440862945\n",
      "train loss:0.03495121874657415\n",
      "train loss:0.012814021422596735\n",
      "train loss:0.005961370584087947\n",
      "train loss:0.006090695250455189\n",
      "train loss:0.006145852547406136\n",
      "train loss:0.045752053379430065\n",
      "train loss:0.014014752806562785\n",
      "train loss:0.012700449759163662\n",
      "train loss:0.020893263056672856\n",
      "train loss:0.019703853007376836\n",
      "train loss:0.059747591859492036\n",
      "train loss:0.010285474803731421\n",
      "train loss:0.016967642851133696\n",
      "train loss:0.01513154903687057\n",
      "train loss:0.010044584070959383\n",
      "train loss:0.019310315808950873\n",
      "train loss:0.09994663373094369\n",
      "train loss:0.029216505052031726\n",
      "train loss:0.006240573747021178\n",
      "train loss:0.010587383052932543\n",
      "train loss:0.018433117605053066\n",
      "train loss:0.015669073608263022\n",
      "train loss:0.01041515165002502\n",
      "train loss:0.025113383550698462\n",
      "train loss:0.009119733673376549\n",
      "train loss:0.028874873769583212\n",
      "train loss:0.01277144292521008\n",
      "train loss:0.032546228137903366\n",
      "train loss:0.050595708119998924\n",
      "train loss:0.016767188940202554\n",
      "train loss:0.014093434057606552\n",
      "train loss:0.006361594700797013\n",
      "train loss:0.01960696412577506\n",
      "train loss:0.01333331105953954\n",
      "train loss:0.037290059302354114\n",
      "train loss:0.008920480534972654\n",
      "train loss:0.045516167178086625\n",
      "train loss:0.0013255150979788245\n",
      "train loss:0.021359647000736306\n",
      "train loss:0.00889174007788251\n",
      "train loss:0.01178022137311857\n",
      "train loss:0.03314762503854188\n",
      "train loss:0.015077127883373004\n",
      "train loss:0.02234464689960395\n",
      "train loss:0.007831312563197499\n",
      "train loss:0.006155713128170086\n",
      "train loss:0.0691811348878888\n",
      "train loss:0.018203036914269385\n",
      "train loss:0.017326891084957594\n",
      "train loss:0.0033851018312029742\n",
      "train loss:0.011518320286917967\n",
      "train loss:0.01353781510668684\n",
      "train loss:0.011435053465061788\n",
      "=== epoch:7, train acc:0.99, test acc:0.982 ===\n",
      "train loss:0.017319088616112935\n",
      "train loss:0.015533013934688028\n",
      "train loss:0.006078324917633838\n",
      "train loss:0.013652643643596338\n",
      "train loss:0.007184869587949901\n",
      "train loss:0.021118027362024207\n",
      "train loss:0.014023331707716646\n",
      "train loss:0.015956129600027777\n",
      "train loss:0.014951310839468561\n",
      "train loss:0.003406788459064937\n",
      "train loss:0.008244098799958514\n",
      "train loss:0.08995195325898868\n",
      "train loss:0.027280768240702812\n",
      "train loss:0.01693682424929904\n",
      "train loss:0.003506638315749919\n",
      "train loss:0.03155265582070133\n",
      "train loss:0.017386967098076175\n",
      "train loss:0.013070671250090656\n",
      "train loss:0.010068298220196021\n",
      "train loss:0.02272583580759506\n",
      "train loss:0.025433601430774288\n",
      "train loss:0.017085612370850448\n",
      "train loss:0.0024717958115972917\n",
      "train loss:0.006168440202526748\n",
      "train loss:0.003940263134441071\n",
      "train loss:0.011918094172053148\n",
      "train loss:0.0611353299903789\n",
      "train loss:0.006218574281941041\n",
      "train loss:0.013798580875833875\n",
      "train loss:0.013563609964617675\n",
      "train loss:0.05378593032606964\n",
      "train loss:0.021100273297315696\n",
      "train loss:0.017082147202471844\n",
      "train loss:0.027595484076141208\n",
      "train loss:0.006136081143863587\n",
      "train loss:0.004737943778076688\n",
      "train loss:0.005308575381002089\n",
      "train loss:0.016075575190682867\n",
      "train loss:0.0052489880288292545\n",
      "train loss:0.006357473309042488\n",
      "train loss:0.055344099627413865\n",
      "train loss:0.027721722060925724\n",
      "train loss:0.005075792963775126\n",
      "train loss:0.013251420021245752\n",
      "train loss:0.007231183523241352\n",
      "train loss:0.024744006032026533\n",
      "train loss:0.0027217679888190023\n",
      "train loss:0.00912255868527033\n",
      "train loss:0.029473813931119492\n",
      "train loss:0.021483389731869557\n",
      "train loss:0.009766626665258089\n",
      "train loss:0.02024462462816059\n",
      "train loss:0.014926294793971727\n",
      "train loss:0.018792871490235542\n",
      "train loss:0.002987486205405869\n",
      "train loss:0.010970899804581413\n",
      "train loss:0.01988076230711639\n",
      "train loss:0.06103509735813807\n",
      "train loss:0.010864448898355144\n",
      "train loss:0.008363248924164433\n",
      "train loss:0.004007063907952245\n",
      "train loss:0.08704298708862432\n",
      "train loss:0.01569663416898072\n",
      "train loss:0.02940040557709712\n",
      "train loss:0.005347282689583057\n",
      "train loss:0.033929291313411845\n",
      "train loss:0.0709795524728589\n",
      "train loss:0.014160120921761655\n",
      "train loss:0.004717085603476266\n",
      "train loss:0.009026741925018211\n",
      "train loss:0.011844130142902962\n",
      "train loss:0.011662207180943523\n",
      "train loss:0.015203343683000406\n",
      "train loss:0.06885147007704626\n",
      "train loss:0.016814727736460047\n",
      "train loss:0.05266995412084021\n",
      "train loss:0.01625167105009443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04097114829436871\n",
      "train loss:0.04393833931458158\n",
      "train loss:0.005006531942799138\n",
      "train loss:0.027579456131820314\n",
      "train loss:0.03061462494414307\n",
      "train loss:0.003101260825482732\n",
      "train loss:0.003998334066427071\n",
      "train loss:0.06376498881492348\n",
      "train loss:0.01775436589900202\n",
      "train loss:0.006025355354374773\n",
      "train loss:0.004659711110145284\n",
      "train loss:0.002649614524600199\n",
      "train loss:0.028289843088451776\n",
      "train loss:0.019568256569891994\n",
      "train loss:0.01775363101473923\n",
      "train loss:0.044188273520897076\n",
      "train loss:0.07732454428871245\n",
      "train loss:0.026843491916101025\n",
      "train loss:0.016089625067318866\n",
      "train loss:0.011468934136518345\n",
      "train loss:0.010356761688788216\n",
      "train loss:0.01681481718252645\n",
      "train loss:0.0037311549101158984\n",
      "train loss:0.022695859401149564\n",
      "train loss:0.015215972534703567\n",
      "train loss:0.0030362014550306556\n",
      "train loss:0.0025463876054887813\n",
      "train loss:0.0044373646541152455\n",
      "train loss:0.05378788548516946\n",
      "train loss:0.013146686399165325\n",
      "train loss:0.007378894398414597\n",
      "train loss:0.001407959465936267\n",
      "train loss:0.005671351786226297\n",
      "train loss:0.027755473192542818\n",
      "train loss:0.018834513705583717\n",
      "train loss:0.011305262918538677\n",
      "train loss:0.004365970313426844\n",
      "train loss:0.06082516842489729\n",
      "train loss:0.014375709701769877\n",
      "train loss:0.012911629653581258\n",
      "train loss:0.023945074705048988\n",
      "train loss:0.005600844196278091\n",
      "train loss:0.014048610345559478\n",
      "train loss:0.015080566311497292\n",
      "train loss:0.023062734107067735\n",
      "train loss:0.00924620826227915\n",
      "train loss:0.0029551976524008054\n",
      "train loss:0.03269161619500902\n",
      "train loss:0.026526925880195572\n",
      "train loss:0.02064892422833837\n",
      "train loss:0.03130768597608241\n",
      "train loss:0.02790961688203283\n",
      "train loss:0.02078089296450529\n",
      "train loss:0.016013192055469354\n",
      "train loss:0.011590852610395198\n",
      "train loss:0.011174619499665512\n",
      "train loss:0.012937725349512296\n",
      "train loss:0.03270185364411003\n",
      "train loss:0.0030835742117390074\n",
      "train loss:0.020033013054192726\n",
      "train loss:0.06720567217746816\n",
      "train loss:0.018891605565299587\n",
      "train loss:0.031009670528376002\n",
      "train loss:0.009865583360287098\n",
      "train loss:0.011747990571531855\n",
      "train loss:0.01342275552289537\n",
      "train loss:0.0346188275176185\n",
      "train loss:0.015796119065401414\n",
      "train loss:0.004005130983447673\n",
      "train loss:0.02415014994824537\n",
      "train loss:0.017152805258899916\n",
      "train loss:0.1669569371386452\n",
      "train loss:0.00853046523998548\n",
      "train loss:0.04221813841984798\n",
      "train loss:0.013234655888436222\n",
      "train loss:0.011557031183788308\n",
      "train loss:0.07814449422801191\n",
      "train loss:0.012711415865644981\n",
      "train loss:0.00623536508506501\n",
      "train loss:0.07449352017154105\n",
      "train loss:0.01815289358811995\n",
      "train loss:0.006740810065869081\n",
      "train loss:0.00953199239454041\n",
      "train loss:0.008822137814433303\n",
      "train loss:0.024731215504245497\n",
      "train loss:0.009689950163205311\n",
      "train loss:0.017603804276453867\n",
      "train loss:0.14208726404285524\n",
      "train loss:0.002261334735967596\n",
      "train loss:0.0059618100091696205\n",
      "train loss:0.006888442529845532\n",
      "train loss:0.010694150386600154\n",
      "train loss:0.0027610566906870354\n",
      "train loss:0.09009869536265055\n",
      "train loss:0.06132688855094097\n",
      "train loss:0.05093159453944161\n",
      "train loss:0.0045387398595791\n",
      "train loss:0.01137872263459508\n",
      "train loss:0.0026277861719850824\n",
      "train loss:0.009201840635702473\n",
      "train loss:0.1117824282539589\n",
      "train loss:0.010997548808377246\n",
      "train loss:0.007222816938992468\n",
      "train loss:0.01615473156967439\n",
      "train loss:0.02238560742630233\n",
      "train loss:0.032290543915782864\n",
      "train loss:0.017609336385101912\n",
      "train loss:0.021950119171566747\n",
      "train loss:0.01685137384549124\n",
      "train loss:0.00464711196812661\n",
      "train loss:0.025854988654735456\n",
      "train loss:0.011419242879923826\n",
      "train loss:0.008321052840918882\n",
      "train loss:0.028018285319249735\n",
      "train loss:0.01264241511906898\n",
      "train loss:0.062477263259884494\n",
      "train loss:0.044437039712418754\n",
      "train loss:0.009662652088961521\n",
      "train loss:0.0020944127710626815\n",
      "train loss:0.01826206609708211\n",
      "train loss:0.07713216295377057\n",
      "train loss:0.015606853191599055\n",
      "train loss:0.020346494222306298\n",
      "train loss:0.01374623177171487\n",
      "train loss:0.03524511866339752\n",
      "train loss:0.036093291084389294\n",
      "train loss:0.01270048469395324\n",
      "train loss:0.013932873177198341\n",
      "train loss:0.012580809865206053\n",
      "train loss:0.006919496994777126\n",
      "train loss:0.046867892007352155\n",
      "train loss:0.007471766773499403\n",
      "train loss:0.011540443523675647\n",
      "train loss:0.00559441423514693\n",
      "train loss:0.023818664683531162\n",
      "train loss:0.007733204515766681\n",
      "train loss:0.004210593580151553\n",
      "train loss:0.013636789997033025\n",
      "train loss:0.005361716925851871\n",
      "train loss:0.022497845722358738\n",
      "train loss:0.031312706169657215\n",
      "train loss:0.0056736355105685655\n",
      "train loss:0.007722939523318945\n",
      "train loss:0.01998542146893858\n",
      "train loss:0.011925361698907571\n",
      "train loss:0.007539540146396068\n",
      "train loss:0.05116194021446214\n",
      "train loss:0.005534230334387381\n",
      "train loss:0.036905070702015735\n",
      "train loss:0.004069438494982806\n",
      "train loss:0.03350074954738822\n",
      "train loss:0.011741943239405625\n",
      "train loss:0.08326217234022282\n",
      "train loss:0.038904351465760045\n",
      "train loss:0.03335881222037001\n",
      "train loss:0.01929832268445516\n",
      "train loss:0.025062836721988006\n",
      "train loss:0.004238772833556746\n",
      "train loss:0.014278966119613889\n",
      "train loss:0.032916228300157294\n",
      "train loss:0.0060128581190808765\n",
      "train loss:0.0134865071214354\n",
      "train loss:0.010693451578115267\n",
      "train loss:0.0031284283685279117\n",
      "train loss:0.009545084511826311\n",
      "train loss:0.023760475980480075\n",
      "train loss:0.010817797136285476\n",
      "train loss:0.008867625781096768\n",
      "train loss:0.027412088800972477\n",
      "train loss:0.015179311244641638\n",
      "train loss:0.042120996392167494\n",
      "train loss:0.02082412920046714\n",
      "train loss:0.01586690960949829\n",
      "train loss:0.036208156742643945\n",
      "train loss:0.008005877828583892\n",
      "train loss:0.013178919460171929\n",
      "train loss:0.020194582519864845\n",
      "train loss:0.007318344617080618\n",
      "train loss:0.005798847299851904\n",
      "train loss:0.025131369686263616\n",
      "train loss:0.004750312153191324\n",
      "train loss:0.03838054884333658\n",
      "train loss:0.036937174935060636\n",
      "train loss:0.022383176216469097\n",
      "train loss:0.010570484362725244\n",
      "train loss:0.01403237207706743\n",
      "train loss:0.008852777784144639\n",
      "train loss:0.004343626399519537\n",
      "train loss:0.001070625462652053\n",
      "train loss:0.011378264985751015\n",
      "train loss:0.014331931939039486\n",
      "train loss:0.0025939119783926507\n",
      "train loss:0.01156076776926448\n",
      "train loss:0.0033158735569142907\n",
      "train loss:0.009053979344535012\n",
      "train loss:0.013257760539248717\n",
      "train loss:0.020193579963675153\n",
      "train loss:0.00962095150710598\n",
      "train loss:0.0030624422776903016\n",
      "train loss:0.0050782609718528614\n",
      "train loss:0.006801406163496029\n",
      "train loss:0.01830911573209666\n",
      "train loss:0.006221612373562946\n",
      "train loss:0.0053269402488840545\n",
      "train loss:0.009388233769869452\n",
      "train loss:0.004956617344637819\n",
      "train loss:0.01935476241672481\n",
      "train loss:0.034435009847676605\n",
      "train loss:0.0030404727815993636\n",
      "train loss:0.013821725215136504\n",
      "train loss:0.004340125299007867\n",
      "train loss:0.011611847138844366\n",
      "train loss:0.007463791328768281\n",
      "train loss:0.001649568744706264\n",
      "train loss:0.0363180125649566\n",
      "train loss:0.019135753547974012\n",
      "train loss:0.02167025222131707\n",
      "train loss:0.021554981855826116\n",
      "train loss:0.0074280302734376445\n",
      "train loss:0.04403572112503352\n",
      "train loss:0.01546154098591081\n",
      "train loss:0.019670036947392538\n",
      "train loss:0.004529264295539607\n",
      "train loss:0.009750621438687058\n",
      "train loss:0.006499995966124078\n",
      "train loss:0.010700389473579907\n",
      "train loss:0.018884083662712912\n",
      "train loss:0.027156494179936007\n",
      "train loss:0.0013444428609233313\n",
      "train loss:0.015112230275925544\n",
      "train loss:0.00481913520552939\n",
      "train loss:0.0018255344702957088\n",
      "train loss:0.010696159176555387\n",
      "train loss:0.015656098401551636\n",
      "train loss:0.058671529238348515\n",
      "train loss:0.012850536730640525\n",
      "train loss:0.022755970555216287\n",
      "train loss:0.024932747178232975\n",
      "train loss:0.005585576421478351\n",
      "train loss:0.0053924908771151026\n",
      "train loss:0.023447476512091385\n",
      "train loss:0.018759409150316698\n",
      "train loss:0.007331297494660095\n",
      "train loss:0.005977492671786776\n",
      "train loss:0.025933471631411912\n",
      "train loss:0.010716976730892456\n",
      "train loss:0.11988405854763647\n",
      "train loss:0.0028825124162998234\n",
      "train loss:0.05100636481025139\n",
      "train loss:0.009248523852357067\n",
      "train loss:0.021145890462302495\n",
      "train loss:0.006311477720618796\n",
      "train loss:0.0031276534243233813\n",
      "train loss:0.0095730829611489\n",
      "train loss:0.06085036990166817\n",
      "train loss:0.005480982575347454\n",
      "train loss:0.0032906418603679067\n",
      "train loss:0.06173692215028656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007999633489846754\n",
      "train loss:0.006063720618276214\n",
      "train loss:0.008218190949205088\n",
      "train loss:0.019315477728866996\n",
      "train loss:0.0036015759507241445\n",
      "train loss:0.04536517897331124\n",
      "train loss:0.03600427155656575\n",
      "train loss:0.02403176670568235\n",
      "train loss:0.006143335914286292\n",
      "train loss:0.015971848238313754\n",
      "train loss:0.023110834788370404\n",
      "train loss:0.008365847677770811\n",
      "train loss:0.02419423811393814\n",
      "train loss:0.08629376223086219\n",
      "train loss:0.006505127664885386\n",
      "train loss:0.028965635341381527\n",
      "train loss:0.0032921760025534947\n",
      "train loss:0.005487071155404022\n",
      "train loss:0.06262069565769139\n",
      "train loss:0.010893259026911043\n",
      "train loss:0.0018913441637587944\n",
      "train loss:0.015863508882188525\n",
      "train loss:0.01764022248353629\n",
      "train loss:0.016039285632463384\n",
      "train loss:0.017401315798141723\n",
      "train loss:0.01089493006537798\n",
      "train loss:0.07362282386591651\n",
      "train loss:0.01302755852807512\n",
      "train loss:0.0426168947158408\n",
      "train loss:0.030802638884208658\n",
      "train loss:0.020272132308306507\n",
      "train loss:0.046651975719583946\n",
      "train loss:0.014637819309089632\n",
      "train loss:0.027441559399729212\n",
      "train loss:0.02630068346261636\n",
      "train loss:0.014279920655833596\n",
      "train loss:0.020613524047090815\n",
      "train loss:0.02546898947351384\n",
      "train loss:0.01269854907398574\n",
      "train loss:0.01850578809571611\n",
      "train loss:0.020383317273847634\n",
      "train loss:0.017301254622443106\n",
      "train loss:0.011811400399573927\n",
      "train loss:0.022442399033137602\n",
      "train loss:0.009487437324282068\n",
      "train loss:0.03292260604340882\n",
      "train loss:0.020667429693240456\n",
      "train loss:0.006255464423741061\n",
      "train loss:0.036911127516135483\n",
      "train loss:0.022770483619957243\n",
      "train loss:0.01778986158872261\n",
      "train loss:0.0040049334313575595\n",
      "train loss:0.0055505624170717445\n",
      "train loss:0.022351080111341712\n",
      "train loss:0.008231376628531952\n",
      "train loss:0.009901171296968747\n",
      "train loss:0.0542699795604191\n",
      "train loss:0.052958575008308445\n",
      "train loss:0.03320844748234085\n",
      "train loss:0.026393322628765946\n",
      "train loss:0.024337511809473744\n",
      "train loss:0.05449922768748898\n",
      "train loss:0.00847368205045876\n",
      "train loss:0.008350527754721919\n",
      "train loss:0.005517634134648789\n",
      "train loss:0.03960460417083339\n",
      "train loss:0.002795714946103367\n",
      "train loss:0.002258651755349229\n",
      "train loss:0.0040944481297192645\n",
      "train loss:0.017966219550648217\n",
      "train loss:0.08418951424909034\n",
      "train loss:0.02272831276029178\n",
      "train loss:0.018129567034972597\n",
      "train loss:0.031742081658102474\n",
      "train loss:0.005837462805415024\n",
      "train loss:0.007811176808875347\n",
      "train loss:0.008933009002871332\n",
      "train loss:0.013420901182473532\n",
      "train loss:0.011686192101758554\n",
      "train loss:0.006756138644803681\n",
      "train loss:0.04115401891328577\n",
      "train loss:0.001657696112818108\n",
      "train loss:0.007254054045844494\n",
      "train loss:0.015110570893036981\n",
      "train loss:0.024730681573133663\n",
      "train loss:0.08313732785829522\n",
      "train loss:0.0627995240034046\n",
      "train loss:0.008398275914187571\n",
      "train loss:0.029326774894440688\n",
      "train loss:0.017173446932883217\n",
      "train loss:0.032405314506440075\n",
      "train loss:0.011733960321935999\n",
      "train loss:0.020561758853284436\n",
      "train loss:0.008332670845149454\n",
      "train loss:0.036801838608248025\n",
      "train loss:0.09288234018871576\n",
      "train loss:0.019513566068689266\n",
      "train loss:0.013902366531805176\n",
      "train loss:0.01955881505296379\n",
      "train loss:0.019234857701187734\n",
      "train loss:0.009875017587869454\n",
      "train loss:0.023128041183549032\n",
      "train loss:0.02841516827748877\n",
      "train loss:0.04807389471969465\n",
      "train loss:0.016615937338731245\n",
      "train loss:0.09795240949758086\n",
      "train loss:0.03213916154907135\n",
      "train loss:0.02270651531794987\n",
      "train loss:0.03639207816901734\n",
      "train loss:0.010242056625102448\n",
      "train loss:0.04897496687475936\n",
      "train loss:0.008539120635611136\n",
      "train loss:0.006677737847065995\n",
      "train loss:0.008613841762410753\n",
      "train loss:0.019726387480289553\n",
      "train loss:0.01705996071100087\n",
      "train loss:0.009428189105816519\n",
      "train loss:0.029905876662070886\n",
      "train loss:0.006103326703917297\n",
      "train loss:0.023981920700699825\n",
      "train loss:0.057559962894139866\n",
      "train loss:0.022809049439285987\n",
      "train loss:0.0054957227918109855\n",
      "train loss:0.004247372207990146\n",
      "train loss:0.02596906902956082\n",
      "train loss:0.02421239328898522\n",
      "train loss:0.016417629997933347\n",
      "train loss:0.003335236177861102\n",
      "train loss:0.04078408389530855\n",
      "train loss:0.0024258373955966814\n",
      "train loss:0.01161860094345806\n",
      "train loss:0.0015269983047704757\n",
      "train loss:0.007228041681984302\n",
      "train loss:0.06429575734274616\n",
      "train loss:0.04443499461993799\n",
      "train loss:0.022585826380489227\n",
      "train loss:0.0051572830810556755\n",
      "train loss:0.01642859553438475\n",
      "train loss:0.01638723886374606\n",
      "train loss:0.0052495190145578855\n",
      "train loss:0.01165221122720309\n",
      "train loss:0.014543383854359715\n",
      "train loss:0.022996220667012356\n",
      "train loss:0.0400224154741375\n",
      "train loss:0.017857059457974157\n",
      "train loss:0.007899291802430116\n",
      "train loss:0.0421351682448004\n",
      "train loss:0.00851626671288225\n",
      "train loss:0.013376846366910347\n",
      "train loss:0.037200627448221925\n",
      "train loss:0.007710646373443177\n",
      "train loss:0.033569881105691396\n",
      "train loss:0.010669093379899838\n",
      "train loss:0.009056721400337206\n",
      "train loss:0.01804402109319357\n",
      "train loss:0.011580073066297197\n",
      "train loss:0.010550322572879077\n",
      "train loss:0.0061369267462510965\n",
      "train loss:0.004205510202784668\n",
      "train loss:0.05315535841719119\n",
      "train loss:0.01365059376998105\n",
      "train loss:0.018192142610589088\n",
      "train loss:0.01653105658412895\n",
      "train loss:0.0698836877888741\n",
      "train loss:0.02738722559168203\n",
      "train loss:0.07022614026539553\n",
      "train loss:0.010328004916944846\n",
      "train loss:0.02085559582454647\n",
      "train loss:0.015864328394869204\n",
      "train loss:0.006954393680334241\n",
      "train loss:0.00426880250398817\n",
      "train loss:0.017949886605268795\n",
      "train loss:0.01392613323384555\n",
      "train loss:0.05542963016528172\n",
      "train loss:0.07129961809117132\n",
      "train loss:0.01916567668803033\n",
      "train loss:0.009399381305774364\n",
      "train loss:0.003955883478211966\n",
      "train loss:0.043856584533416516\n",
      "train loss:0.003133372597761015\n",
      "train loss:0.0049392133210861945\n",
      "train loss:0.009747771672492953\n",
      "train loss:0.005089592455480019\n",
      "train loss:0.036220325399764816\n",
      "train loss:0.06724594536881083\n",
      "train loss:0.00989683231454108\n",
      "train loss:0.019821862070213383\n",
      "train loss:0.00522610718939935\n",
      "train loss:0.03664113974943918\n",
      "train loss:0.03604791954391422\n",
      "train loss:0.005981328657116683\n",
      "train loss:0.04518146416048935\n",
      "train loss:0.05353458886541081\n",
      "train loss:0.023775372465416663\n",
      "train loss:0.052055209825073806\n",
      "train loss:0.021748458224619956\n",
      "train loss:0.004166311997912541\n",
      "train loss:0.0067500199305508424\n",
      "train loss:0.020670932585685375\n",
      "train loss:0.004801085647379919\n",
      "train loss:0.012828140224464933\n",
      "train loss:0.0027421551678956757\n",
      "train loss:0.004103089001225668\n",
      "train loss:0.011594899979906807\n",
      "train loss:0.007505596008122998\n",
      "train loss:0.01319176934072118\n",
      "train loss:0.012879556930760238\n",
      "train loss:0.00507122903564752\n",
      "train loss:0.0016501445496155476\n",
      "train loss:0.018513864355252846\n",
      "train loss:0.014996837580766177\n",
      "train loss:0.036142652879385805\n",
      "train loss:0.02485900741793272\n",
      "train loss:0.015936286726461024\n",
      "train loss:0.019029896714680056\n",
      "train loss:0.02013112310776041\n",
      "train loss:0.003615066744778223\n",
      "train loss:0.004813474331268911\n",
      "train loss:0.0073042021564031535\n",
      "train loss:0.01203953575615645\n",
      "train loss:0.03692293955221375\n",
      "train loss:0.014221254380850434\n",
      "train loss:0.00832464166063588\n",
      "train loss:0.007679980767667802\n",
      "train loss:0.009207258298346652\n",
      "train loss:0.008493920072500223\n",
      "train loss:0.00979075005185198\n",
      "train loss:0.009903348271409726\n",
      "train loss:0.0034062386643227637\n",
      "train loss:0.006782202060847461\n",
      "train loss:0.006526456802379402\n",
      "train loss:0.012715628327807925\n",
      "train loss:0.0037845321385080043\n",
      "train loss:0.012191095911722273\n",
      "train loss:0.04340785660256042\n",
      "train loss:0.007967858779480076\n",
      "train loss:0.00797366342649469\n",
      "train loss:0.014171406780930011\n",
      "train loss:0.00503721886134332\n",
      "train loss:0.006874327422151148\n",
      "train loss:0.0154027984196015\n",
      "train loss:0.09222543039917759\n",
      "train loss:0.0053834638713513485\n",
      "train loss:0.004982478504387939\n",
      "train loss:0.03835240946696932\n",
      "train loss:0.007157725847512995\n",
      "train loss:0.008092611704414337\n",
      "train loss:0.05510101880199905\n",
      "train loss:0.014407342084275155\n",
      "train loss:0.009872465993921243\n",
      "train loss:0.05261068611028444\n",
      "train loss:0.0218548292974068\n",
      "train loss:0.010178241914929678\n",
      "train loss:0.008719438061972722\n",
      "train loss:0.007024285288062976\n",
      "train loss:0.044737743113032316\n",
      "train loss:0.007002496277564902\n",
      "train loss:0.0034193629830271605\n",
      "train loss:0.17144305631014525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007993523657863542\n",
      "train loss:0.01254910144245242\n",
      "train loss:0.009636883555659437\n",
      "train loss:0.03704658675075589\n",
      "train loss:0.036088359584883656\n",
      "train loss:0.029573585509511634\n",
      "=== epoch:8, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.007086054443274878\n",
      "train loss:0.006213347348400159\n",
      "train loss:0.011117621240093089\n",
      "train loss:0.010058125305689234\n",
      "train loss:0.004317393948999456\n",
      "train loss:0.019978254694733293\n",
      "train loss:0.007342524175000761\n",
      "train loss:0.008906547090584584\n",
      "train loss:0.0014250258759782059\n",
      "train loss:0.009137886893546195\n",
      "train loss:0.0169989825186879\n",
      "train loss:0.007924553014682471\n",
      "train loss:0.011575560536497671\n",
      "train loss:0.024980605515303563\n",
      "train loss:0.0022840393504732623\n",
      "train loss:0.010095490569319951\n",
      "train loss:0.03996275354348362\n",
      "train loss:0.011645979612571739\n",
      "train loss:0.029071944377696703\n",
      "train loss:0.015934065583666883\n",
      "train loss:0.07324673980891887\n",
      "train loss:0.019393180827790193\n",
      "train loss:0.04162706846169153\n",
      "train loss:0.008126673179720614\n",
      "train loss:0.005073723611817828\n",
      "train loss:0.001512403374282828\n",
      "train loss:0.0394215573829896\n",
      "train loss:0.005748157174965661\n",
      "train loss:0.00872338406270423\n",
      "train loss:0.011410458093599809\n",
      "train loss:0.018701644981017323\n",
      "train loss:0.004121174897752693\n",
      "train loss:0.007794820016341388\n",
      "train loss:0.013704915113668002\n",
      "train loss:0.009773867701965259\n",
      "train loss:0.01049795373640448\n",
      "train loss:0.019014686374726884\n",
      "train loss:0.006059803638990433\n",
      "train loss:0.014534163251347132\n",
      "train loss:0.01622513383276182\n",
      "train loss:0.039474194563106996\n",
      "train loss:0.012416737375527918\n",
      "train loss:0.006000733261667709\n",
      "train loss:0.00767792801570076\n",
      "train loss:0.011009100736166599\n",
      "train loss:0.01562610785496453\n",
      "train loss:0.011622650297925363\n",
      "train loss:0.015698847124149252\n",
      "train loss:0.02492089196077567\n",
      "train loss:0.004480569486401174\n",
      "train loss:0.01635531735520367\n",
      "train loss:0.024820129258300606\n",
      "train loss:0.00631344477312347\n",
      "train loss:0.010658176352851021\n",
      "train loss:0.026636798581516054\n",
      "train loss:0.005454459301120863\n",
      "train loss:0.027373551918405722\n",
      "train loss:0.006432447268779775\n",
      "train loss:0.00798278135259793\n",
      "train loss:0.006579473283875892\n",
      "train loss:0.022782453647618887\n",
      "train loss:0.014406646233956696\n",
      "train loss:0.01757224846815009\n",
      "train loss:0.017824711550878797\n",
      "train loss:0.00367199768528913\n",
      "train loss:0.0038884000857537632\n",
      "train loss:0.007728816334285774\n",
      "train loss:0.03369033837987949\n",
      "train loss:0.008942186678433847\n",
      "train loss:0.023354979563294003\n",
      "train loss:0.026936873838273347\n",
      "train loss:0.009086788882071263\n",
      "train loss:0.058262758499657966\n",
      "train loss:0.018942550455854402\n",
      "train loss:0.018328150047329895\n",
      "train loss:0.004048808590671829\n",
      "train loss:0.004691452756626827\n",
      "train loss:0.013387533985074777\n",
      "train loss:0.003999611634992957\n",
      "train loss:0.043399129534861816\n",
      "train loss:0.002913921554147047\n",
      "train loss:0.01087018103789086\n",
      "train loss:0.00613119597307866\n",
      "train loss:0.008068487970420476\n",
      "train loss:0.05507939497924652\n",
      "train loss:0.022967372215603712\n",
      "train loss:0.012716163395289573\n",
      "train loss:0.010554760352512516\n",
      "train loss:0.011977616160715448\n",
      "train loss:0.03439208490306357\n",
      "train loss:0.0017902933995022096\n",
      "train loss:0.020684571787205622\n",
      "train loss:0.006247494535800786\n",
      "train loss:0.02538032418305945\n",
      "train loss:0.02637658387217853\n",
      "train loss:0.012472691045133728\n",
      "train loss:0.009709662273829378\n",
      "train loss:0.012478999916207411\n",
      "train loss:0.0010203309093890461\n",
      "train loss:0.05236467544061919\n",
      "train loss:0.007302125354312529\n",
      "train loss:0.0413841232566611\n",
      "train loss:0.03665671154738068\n",
      "train loss:0.008724943886405719\n",
      "train loss:0.00932272441124909\n",
      "train loss:0.006163296476295689\n",
      "train loss:0.003189839148629721\n",
      "train loss:0.011416208467920064\n",
      "train loss:0.06386883304745365\n",
      "train loss:0.00856380737528319\n",
      "train loss:0.01526792518357218\n",
      "train loss:0.023510986191170286\n",
      "train loss:0.012692485609313672\n",
      "train loss:0.035549608353761836\n",
      "train loss:0.0067486848774369265\n",
      "train loss:0.020055776813735927\n",
      "train loss:0.004792614000107336\n",
      "train loss:0.007680549889403656\n",
      "train loss:0.02813406099228726\n",
      "train loss:0.008782879742932993\n",
      "train loss:0.012747067316453921\n",
      "train loss:0.005055059414262062\n",
      "train loss:0.007534205469069606\n",
      "train loss:0.021157814490842183\n",
      "train loss:0.012577700451401202\n",
      "train loss:0.011743634221932316\n",
      "train loss:0.010675054262597596\n",
      "train loss:0.018463771645078488\n",
      "train loss:0.04030053648702279\n",
      "train loss:0.022236369203998078\n",
      "train loss:0.028953845493180076\n",
      "train loss:0.00563252357022333\n",
      "train loss:0.00899315940967364\n",
      "train loss:0.07853025173972339\n",
      "train loss:0.013773441017235925\n",
      "train loss:0.03517956326163313\n",
      "train loss:0.045217121178367306\n",
      "train loss:0.032677711690328924\n",
      "train loss:0.013433786598903595\n",
      "train loss:0.01228669383690386\n",
      "train loss:0.008260028828029276\n",
      "train loss:0.015286279104581819\n",
      "train loss:0.04458856575273442\n",
      "train loss:0.004232135737348588\n",
      "train loss:0.007118650814129784\n",
      "train loss:0.0205965824297878\n",
      "train loss:0.00883033634937197\n",
      "train loss:0.003607939483561727\n",
      "train loss:0.014648376065310848\n",
      "train loss:0.008793715944552312\n",
      "train loss:0.004496919949897186\n",
      "train loss:0.006077975903045064\n",
      "train loss:0.007157934390423686\n",
      "train loss:0.011005918547275919\n",
      "train loss:0.024554986620412333\n",
      "train loss:0.002211916094970533\n",
      "train loss:0.004785093831179596\n",
      "train loss:0.018853635366092716\n",
      "train loss:0.0029975803068748403\n",
      "train loss:0.13341666282101708\n",
      "train loss:0.00958912808386126\n",
      "train loss:0.05490873377118228\n",
      "train loss:0.0062835573906877655\n",
      "train loss:0.010337097790940837\n",
      "train loss:0.0082136346235797\n",
      "train loss:0.03141433113683484\n",
      "train loss:0.04734583037287647\n",
      "train loss:0.009436182691148669\n",
      "train loss:0.008809494090618241\n",
      "train loss:0.0038662248173668545\n",
      "train loss:0.03374314533404324\n",
      "train loss:0.004934774501619899\n",
      "train loss:0.006225335150781373\n",
      "train loss:0.008709404987496967\n",
      "train loss:0.020150379892638973\n",
      "train loss:0.015545349495164531\n",
      "train loss:0.006427812188390067\n",
      "train loss:0.022420942682769302\n",
      "train loss:0.07554720807798974\n",
      "train loss:0.006089666596532286\n",
      "train loss:0.01149376318619352\n",
      "train loss:0.007441706641221425\n",
      "train loss:0.010935335023048116\n",
      "train loss:0.008126681266393859\n",
      "train loss:0.020164430536049535\n",
      "train loss:0.011188809889914829\n",
      "train loss:0.029472960819857542\n",
      "train loss:0.004475061936295387\n",
      "train loss:0.014245286971539655\n",
      "train loss:0.007206558826573289\n",
      "train loss:0.004748191837651983\n",
      "train loss:0.008306825371032991\n",
      "train loss:0.028367345882983837\n",
      "train loss:0.004126924508642935\n",
      "train loss:0.01052721379896221\n",
      "train loss:0.02572901120852631\n",
      "train loss:0.0073221127542031205\n",
      "train loss:0.019775389915208143\n",
      "train loss:0.011121383397180612\n",
      "train loss:0.011858080958246866\n",
      "train loss:0.01647537185354005\n",
      "train loss:0.0064818817538051235\n",
      "train loss:0.03710413675652384\n",
      "train loss:0.015573001877917445\n",
      "train loss:0.011060215193770555\n",
      "train loss:0.01132598698822273\n",
      "train loss:0.006982616517822751\n",
      "train loss:0.0018204145498561938\n",
      "train loss:0.0062400357373519465\n",
      "train loss:0.0008855988274022415\n",
      "train loss:0.010170480014566004\n",
      "train loss:0.07033840725120029\n",
      "train loss:0.04411960254577758\n",
      "train loss:0.004646532903489856\n",
      "train loss:0.013414514018772734\n",
      "train loss:0.013398964457108642\n",
      "train loss:0.01621601545664461\n",
      "train loss:0.04772098045616847\n",
      "train loss:0.0067449947738752415\n",
      "train loss:0.013848566822583215\n",
      "train loss:0.012167791683226398\n",
      "train loss:0.0072658577343785715\n",
      "train loss:0.012248201525763426\n",
      "train loss:0.019168381851407203\n",
      "train loss:0.0100285160239851\n",
      "train loss:0.004213819807489903\n",
      "train loss:0.027849894995732444\n",
      "train loss:0.0026513534925703152\n",
      "train loss:0.008278348990737684\n",
      "train loss:0.006505617432032774\n",
      "train loss:0.00615543469561236\n",
      "train loss:0.09557589424594408\n",
      "train loss:0.06668032139630192\n",
      "train loss:0.0210369303277208\n",
      "train loss:0.04827255419950002\n",
      "train loss:0.013724986407439774\n",
      "train loss:0.0062806985663315055\n",
      "train loss:0.039805262080325955\n",
      "train loss:0.019012956175528607\n",
      "train loss:0.006090269885225252\n",
      "train loss:0.019399280319018525\n",
      "train loss:0.027125509710675025\n",
      "train loss:0.008493677086744911\n",
      "train loss:0.11442847412726176\n",
      "train loss:0.009048607428037534\n",
      "train loss:0.0823330522685877\n",
      "train loss:0.006477155007743095\n",
      "train loss:0.002887299977245122\n",
      "train loss:0.008488704305596211\n",
      "train loss:0.006202504527899167\n",
      "train loss:0.004354632603245805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018801346598585778\n",
      "train loss:0.006676982525494358\n",
      "train loss:0.03558215246279155\n",
      "train loss:0.007358643353844187\n",
      "train loss:0.007855641901914916\n",
      "train loss:0.0077176723587587285\n",
      "train loss:0.011883708064840029\n",
      "train loss:0.011837978679469556\n",
      "train loss:0.0188335118542356\n",
      "train loss:0.013712050680086645\n",
      "train loss:0.005332492350135456\n",
      "train loss:0.03710684526723412\n",
      "train loss:0.02180967180376531\n",
      "train loss:0.0019602849601142924\n",
      "train loss:0.017508050680557333\n",
      "train loss:0.01680642064821531\n",
      "train loss:0.012552325677335193\n",
      "train loss:0.009607462189411126\n",
      "train loss:0.011812515647885739\n",
      "train loss:0.03836957152626253\n",
      "train loss:0.007138435846980956\n",
      "train loss:0.0795975630853493\n",
      "train loss:0.013804255302783737\n",
      "train loss:0.007505387568175703\n",
      "train loss:0.007696312060392482\n",
      "train loss:0.008564818407036795\n",
      "train loss:0.011216907896740087\n",
      "train loss:0.031221242462549773\n",
      "train loss:0.018045611077468948\n",
      "train loss:0.00930656410775067\n",
      "train loss:0.000839994731454133\n",
      "train loss:0.010440678254119522\n",
      "train loss:0.003748304022534722\n",
      "train loss:0.005630965019665028\n",
      "train loss:0.05104696560672775\n",
      "train loss:0.003036565833201576\n",
      "train loss:0.013805590343443452\n",
      "train loss:0.0034649046794994046\n",
      "train loss:0.004592534911756182\n",
      "train loss:0.009560152757569164\n",
      "train loss:0.006491116397323026\n",
      "train loss:0.009262216986972573\n",
      "train loss:0.06758634573467524\n",
      "train loss:0.013113294532024271\n",
      "train loss:0.01418018584510822\n",
      "train loss:0.0033397127806499348\n",
      "train loss:0.00494127461470935\n",
      "train loss:0.004355179876080594\n",
      "train loss:0.00325692281015132\n",
      "train loss:0.011955291701062343\n",
      "train loss:0.1359520309369195\n",
      "train loss:0.025027688143735297\n",
      "train loss:0.0088484474793995\n",
      "train loss:0.005500491220124329\n",
      "train loss:0.0016195349111320573\n",
      "train loss:0.025817720163707408\n",
      "train loss:0.01961961218350264\n",
      "train loss:0.02109238502602269\n",
      "train loss:0.012698292395229127\n",
      "train loss:0.0047457365149816575\n",
      "train loss:0.012950134663910744\n",
      "train loss:0.011677563647557392\n",
      "train loss:0.010160666838107704\n",
      "train loss:0.006413701801140735\n",
      "train loss:0.04036124272869502\n",
      "train loss:0.015016205223629134\n",
      "train loss:0.0506222106795634\n",
      "train loss:0.018636954758195188\n",
      "train loss:0.005655004851761061\n",
      "train loss:0.004410300846694638\n",
      "train loss:0.003173060531583668\n",
      "train loss:0.007754288614012336\n",
      "train loss:0.031154918172248615\n",
      "train loss:0.011212119616527112\n",
      "train loss:0.010841735678132236\n",
      "train loss:0.018582662691122707\n",
      "train loss:0.0122601090524728\n",
      "train loss:0.016133981936561397\n",
      "train loss:0.046573140680922026\n",
      "train loss:0.012024376730279021\n",
      "train loss:0.005421996881485659\n",
      "train loss:0.00298282979526947\n",
      "train loss:0.007999148949559932\n",
      "train loss:0.05901102578300928\n",
      "train loss:0.04749747007686942\n",
      "train loss:0.015665557737532518\n",
      "train loss:0.004761848070890158\n",
      "train loss:0.015777025099115133\n",
      "train loss:0.024436718783010732\n",
      "train loss:0.012667163678601325\n",
      "train loss:0.017233339211939397\n",
      "train loss:0.002847846422690412\n",
      "train loss:0.014621268121267206\n",
      "train loss:0.0036374630178227945\n",
      "train loss:0.01864507978855425\n",
      "train loss:0.01061969872870419\n",
      "train loss:0.012299558702123469\n",
      "train loss:0.009805769624149108\n",
      "train loss:0.008240221101277511\n",
      "train loss:0.009790492318894792\n",
      "train loss:0.04929620376000679\n",
      "train loss:0.012083148322149273\n",
      "train loss:0.04065597041325025\n",
      "train loss:0.013978990144211\n",
      "train loss:0.0144891060172872\n",
      "train loss:0.00807464725025026\n",
      "train loss:0.011602180805804824\n",
      "train loss:0.0036942534418060624\n",
      "train loss:0.0041402292503420444\n",
      "train loss:0.044470365545040275\n",
      "train loss:0.026293096359536246\n",
      "train loss:0.01137586607615941\n",
      "train loss:0.003942392588332091\n",
      "train loss:0.021701094274637907\n",
      "train loss:0.0029683142780004023\n",
      "train loss:0.027471412984249568\n",
      "train loss:0.006884735694045942\n",
      "train loss:0.037239005541890996\n",
      "train loss:0.004552741893441892\n",
      "train loss:0.0015526808334564276\n",
      "train loss:0.004988710820944447\n",
      "train loss:0.006050952143456141\n",
      "train loss:0.005261456436084904\n",
      "train loss:0.0016783511960659614\n",
      "train loss:0.024208864989568837\n",
      "train loss:0.008196956130828083\n",
      "train loss:0.0008073969486897287\n",
      "train loss:0.0006075518642783597\n",
      "train loss:0.0007190309587722486\n",
      "train loss:0.01321354708230455\n",
      "train loss:0.052229608436954955\n",
      "train loss:0.007826664286068624\n",
      "train loss:0.0044010971722482075\n",
      "train loss:0.004779537240952234\n",
      "train loss:0.006797928383613119\n",
      "train loss:0.004759972926107516\n",
      "train loss:0.021064599405142395\n",
      "train loss:0.007715094735991673\n",
      "train loss:0.00044220939726730786\n",
      "train loss:0.06039148609809931\n",
      "train loss:0.010668143642018091\n",
      "train loss:0.003152825756349742\n",
      "train loss:0.0017710960978689788\n",
      "train loss:0.0033231272730013133\n",
      "train loss:0.013924443956368725\n",
      "train loss:0.05049527261104379\n",
      "train loss:0.002222923240636278\n",
      "train loss:0.01761098943379156\n",
      "train loss:0.007005874127749655\n",
      "train loss:0.0030535108842352997\n",
      "train loss:0.05032982770086554\n",
      "train loss:0.015280642832592934\n",
      "train loss:0.01976113936069583\n",
      "train loss:0.03200447870290618\n",
      "train loss:0.015761742894034314\n",
      "train loss:0.0070278546531116395\n",
      "train loss:0.010067306505156326\n",
      "train loss:0.010910167283190744\n",
      "train loss:0.015312889608925432\n",
      "train loss:0.03919140040915106\n",
      "train loss:0.002736202426432563\n",
      "train loss:0.045386369575090145\n",
      "train loss:0.019399716197835065\n",
      "train loss:0.0033587568696178327\n",
      "train loss:0.01837681326624227\n",
      "train loss:0.0031769777982860892\n",
      "train loss:0.003118870354401832\n",
      "train loss:0.01710312825306334\n",
      "train loss:0.02423706082688319\n",
      "train loss:0.04847340987856423\n",
      "train loss:0.013539536656546973\n",
      "train loss:0.004502795333836257\n",
      "train loss:0.0027210342146390216\n",
      "train loss:0.009063085100202402\n",
      "train loss:0.01653711584700805\n",
      "train loss:0.014725018474592717\n",
      "train loss:0.015089399667250057\n",
      "train loss:0.013412091989310182\n",
      "train loss:0.020522533655149458\n",
      "train loss:0.037992726820417426\n",
      "train loss:0.009609064298097422\n",
      "train loss:0.0018546460488698523\n",
      "train loss:0.007118166812832314\n",
      "train loss:0.0174430401034215\n",
      "train loss:0.0365247544572572\n",
      "train loss:0.014584790059993951\n",
      "train loss:0.0072372410950157715\n",
      "train loss:0.0041834449934173654\n",
      "train loss:0.04998062808985832\n",
      "train loss:0.014582275140122291\n",
      "train loss:0.01834476757438341\n",
      "train loss:0.04639011024976922\n",
      "train loss:0.007315171370944626\n",
      "train loss:0.014156595421827121\n",
      "train loss:0.008683375573473694\n",
      "train loss:0.026677862810109434\n",
      "train loss:0.0035528904446643973\n",
      "train loss:0.0011629159934877984\n",
      "train loss:0.0022696544058688284\n",
      "train loss:0.09865166582379965\n",
      "train loss:0.0021280500600820017\n",
      "train loss:0.019197752287446725\n",
      "train loss:0.03159428648768973\n",
      "train loss:0.007861906419248789\n",
      "train loss:0.02355805668858194\n",
      "train loss:0.013052488909198252\n",
      "train loss:0.002898628478732835\n",
      "train loss:0.004774103315638282\n",
      "train loss:0.026711846963994406\n",
      "train loss:0.017795415661040575\n",
      "train loss:0.009696221909563848\n",
      "train loss:0.0063451619589456046\n",
      "train loss:0.0048128473631865246\n",
      "train loss:0.0037176091407970548\n",
      "train loss:0.03458495910617004\n",
      "train loss:0.010509397533426874\n",
      "train loss:0.011120275388816518\n",
      "train loss:0.017747032167165923\n",
      "train loss:0.04274605072980168\n",
      "train loss:0.00966463888360461\n",
      "train loss:0.005139666057213634\n",
      "train loss:0.028425644680571214\n",
      "train loss:0.004765155725513342\n",
      "train loss:0.01931766884975405\n",
      "train loss:0.011272115828982552\n",
      "train loss:0.028547079966052345\n",
      "train loss:0.009561915573017273\n",
      "train loss:0.012596917015983637\n",
      "train loss:0.009663949424239416\n",
      "train loss:0.044060834533097254\n",
      "train loss:0.014091429009054371\n",
      "train loss:0.00396554165853942\n",
      "train loss:0.0007518393580191198\n",
      "train loss:0.00707310860137048\n",
      "train loss:0.004685393545919316\n",
      "train loss:0.012291740946301026\n",
      "train loss:0.0066848899889584545\n",
      "train loss:0.0030282054069636632\n",
      "train loss:0.021394932247561775\n",
      "train loss:0.003455044451607946\n",
      "train loss:0.013790259171324816\n",
      "train loss:0.05396401688070023\n",
      "train loss:0.011613366866191408\n",
      "train loss:0.03789304820522422\n",
      "train loss:0.005562780537643214\n",
      "train loss:0.010155743541117819\n",
      "train loss:0.021221491356586544\n",
      "train loss:0.01408388368120287\n",
      "train loss:0.04243489207586817\n",
      "train loss:0.022568996320367383\n",
      "train loss:0.00941659583995265\n",
      "train loss:0.0071775516827403355\n",
      "train loss:0.026085273960571764\n",
      "train loss:0.013237930025764828\n",
      "train loss:0.0042194279598984094\n",
      "train loss:0.007895833770701844\n",
      "train loss:0.028127260368053082\n",
      "train loss:0.0015886997502084844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00828577673987146\n",
      "train loss:0.0033192613108113072\n",
      "train loss:0.014912454571231692\n",
      "train loss:0.015816225412512312\n",
      "train loss:0.0014644862883664924\n",
      "train loss:0.004016033126831118\n",
      "train loss:0.007352070803264633\n",
      "train loss:0.026886822125706436\n",
      "train loss:0.005761927157297495\n",
      "train loss:0.003856812245131166\n",
      "train loss:0.01786740353390814\n",
      "train loss:0.05061375854097459\n",
      "train loss:0.011039473401754098\n",
      "train loss:0.022079351148938137\n",
      "train loss:0.011634392345977069\n",
      "train loss:0.002912197431814222\n",
      "train loss:0.005183763268969826\n",
      "train loss:0.017392233625678058\n",
      "train loss:0.03601493185418084\n",
      "train loss:0.008053347432466705\n",
      "train loss:0.0036595401982944397\n",
      "train loss:0.007504586861043876\n",
      "train loss:0.003360614354522812\n",
      "train loss:0.043760116200139275\n",
      "train loss:0.0188095256768335\n",
      "train loss:0.002847442403617942\n",
      "train loss:0.005894658613056592\n",
      "train loss:0.00348389190966698\n",
      "train loss:0.008023973521605512\n",
      "train loss:0.013265906689300989\n",
      "train loss:0.019246795716624767\n",
      "train loss:0.030097782656952586\n",
      "train loss:0.002195614931317909\n",
      "train loss:0.017405247761964407\n",
      "train loss:0.009711777786124151\n",
      "train loss:0.0063601873323575675\n",
      "train loss:0.01460577406136473\n",
      "train loss:0.007828910946668958\n",
      "train loss:0.01573014767523163\n",
      "train loss:0.023927945696667993\n",
      "train loss:0.005968917109870666\n",
      "train loss:0.014333023668567669\n",
      "train loss:0.01970040549633655\n",
      "train loss:0.00751521266448943\n",
      "train loss:0.006696988046761652\n",
      "train loss:0.01293459233850948\n",
      "train loss:0.017999270439284457\n",
      "train loss:0.003933313656296256\n",
      "train loss:0.012333828711515418\n",
      "train loss:0.0025603210516898693\n",
      "train loss:0.02048347450144099\n",
      "train loss:0.03459984265571714\n",
      "train loss:0.008560538753593954\n",
      "train loss:0.004989029251747414\n",
      "train loss:0.01304081005582674\n",
      "train loss:0.00863462349887448\n",
      "train loss:0.004881584961456051\n",
      "train loss:0.04646408002750981\n",
      "train loss:0.060616803610599505\n",
      "train loss:0.016913103422717693\n",
      "train loss:0.013237668404400927\n",
      "train loss:0.006972433348385603\n",
      "train loss:0.0033011915210843738\n",
      "train loss:0.013734975520207334\n",
      "train loss:0.029280437682672876\n",
      "train loss:0.0006394095509810504\n",
      "train loss:0.004119488429307066\n",
      "train loss:0.0017677704198555948\n",
      "train loss:0.012534102438640013\n",
      "train loss:0.0024924797964187796\n",
      "train loss:0.0778764881990674\n",
      "train loss:0.01317184724451234\n",
      "train loss:0.004523394373768206\n",
      "train loss:0.011556760873488866\n",
      "train loss:0.0064306750818174455\n",
      "train loss:0.007447070918411457\n",
      "train loss:0.006877928044121334\n",
      "train loss:0.026567124368913064\n",
      "train loss:0.010554259701247343\n",
      "train loss:0.015165822006950375\n",
      "train loss:0.008419423678601753\n",
      "train loss:0.006482316634477989\n",
      "train loss:0.014560393125166488\n",
      "train loss:0.00271160647786119\n",
      "train loss:0.011470152700729626\n",
      "train loss:0.003964520556424058\n",
      "train loss:0.003975994227192085\n",
      "train loss:0.052367289231570815\n",
      "train loss:0.003599422851796416\n",
      "train loss:0.0066581517890288225\n",
      "train loss:0.009783944106605406\n",
      "=== epoch:9, train acc:0.996, test acc:0.984 ===\n",
      "train loss:0.007797088147763837\n",
      "train loss:0.008938012186512703\n",
      "train loss:0.02803706696313102\n",
      "train loss:0.017913377786304106\n",
      "train loss:0.025288794477307582\n",
      "train loss:0.005225947566910748\n",
      "train loss:0.0037542476019636383\n",
      "train loss:0.008096898201346748\n",
      "train loss:0.12896939271363564\n",
      "train loss:0.026824121078641433\n",
      "train loss:0.009244013735540436\n",
      "train loss:0.019439617114973634\n",
      "train loss:0.008411354629997784\n",
      "train loss:0.00772386452448502\n",
      "train loss:0.017996678922548776\n",
      "train loss:0.0031505217130354825\n",
      "train loss:0.06940924130624329\n",
      "train loss:0.011318429783219142\n",
      "train loss:0.004242017845653829\n",
      "train loss:0.043831384916812315\n",
      "train loss:0.003307655526845305\n",
      "train loss:0.03615296543824516\n",
      "train loss:0.008592794085271976\n",
      "train loss:0.018653771116567987\n",
      "train loss:0.01743095850333435\n",
      "train loss:0.010184824122748985\n",
      "train loss:0.007425325267195912\n",
      "train loss:0.019798658896930468\n",
      "train loss:0.012177022201536077\n",
      "train loss:0.021635979142580964\n",
      "train loss:0.006118038710420609\n",
      "train loss:0.006750916099533135\n",
      "train loss:0.03904418884699164\n",
      "train loss:0.00683903888371334\n",
      "train loss:0.002165746870670714\n",
      "train loss:0.014459236251445885\n",
      "train loss:0.02827030667674122\n",
      "train loss:0.01693828638497475\n",
      "train loss:0.004849857229208238\n",
      "train loss:0.0028945836567338895\n",
      "train loss:0.004634547870614331\n",
      "train loss:0.007632366630485123\n",
      "train loss:0.012233996641849898\n",
      "train loss:0.038615818767544934\n",
      "train loss:0.005899664908441602\n",
      "train loss:0.006056054507729186\n",
      "train loss:0.004492827754153239\n",
      "train loss:0.005839832947639963\n",
      "train loss:0.003896460745959788\n",
      "train loss:0.013119629016114139\n",
      "train loss:0.007495570609095332\n",
      "train loss:0.003107293575069322\n",
      "train loss:0.005169851809488619\n",
      "train loss:0.01968463339665073\n",
      "train loss:0.022540544728415456\n",
      "train loss:0.0077983650817295335\n",
      "train loss:0.028655823634515607\n",
      "train loss:0.03142822794275816\n",
      "train loss:0.046721027377786106\n",
      "train loss:0.0016083801140903528\n",
      "train loss:0.028360832509626\n",
      "train loss:0.008697596340301735\n",
      "train loss:0.01741290093495879\n",
      "train loss:0.0078107063409844765\n",
      "train loss:0.003780571456968473\n",
      "train loss:0.014137287684751325\n",
      "train loss:0.004056725863417974\n",
      "train loss:0.0034411224240280145\n",
      "train loss:0.030557115020732183\n",
      "train loss:0.015823663825401128\n",
      "train loss:0.00849784199432034\n",
      "train loss:0.0069145978443283206\n",
      "train loss:0.013226865874766004\n",
      "train loss:0.0023402131483261424\n",
      "train loss:0.044829995121344085\n",
      "train loss:0.005958561942766684\n",
      "train loss:0.019325018044125297\n",
      "train loss:0.034752857073158665\n",
      "train loss:0.04180640215482436\n",
      "train loss:0.008879810092922755\n",
      "train loss:0.006346112510100894\n",
      "train loss:0.0025666084098691128\n",
      "train loss:0.006874741342608775\n",
      "train loss:0.00960144561814927\n",
      "train loss:0.023594296979869585\n",
      "train loss:0.010145228792945587\n",
      "train loss:0.002307961558609843\n",
      "train loss:0.0021569651603027488\n",
      "train loss:0.009429824620442232\n",
      "train loss:0.02448204341971453\n",
      "train loss:0.006882995971502939\n",
      "train loss:0.01982749352222375\n",
      "train loss:0.014968004152432041\n",
      "train loss:0.007204963454701727\n",
      "train loss:0.00908561707880715\n",
      "train loss:0.002932234467702044\n",
      "train loss:0.02546257684294941\n",
      "train loss:0.006676221784507008\n",
      "train loss:0.01379725234919114\n",
      "train loss:0.0031677605338431203\n",
      "train loss:0.012694236414513562\n",
      "train loss:0.007509529835043597\n",
      "train loss:0.006239162100169456\n",
      "train loss:0.004301384646862181\n",
      "train loss:0.012349527387495536\n",
      "train loss:0.01855942011121747\n",
      "train loss:0.029999844789661077\n",
      "train loss:0.036391712065986986\n",
      "train loss:0.005589084418351058\n",
      "train loss:0.005887619059989932\n",
      "train loss:0.0024154365877614385\n",
      "train loss:0.008314951293966208\n",
      "train loss:0.009620885856550705\n",
      "train loss:0.014201330518783091\n",
      "train loss:0.005994824368200139\n",
      "train loss:0.015461335881749184\n",
      "train loss:0.01840912923782052\n",
      "train loss:0.0009676661773315527\n",
      "train loss:0.0337105066818182\n",
      "train loss:0.011970445443650064\n",
      "train loss:0.07448599769575598\n",
      "train loss:0.022208064004592055\n",
      "train loss:0.005419588027219826\n",
      "train loss:0.010121620098721832\n",
      "train loss:0.03298599420817254\n",
      "train loss:0.0033340070493386178\n",
      "train loss:0.0202831871939534\n",
      "train loss:0.021496916255150666\n",
      "train loss:0.003885872362595721\n",
      "train loss:0.006933132921646138\n",
      "train loss:0.03534580709709912\n",
      "train loss:0.002992700635852038\n",
      "train loss:0.018101225901521037\n",
      "train loss:0.022566242757086255\n",
      "train loss:0.025056367498121873\n",
      "train loss:0.04592205462345931\n",
      "train loss:0.01163034644052514\n",
      "train loss:0.020407039740200382\n",
      "train loss:0.017478577249720798\n",
      "train loss:0.06807931346737772\n",
      "train loss:0.012214191214426868\n",
      "train loss:0.006135625277331997\n",
      "train loss:0.0081865923967309\n",
      "train loss:0.02403024419452066\n",
      "train loss:0.03570538268589682\n",
      "train loss:0.009366702608589588\n",
      "train loss:0.01804965227436093\n",
      "train loss:0.010375085465900826\n",
      "train loss:0.011903872346473483\n",
      "train loss:0.006976339132223599\n",
      "train loss:0.06155491971740368\n",
      "train loss:0.004546801883366247\n",
      "train loss:0.022658460099133065\n",
      "train loss:0.0042123873885575435\n",
      "train loss:0.05817611345501495\n",
      "train loss:0.0009944049388168625\n",
      "train loss:0.012328672494318387\n",
      "train loss:0.013308977508344953\n",
      "train loss:0.007708751706418524\n",
      "train loss:0.014153765641505025\n",
      "train loss:0.0023489536031498608\n",
      "train loss:0.0007871058862982702\n",
      "train loss:0.007734909325025401\n",
      "train loss:0.0015531332215347029\n",
      "train loss:0.0037282360967160356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005474895292374394\n",
      "train loss:0.0035499473260114044\n",
      "train loss:0.008239750307808895\n",
      "train loss:0.02144647014210419\n",
      "train loss:0.012173945013551119\n",
      "train loss:0.012674902435242393\n",
      "train loss:0.003459688557581153\n",
      "train loss:0.004238094954547894\n",
      "train loss:0.016852179558296605\n",
      "train loss:0.0010871330433866984\n",
      "train loss:0.0015546953966135105\n",
      "train loss:0.004001938127484535\n",
      "train loss:0.003499961418593242\n",
      "train loss:0.007401317718250148\n",
      "train loss:0.012895083436362819\n",
      "train loss:0.003330340332954439\n",
      "train loss:0.004209056646007775\n",
      "train loss:0.003326226544850161\n",
      "train loss:0.002122979584909499\n",
      "train loss:0.007202364355652955\n",
      "train loss:0.009354218524692506\n",
      "train loss:0.011206074769466001\n",
      "train loss:0.011203981514512842\n",
      "train loss:0.006501393102572404\n",
      "train loss:0.007536633516074357\n",
      "train loss:0.01593618357144485\n",
      "train loss:0.013775164095020638\n",
      "train loss:0.010085786232993584\n",
      "train loss:0.03665792812090765\n",
      "train loss:0.01554958611792455\n",
      "train loss:0.07565767981123937\n",
      "train loss:0.04945964512703464\n",
      "train loss:0.035130808629574246\n",
      "train loss:0.16718599890782834\n",
      "train loss:0.0035236344693231297\n",
      "train loss:0.0029336220789357294\n",
      "train loss:0.009319126948266027\n",
      "train loss:0.024692408628214736\n",
      "train loss:0.013157104913611859\n",
      "train loss:0.009919914608226934\n",
      "train loss:0.010142990572497079\n",
      "train loss:0.010980318136708482\n",
      "train loss:0.009323344081214291\n",
      "train loss:0.008994397931302259\n",
      "train loss:0.0022294227506875534\n",
      "train loss:0.0031565656726128626\n",
      "train loss:0.025814488507575718\n",
      "train loss:0.0033552983396692966\n",
      "train loss:0.016125063603484556\n",
      "train loss:0.014930104654113324\n",
      "train loss:0.006620116251997276\n",
      "train loss:0.007049306450207631\n",
      "train loss:0.004440574338114931\n",
      "train loss:0.018855848636676265\n",
      "train loss:0.003711500380711473\n",
      "train loss:0.006449327892131232\n",
      "train loss:0.00741963632308289\n",
      "train loss:0.005913706225940918\n",
      "train loss:0.006426734789291819\n",
      "train loss:0.010929955193481571\n",
      "train loss:0.001184742370087119\n",
      "train loss:0.005381409245830559\n",
      "train loss:0.006318064622253157\n",
      "train loss:0.006822191128205671\n",
      "train loss:0.030140379838062795\n",
      "train loss:0.0021270827263543926\n",
      "train loss:0.0088805458907605\n",
      "train loss:0.01858914674898853\n",
      "train loss:0.0023759307038186935\n",
      "train loss:0.009919120497607348\n",
      "train loss:0.0028747052995329843\n",
      "train loss:0.007412846315444109\n",
      "train loss:0.022871268631998384\n",
      "train loss:0.004106072505457445\n",
      "train loss:0.013322184008117723\n",
      "train loss:0.0048539493555395975\n",
      "train loss:0.002038582155486851\n",
      "train loss:0.002137229329629156\n",
      "train loss:0.0021611674008508905\n",
      "train loss:0.02771543660184426\n",
      "train loss:0.06221241003509428\n",
      "train loss:0.00409964314274084\n",
      "train loss:0.008593700399206533\n",
      "train loss:0.02149635433633379\n",
      "train loss:0.009350680706252949\n",
      "train loss:0.08272613538542867\n",
      "train loss:0.027698611572557107\n",
      "train loss:0.031252488023705005\n",
      "train loss:0.004818392350407468\n",
      "train loss:0.009462246261141189\n",
      "train loss:0.008171876899309637\n",
      "train loss:0.004085725403628457\n",
      "train loss:0.006596400517327846\n",
      "train loss:0.009359033144740772\n",
      "train loss:0.006379125952443473\n",
      "train loss:0.006594556565104795\n",
      "train loss:0.0395606630892624\n",
      "train loss:0.012946004594138921\n",
      "train loss:0.00602758514498616\n",
      "train loss:0.010671556417346722\n",
      "train loss:0.0056924246507393805\n",
      "train loss:0.008293846596075507\n",
      "train loss:0.04007990395669209\n",
      "train loss:0.005538845416905442\n",
      "train loss:0.002745033198449327\n",
      "train loss:0.0025750999791338447\n",
      "train loss:0.004626935555228728\n",
      "train loss:0.06102522142299167\n",
      "train loss:0.017029840815508995\n",
      "train loss:0.0030257332497664346\n",
      "train loss:0.014512262198784183\n",
      "train loss:0.015629732785034153\n",
      "train loss:0.011557903110516198\n",
      "train loss:0.011390320207260536\n",
      "train loss:0.01887999446231068\n",
      "train loss:0.010312074204476189\n",
      "train loss:0.01834599711018104\n",
      "train loss:0.014779739775209948\n",
      "train loss:0.015632414773011027\n",
      "train loss:0.008936849146360323\n",
      "train loss:0.012542977999279314\n",
      "train loss:0.005403725005128344\n",
      "train loss:0.008694545631049287\n",
      "train loss:0.006983613969472125\n",
      "train loss:0.0150091594289226\n",
      "train loss:0.00750417029400787\n",
      "train loss:0.011060802219737946\n",
      "train loss:0.010407072895439549\n",
      "train loss:0.02585567241758881\n",
      "train loss:0.0034229721751265446\n",
      "train loss:0.0038538586732980696\n",
      "train loss:0.004004757978441979\n",
      "train loss:0.04146072579979004\n",
      "train loss:0.0010620794790861252\n",
      "train loss:0.010173851524473027\n",
      "train loss:0.004696229095242197\n",
      "train loss:0.01718307273620481\n",
      "train loss:0.0015010074933103645\n",
      "train loss:0.0008317918559355605\n",
      "train loss:0.010474327341998182\n",
      "train loss:0.0064956266567802665\n",
      "train loss:0.0012017336578741351\n",
      "train loss:0.006066757137336441\n",
      "train loss:0.017218303042678882\n",
      "train loss:0.02414968750188896\n",
      "train loss:0.007020031130297916\n",
      "train loss:0.029024428226916067\n",
      "train loss:0.023682885687181448\n",
      "train loss:0.002864739629240772\n",
      "train loss:0.01915543218787523\n",
      "train loss:0.0053418754792726045\n",
      "train loss:0.0024670847124049653\n",
      "train loss:0.0029085799534202465\n",
      "train loss:0.00416723434110532\n",
      "train loss:0.030320079397750464\n",
      "train loss:0.0022306711123399586\n",
      "train loss:0.005527374852978112\n",
      "train loss:0.008539090335852302\n",
      "train loss:0.009684087952055291\n",
      "train loss:0.007300999035757946\n",
      "train loss:0.00440787678794326\n",
      "train loss:0.003929492530440288\n",
      "train loss:0.019966572155842407\n",
      "train loss:0.03517164125697691\n",
      "train loss:0.0047321262934863564\n",
      "train loss:0.005546916911864156\n",
      "train loss:0.0016532009230525336\n",
      "train loss:0.001077888221220745\n",
      "train loss:0.00914076835955762\n",
      "train loss:0.003873282166786618\n",
      "train loss:0.02960925437494338\n",
      "train loss:0.0023966420090726914\n",
      "train loss:0.0013623098573577416\n",
      "train loss:0.013380555270503884\n",
      "train loss:0.02274540752856564\n",
      "train loss:0.008453740962386071\n",
      "train loss:0.013003592438506453\n",
      "train loss:0.019792441994172953\n",
      "train loss:0.005046535323319105\n",
      "train loss:0.009950831009089134\n",
      "train loss:0.01925927520691994\n",
      "train loss:0.006958876234700917\n",
      "train loss:0.020994616538458747\n",
      "train loss:0.004647934296921505\n",
      "train loss:0.011160263318319546\n",
      "train loss:0.047102387323366995\n",
      "train loss:0.003361258838974329\n",
      "train loss:0.04999042940284516\n",
      "train loss:0.014715149833409085\n",
      "train loss:0.0023266612106758616\n",
      "train loss:0.033799505405952356\n",
      "train loss:0.0012864477376612021\n",
      "train loss:0.005785858310798775\n",
      "train loss:0.01921950198386202\n",
      "train loss:0.00231252602105706\n",
      "train loss:0.007672486208949717\n",
      "train loss:0.004393708027837435\n",
      "train loss:0.02643756557942558\n",
      "train loss:0.009111202837744449\n",
      "train loss:0.007605302794478671\n",
      "train loss:0.042697663436869746\n",
      "train loss:0.0023781518840274795\n",
      "train loss:0.004497638082701095\n",
      "train loss:0.02994257756253814\n",
      "train loss:0.008342917359803213\n",
      "train loss:0.009799025954966796\n",
      "train loss:0.01237563359326902\n",
      "train loss:0.010784210713901258\n",
      "train loss:0.010738845194008173\n",
      "train loss:0.006101251826858495\n",
      "train loss:0.007922743428351758\n",
      "train loss:0.0051383161757739704\n",
      "train loss:0.0023263039433562478\n",
      "train loss:0.007359916735329968\n",
      "train loss:0.005154587776462141\n",
      "train loss:0.046057456363519184\n",
      "train loss:0.001765947511109451\n",
      "train loss:0.008574488008213595\n",
      "train loss:0.019386082854139137\n",
      "train loss:0.01838919747778169\n",
      "train loss:0.0059706244963408485\n",
      "train loss:0.005306390074315484\n",
      "train loss:0.004691083694718322\n",
      "train loss:0.004892626106346748\n",
      "train loss:0.011638307545845872\n",
      "train loss:0.02231340135382148\n",
      "train loss:0.0029752947849085113\n",
      "train loss:0.0038935120981936785\n",
      "train loss:0.03890024658788352\n",
      "train loss:0.015997808906221385\n",
      "train loss:0.008309641809982676\n",
      "train loss:0.011694897801070619\n",
      "train loss:0.008378534666368063\n",
      "train loss:0.0075042941017348505\n",
      "train loss:0.009227469540930108\n",
      "train loss:0.007494837205143389\n",
      "train loss:0.004224420831077487\n",
      "train loss:0.045499248187745006\n",
      "train loss:0.012626346491579652\n",
      "train loss:0.002024378938048469\n",
      "train loss:0.01578360394226529\n",
      "train loss:0.009518861613760934\n",
      "train loss:0.01043897485664974\n",
      "train loss:0.017770184727435273\n",
      "train loss:0.0515968660662059\n",
      "train loss:0.006339179340380363\n",
      "train loss:0.016510352424231763\n",
      "train loss:0.005656580738906951\n",
      "train loss:0.003999273217404665\n",
      "train loss:0.003924394899489812\n",
      "train loss:0.07004692606460809\n",
      "train loss:0.004919453187895274\n",
      "train loss:0.008204743889491087\n",
      "train loss:0.010961924907254781\n",
      "train loss:0.0010796326926788015\n",
      "train loss:0.031088595581632017\n",
      "train loss:0.04679281751626398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0035061301232521837\n",
      "train loss:0.00844328628712056\n",
      "train loss:0.0219872165706762\n",
      "train loss:0.06750222944607631\n",
      "train loss:0.003416061636633145\n",
      "train loss:0.005802028502217267\n",
      "train loss:0.0036597045858895953\n",
      "train loss:0.001187364494648591\n",
      "train loss:0.006244568328672348\n",
      "train loss:0.0108994145019313\n",
      "train loss:0.005608814115955795\n",
      "train loss:0.02348497333050203\n",
      "train loss:0.003472041987939083\n",
      "train loss:0.003824825935500764\n",
      "train loss:0.009873846999480377\n",
      "train loss:0.0063533821449306225\n",
      "train loss:0.0013051594021675293\n",
      "train loss:0.008371931838971143\n",
      "train loss:0.004040946444184071\n",
      "train loss:0.004749285749596353\n",
      "train loss:0.04402889512616224\n",
      "train loss:0.03630149200247183\n",
      "train loss:0.0021089170181708035\n",
      "train loss:0.004505756472800258\n",
      "train loss:0.00833043913742258\n",
      "train loss:0.00436691802477496\n",
      "train loss:0.021829154598125924\n",
      "train loss:0.016793225323337546\n",
      "train loss:0.0015351357157346052\n",
      "train loss:0.020630746040086696\n",
      "train loss:0.022697423010643137\n",
      "train loss:0.006455024106276446\n",
      "train loss:0.004205769089280927\n",
      "train loss:0.005261783298094501\n",
      "train loss:0.004998168815444655\n",
      "train loss:0.007125258513203556\n",
      "train loss:0.009337240432856575\n",
      "train loss:0.004101565171960625\n",
      "train loss:0.004011089368677152\n",
      "train loss:0.0089100764180398\n",
      "train loss:0.006252485415107456\n",
      "train loss:0.005635540747110904\n",
      "train loss:0.007556930712999767\n",
      "train loss:0.012959677356483503\n",
      "train loss:0.007961784320764175\n",
      "train loss:0.007855323466203174\n",
      "train loss:0.0017439774668814726\n",
      "train loss:0.004266516155748183\n",
      "train loss:0.005973206382657479\n",
      "train loss:0.01466373242224698\n",
      "train loss:0.01632628711051967\n",
      "train loss:0.009484125132441894\n",
      "train loss:0.0016231100450294126\n",
      "train loss:0.0061565320156074755\n",
      "train loss:0.002702517386480961\n",
      "train loss:0.01109132363377927\n",
      "train loss:0.001546009987642666\n",
      "train loss:0.0012954476167604295\n",
      "train loss:0.001911270523633997\n",
      "train loss:0.01608552107291589\n",
      "train loss:0.03249791946798071\n",
      "train loss:0.004339616669888573\n",
      "train loss:0.013775225150943845\n",
      "train loss:0.0010428597830964195\n",
      "train loss:0.030065979482630154\n",
      "train loss:0.0016892882605927641\n",
      "train loss:0.017887655507321586\n",
      "train loss:0.006900377883130632\n",
      "train loss:0.007113347917554405\n",
      "train loss:0.009847356617921115\n",
      "train loss:0.004287776214638759\n",
      "train loss:0.009076298798167381\n",
      "train loss:0.00833746948299689\n",
      "train loss:0.0224971623903775\n",
      "train loss:0.00846554290358863\n",
      "train loss:0.06663205310283493\n",
      "train loss:0.014591402076953834\n",
      "train loss:0.0015264460589683518\n",
      "train loss:0.04272151794391095\n",
      "train loss:0.013221906070192352\n",
      "train loss:0.014043210346364195\n",
      "train loss:0.008101812700401823\n",
      "train loss:0.00883250169977327\n",
      "train loss:0.003215543247686176\n",
      "train loss:0.02488861652174723\n",
      "train loss:0.005156848344787541\n",
      "train loss:0.002789175932715079\n",
      "train loss:0.004861077046346432\n",
      "train loss:0.008012284372508333\n",
      "train loss:0.0056359598561442955\n",
      "train loss:0.00544420495235174\n",
      "train loss:0.007945622548785532\n",
      "train loss:0.00471789457743404\n",
      "train loss:0.022345789684731297\n",
      "train loss:0.036415775147750275\n",
      "train loss:0.008007775028147444\n",
      "train loss:0.009073540721425992\n",
      "train loss:0.015803158731282626\n",
      "train loss:0.0035015299224860647\n",
      "train loss:0.02633080416184406\n",
      "train loss:0.015903148718884465\n",
      "train loss:0.015228689709329737\n",
      "train loss:0.003995794622585583\n",
      "train loss:0.019055496587324063\n",
      "train loss:0.03230063794911551\n",
      "train loss:0.006096975686533891\n",
      "train loss:0.00567525490227506\n",
      "train loss:0.013117941872511401\n",
      "train loss:0.0018018125872263124\n",
      "train loss:0.012106114772520432\n",
      "train loss:0.003750836460796944\n",
      "train loss:0.0018042057121073047\n",
      "train loss:0.005237179768703542\n",
      "train loss:0.005698940018701458\n",
      "train loss:0.012468649624951407\n",
      "train loss:0.03777234427901158\n",
      "train loss:0.024887282952367945\n",
      "train loss:0.01692283922372219\n",
      "train loss:0.008562597330592656\n",
      "train loss:0.003878983601668525\n",
      "train loss:0.005194601631825942\n",
      "train loss:0.008658799564908188\n",
      "train loss:0.016032591239489753\n",
      "train loss:0.011127885066464767\n",
      "train loss:0.009940268969455743\n",
      "train loss:0.0013646565423093401\n",
      "train loss:0.0347997361168533\n",
      "train loss:0.00875719406687842\n",
      "train loss:0.009744323477981471\n",
      "train loss:0.0020787494165913586\n",
      "train loss:0.004647722284955238\n",
      "train loss:0.016596514890439874\n",
      "train loss:0.005174797692164133\n",
      "train loss:0.016815575665920388\n",
      "train loss:0.007450289400946192\n",
      "train loss:0.027186579157671368\n",
      "train loss:0.008286786095027447\n",
      "train loss:0.004164483056170848\n",
      "train loss:0.010903480986994006\n",
      "train loss:0.00497187180729329\n",
      "train loss:0.013341321616941564\n",
      "train loss:0.007473042296512723\n",
      "train loss:0.005094456237899824\n",
      "train loss:0.002684681898395236\n",
      "train loss:0.010448736005212855\n",
      "train loss:0.00534896950645013\n",
      "train loss:0.014695829837985994\n",
      "train loss:0.009378642356105513\n",
      "train loss:0.05485970085826171\n",
      "train loss:0.001492894061908706\n",
      "train loss:0.003906900212720962\n",
      "train loss:0.009584046248373272\n",
      "train loss:0.008368853310703868\n",
      "train loss:0.011445146604035072\n",
      "train loss:0.003088762343835287\n",
      "train loss:0.005465301603181294\n",
      "train loss:0.004011417798158396\n",
      "train loss:0.00590122483806944\n",
      "train loss:0.008708576310684397\n",
      "train loss:0.008471130677375068\n",
      "train loss:0.0007076672954028998\n",
      "train loss:0.0031166570032101896\n",
      "train loss:0.0055406450582094645\n",
      "train loss:0.004271354256311872\n",
      "train loss:0.0022635538782340716\n",
      "train loss:0.023094401532913648\n",
      "train loss:0.005253811082222955\n",
      "train loss:0.030684212693945088\n",
      "train loss:0.021808821701041106\n",
      "train loss:0.005147973337685361\n",
      "train loss:0.01784184044831009\n",
      "train loss:0.030778818284064036\n",
      "train loss:0.021042024521919233\n",
      "train loss:0.0069609804104930695\n",
      "train loss:0.03961869838784328\n",
      "train loss:0.007587636905732612\n",
      "train loss:0.027357612576488423\n",
      "train loss:0.008558391187733324\n",
      "=== epoch:10, train acc:0.99, test acc:0.984 ===\n",
      "train loss:0.005348708425388069\n",
      "train loss:0.037115195053853696\n",
      "train loss:0.003080643713907447\n",
      "train loss:0.007444854506667471\n",
      "train loss:0.0042343820124182\n",
      "train loss:0.004196075091663784\n",
      "train loss:0.001653022389186456\n",
      "train loss:0.005719026774282837\n",
      "train loss:0.012398308489234186\n",
      "train loss:0.01596341939586859\n",
      "train loss:0.006472520207696603\n",
      "train loss:0.0033461468391591353\n",
      "train loss:0.0026279359325001544\n",
      "train loss:0.0013504591203787769\n",
      "train loss:0.0020504839273825207\n",
      "train loss:0.011575274629459112\n",
      "train loss:0.005676292479514431\n",
      "train loss:0.007286262086610833\n",
      "train loss:0.01850132722362755\n",
      "train loss:0.003016723988721822\n",
      "train loss:0.003869503606482844\n",
      "train loss:0.003561959433505692\n",
      "train loss:0.00243497256850433\n",
      "train loss:0.0035281233925252738\n",
      "train loss:0.0053009625641352864\n",
      "train loss:0.025828847399305868\n",
      "train loss:0.007257322527010821\n",
      "train loss:0.006218424695234172\n",
      "train loss:0.0028035621165523788\n",
      "train loss:0.0076730518766374\n",
      "train loss:0.002367925435675278\n",
      "train loss:0.0032156426506285557\n",
      "train loss:0.017057586904009568\n",
      "train loss:0.029494996298249535\n",
      "train loss:0.005918985689850483\n",
      "train loss:0.06384689614450183\n",
      "train loss:0.004452901163827227\n",
      "train loss:0.007074856663134935\n",
      "train loss:0.003669518768549691\n",
      "train loss:0.004028841911421474\n",
      "train loss:0.015999953218627253\n",
      "train loss:0.010479596561863985\n",
      "train loss:0.00552736820807352\n",
      "train loss:0.03235081738191417\n",
      "train loss:0.009942903038510894\n",
      "train loss:0.08030109950763734\n",
      "train loss:0.01224738473213465\n",
      "train loss:0.007227774803634408\n",
      "train loss:0.014244767259373247\n",
      "train loss:0.01847163826623222\n",
      "train loss:0.05351831589900252\n",
      "train loss:0.003263743327844719\n",
      "train loss:0.014561975809102066\n",
      "train loss:0.004412530761010116\n",
      "train loss:0.0012982056580277722\n",
      "train loss:0.009279780428344058\n",
      "train loss:0.0020544655188576397\n",
      "train loss:0.02312129524595392\n",
      "train loss:0.009043822129620096\n",
      "train loss:0.002732911203710111\n",
      "train loss:0.011576510170294114\n",
      "train loss:0.003086215838921154\n",
      "train loss:0.008248769936896563\n",
      "train loss:0.005761079823369713\n",
      "train loss:0.007591887349048594\n",
      "train loss:0.007812670441261918\n",
      "train loss:0.006226828104302844\n",
      "train loss:0.01401559135668436\n",
      "train loss:0.039360350925800425\n",
      "train loss:0.0917855228977356\n",
      "train loss:0.010923879182101463\n",
      "train loss:0.0026723100194794304\n",
      "train loss:0.004142228512919391\n",
      "train loss:0.011933326742613899\n",
      "train loss:0.01297310312184207\n",
      "train loss:0.001724596123439414\n",
      "train loss:0.0030572312659432506\n",
      "train loss:0.02037474829128077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08225538296392816\n",
      "train loss:0.012759067618569238\n",
      "train loss:0.004662001273007559\n",
      "train loss:0.01407126412444078\n",
      "train loss:0.00897937231070361\n",
      "train loss:0.004518103084217621\n",
      "train loss:0.0040442794755732895\n",
      "train loss:0.005866553242521625\n",
      "train loss:0.0008764906454928944\n",
      "train loss:0.009090608109251882\n",
      "train loss:0.0005510769740351754\n",
      "train loss:0.004492159207355577\n",
      "train loss:0.006500534088138281\n",
      "train loss:0.021141049158282865\n",
      "train loss:0.05223484178986773\n",
      "train loss:0.004399026270191768\n",
      "train loss:0.001606484812791269\n",
      "train loss:0.0032494833906646647\n",
      "train loss:0.0008201427608236127\n",
      "train loss:0.017146161938166527\n",
      "train loss:0.012805360633484504\n",
      "train loss:0.002915347089155689\n",
      "train loss:0.011327944422950815\n",
      "train loss:0.0038316775941021025\n",
      "train loss:0.008082621530251306\n",
      "train loss:0.00905199762820479\n",
      "train loss:0.02230415380582045\n",
      "train loss:0.003226591993749231\n",
      "train loss:0.0036443389948718143\n",
      "train loss:0.014391301345877284\n",
      "train loss:0.003246647236340428\n",
      "train loss:0.04651440621518612\n",
      "train loss:0.0015092098733914924\n",
      "train loss:0.02308369233225034\n",
      "train loss:0.051685141100836975\n",
      "train loss:0.0020122930731472323\n",
      "train loss:0.0015180910002374072\n",
      "train loss:0.0005571601385067298\n",
      "train loss:0.006703436937891082\n",
      "train loss:0.024959701321610486\n",
      "train loss:0.013207325994924198\n",
      "train loss:0.00345980305220141\n",
      "train loss:0.0020857714702467575\n",
      "train loss:0.005758447901548946\n",
      "train loss:0.008734560905071916\n",
      "train loss:0.0014598912679745484\n",
      "train loss:0.012970242788239524\n",
      "train loss:0.004272263521482537\n",
      "train loss:0.010844357524099046\n",
      "train loss:0.01015610880802186\n",
      "train loss:0.013322535543239582\n",
      "train loss:0.01648971938182561\n",
      "train loss:0.0025210036423997796\n",
      "train loss:0.0028426749881640513\n",
      "train loss:0.008312432455729024\n",
      "train loss:0.002224777314121433\n",
      "train loss:0.001575497567983665\n",
      "train loss:0.0023357990449224984\n",
      "train loss:0.005258576763127024\n",
      "train loss:0.002369783423571763\n",
      "train loss:0.009747219984900078\n",
      "train loss:0.013160171859214323\n",
      "train loss:0.006717112122875042\n",
      "train loss:0.004878403529249268\n",
      "train loss:0.00566702369889176\n",
      "train loss:0.000642321141679995\n",
      "train loss:0.006915799782328231\n",
      "train loss:0.0028636614915193907\n",
      "train loss:0.0044732559995588495\n",
      "train loss:0.001779251103632527\n",
      "train loss:0.1498340005843449\n",
      "train loss:0.00839700779926474\n",
      "train loss:0.0008993583750761315\n",
      "train loss:0.016958652222842416\n",
      "train loss:0.06560389717622087\n",
      "train loss:0.007886346849497893\n",
      "train loss:0.002050716700324922\n",
      "train loss:0.027174932722889636\n",
      "train loss:0.0012819851437847953\n",
      "train loss:0.007276214355358642\n",
      "train loss:0.007266321118307356\n",
      "train loss:0.005932258240384426\n",
      "train loss:0.0007644469003524806\n",
      "train loss:0.0034111135663378277\n",
      "train loss:0.004499623126994834\n",
      "train loss:0.023261924831922326\n",
      "train loss:0.007963039749850265\n",
      "train loss:0.005810156331580902\n",
      "train loss:0.00601743774010693\n",
      "train loss:0.009212425377376897\n",
      "train loss:0.0034919707244881375\n",
      "train loss:0.0020950914271818544\n",
      "train loss:0.00854765991911765\n",
      "train loss:0.004707484285550257\n",
      "train loss:0.014661469115528876\n",
      "train loss:0.006844441576146781\n",
      "train loss:0.0023063600257153495\n",
      "train loss:0.018882111804908303\n",
      "train loss:0.005119761324282704\n",
      "train loss:0.0059594986073082164\n",
      "train loss:0.002096874257036263\n",
      "train loss:0.004160720294820352\n",
      "train loss:0.002018368931265813\n",
      "train loss:0.012315369163083229\n",
      "train loss:0.0129319766768956\n",
      "train loss:0.0053823190772605235\n",
      "train loss:0.0076606869723419855\n",
      "train loss:0.0015239218544892017\n",
      "train loss:0.01614860263409384\n",
      "train loss:0.009843964107981438\n",
      "train loss:0.001115851435339431\n",
      "train loss:0.001467366538246227\n",
      "train loss:0.02402722641450923\n",
      "train loss:0.005232965659710047\n",
      "train loss:0.0061759050219855685\n",
      "train loss:0.001864241919673679\n",
      "train loss:0.002005046194973022\n",
      "train loss:0.0028978959987749748\n",
      "train loss:0.0033250761668501883\n",
      "train loss:0.038004657821797155\n",
      "train loss:0.0029368740296001265\n",
      "train loss:0.005078749209332025\n",
      "train loss:0.006369045817873298\n",
      "train loss:0.027648029433700504\n",
      "train loss:0.0068637539784433665\n",
      "train loss:0.011457337277976556\n",
      "train loss:0.0026575072621123413\n",
      "train loss:0.026697996681153278\n",
      "train loss:0.039566739471633736\n",
      "train loss:0.028592695947684304\n",
      "train loss:0.00825517532606894\n",
      "train loss:0.018878870808694874\n",
      "train loss:0.0020931431712691976\n",
      "train loss:0.07166218704834301\n",
      "train loss:0.004367479153606706\n",
      "train loss:0.0033339486204292026\n",
      "train loss:0.004365717076593544\n",
      "train loss:0.005251596300472409\n",
      "train loss:0.020659281385072385\n",
      "train loss:0.010675797144768174\n",
      "train loss:0.00348887488184075\n",
      "train loss:0.004336902075104686\n",
      "train loss:0.006677068273287955\n",
      "train loss:0.004539465703181211\n",
      "train loss:0.01314594990496243\n",
      "train loss:0.01594571585535995\n",
      "train loss:0.003435956760875981\n",
      "train loss:0.004518610669059927\n",
      "train loss:0.007086479610763573\n",
      "train loss:0.0009161620169674149\n",
      "train loss:0.01188172120271516\n",
      "train loss:0.004692846086386545\n",
      "train loss:0.015348570385135875\n",
      "train loss:0.010308528548453821\n",
      "train loss:0.02483001881381496\n",
      "train loss:0.011463784432359951\n",
      "train loss:0.0022730984368354414\n",
      "train loss:0.00961298680488144\n",
      "train loss:0.010643756639985071\n",
      "train loss:0.007593242666629985\n",
      "train loss:0.05623165480751743\n",
      "train loss:0.0022001780700924307\n",
      "train loss:0.030115428655164617\n",
      "train loss:0.031803214832128134\n",
      "train loss:0.003434468591844767\n",
      "train loss:0.05229343278766819\n",
      "train loss:0.0022827657236247968\n",
      "train loss:0.010225269108772177\n",
      "train loss:0.003641918098375147\n",
      "train loss:0.00773394583185785\n",
      "train loss:0.005823710013336489\n",
      "train loss:0.0007281235680674117\n",
      "train loss:0.006780460345604939\n",
      "train loss:0.00540432752384825\n",
      "train loss:0.005313366157694951\n",
      "train loss:0.005899681123616935\n",
      "train loss:0.009141822859196387\n",
      "train loss:0.019114930077586207\n",
      "train loss:0.0032095841151798267\n",
      "train loss:0.0030982956209281874\n",
      "train loss:0.01477987194439165\n",
      "train loss:0.009208419853223425\n",
      "train loss:0.01153208928877674\n",
      "train loss:0.02141220934155661\n",
      "train loss:0.01672240706075115\n",
      "train loss:0.0071619974886317165\n",
      "train loss:0.011143551287339857\n",
      "train loss:0.02246208226169515\n",
      "train loss:0.0037782239021522663\n",
      "train loss:0.012514801237881576\n",
      "train loss:0.017100015389672277\n",
      "train loss:0.016951047779504326\n",
      "train loss:0.00916604449767915\n",
      "train loss:0.002744171891678173\n",
      "train loss:0.003091264272537106\n",
      "train loss:0.0018186678735184895\n",
      "train loss:0.006487026984941514\n",
      "train loss:0.006454498623956861\n",
      "train loss:0.002282218743390429\n",
      "train loss:0.013162344441980561\n",
      "train loss:0.006151386529656542\n",
      "train loss:0.04660491951394962\n",
      "train loss:0.0030759373656310766\n",
      "train loss:0.005490029453558009\n",
      "train loss:0.008758094116951469\n",
      "train loss:0.01187132314490096\n",
      "train loss:0.008384362332797836\n",
      "train loss:0.00518774872590877\n",
      "train loss:0.03465819372129846\n",
      "train loss:0.015391295767530493\n",
      "train loss:0.015081619156348225\n",
      "train loss:0.005359784398928485\n",
      "train loss:0.009442774082233383\n",
      "train loss:0.012962374229008635\n",
      "train loss:0.0019728186368412823\n",
      "train loss:0.00291971022540201\n",
      "train loss:0.004388866239632567\n",
      "train loss:0.011996766658691666\n",
      "train loss:0.012324846634634077\n",
      "train loss:0.010737607023619757\n",
      "train loss:0.008680426957346572\n",
      "train loss:0.01118465555154829\n",
      "train loss:0.004635503567466514\n",
      "train loss:0.0015264307786725404\n",
      "train loss:0.00290935241684305\n",
      "train loss:0.002872684580214859\n",
      "train loss:0.01307886397071342\n",
      "train loss:0.003863651957474829\n",
      "train loss:0.002275275163244825\n",
      "train loss:0.009466344716261411\n",
      "train loss:0.0010270450938846627\n",
      "train loss:0.015330457934650368\n",
      "train loss:0.020591762621768667\n",
      "train loss:0.008442641763553997\n",
      "train loss:0.010858629173629508\n",
      "train loss:0.023433935317326186\n",
      "train loss:0.003054566961162337\n",
      "train loss:0.003225490067251898\n",
      "train loss:0.0032143563973233945\n",
      "train loss:0.016878581320483855\n",
      "train loss:0.0063030862012831675\n",
      "train loss:0.0026065885996053896\n",
      "train loss:0.0038110859316906835\n",
      "train loss:0.014014244076216185\n",
      "train loss:0.003468804702982559\n",
      "train loss:0.011021268465001836\n",
      "train loss:0.020820472420573357\n",
      "train loss:0.012438130473179097\n",
      "train loss:0.07381586533822762\n",
      "train loss:0.01372608888961275\n",
      "train loss:0.02190907667304172\n",
      "train loss:0.003938170371484844\n",
      "train loss:0.003164063869021232\n",
      "train loss:0.0033363259286151386\n",
      "train loss:0.0036292533194714704\n",
      "train loss:0.001295137199445707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012079250304163756\n",
      "train loss:0.010788770634588718\n",
      "train loss:0.02199631313662591\n",
      "train loss:0.0038600927434010294\n",
      "train loss:0.008918176000829748\n",
      "train loss:0.008674257139129525\n",
      "train loss:0.03261465077767374\n",
      "train loss:0.012115444015974773\n",
      "train loss:0.00713071811314418\n",
      "train loss:0.0012363159213723792\n",
      "train loss:0.02131046192931434\n",
      "train loss:0.008438003821108585\n",
      "train loss:0.02974355915174211\n",
      "train loss:0.012270329698585688\n",
      "train loss:0.003546258018240445\n",
      "train loss:0.004794265280531552\n",
      "train loss:0.0014846889794897324\n",
      "train loss:0.005436098365542062\n",
      "train loss:0.009150179795389334\n",
      "train loss:0.045139043415100326\n",
      "train loss:0.0086202824492236\n",
      "train loss:0.004563874314001605\n",
      "train loss:0.02078921717595552\n",
      "train loss:0.009386729753629065\n",
      "train loss:0.005902720322337395\n",
      "train loss:0.0007456522405769647\n",
      "train loss:0.001500356046451145\n",
      "train loss:0.013329226372240979\n",
      "train loss:0.011755593926919742\n",
      "train loss:0.008295873586157427\n",
      "train loss:0.020182612719393617\n",
      "train loss:0.001045872887165109\n",
      "train loss:0.02343238003507416\n",
      "train loss:0.007718593852863811\n",
      "train loss:0.005163015566011168\n",
      "train loss:0.004160012322605528\n",
      "train loss:0.004147350554244328\n",
      "train loss:0.016346931692924713\n",
      "train loss:0.006228025281069734\n",
      "train loss:0.004251555676131473\n",
      "train loss:0.003957178525038067\n",
      "train loss:0.007127346538233084\n",
      "train loss:0.002485986680168291\n",
      "train loss:0.0038066081538063144\n",
      "train loss:0.00825069955627579\n",
      "train loss:0.0288870532622108\n",
      "train loss:0.009613599028367687\n",
      "train loss:0.0057925413807072765\n",
      "train loss:0.007398062447089046\n",
      "train loss:0.0035234251365832132\n",
      "train loss:0.027217244137076328\n",
      "train loss:0.00624438491198096\n",
      "train loss:0.007914434691989457\n",
      "train loss:0.005304151171990146\n",
      "train loss:0.003614936199248298\n",
      "train loss:0.019084444050158376\n",
      "train loss:0.0016075252389266639\n",
      "train loss:0.002448595650525632\n",
      "train loss:0.0015704689116373574\n",
      "train loss:0.0019025200553488089\n",
      "train loss:0.008685906248309033\n",
      "train loss:0.008048665417495864\n",
      "train loss:0.004498237409606765\n",
      "train loss:0.05810306447305919\n",
      "train loss:0.0031512224822750905\n",
      "train loss:0.015932019751797435\n",
      "train loss:0.018671509448228804\n",
      "train loss:0.003981063743271725\n",
      "train loss:0.0018349824024743774\n",
      "train loss:0.02858940160681568\n",
      "train loss:0.02434731415844149\n",
      "train loss:0.003846485128427479\n",
      "train loss:0.009986976480880694\n",
      "train loss:0.011614680095602964\n",
      "train loss:0.004717259638523189\n",
      "train loss:0.0014417513302597137\n",
      "train loss:0.0053879941642887876\n",
      "train loss:0.0005723206994863781\n",
      "train loss:0.0028933287179193235\n",
      "train loss:0.0024044765725421123\n",
      "train loss:0.004145193389422007\n",
      "train loss:0.006191144593895252\n",
      "train loss:0.007150028856399858\n",
      "train loss:0.008187655130529346\n",
      "train loss:0.0030476826281414554\n",
      "train loss:0.0032592844905547608\n",
      "train loss:0.007858601058798065\n",
      "train loss:0.006780423247172195\n",
      "train loss:0.006405507488288727\n",
      "train loss:0.002950090421218352\n",
      "train loss:0.002148609871126688\n",
      "train loss:0.015451163021923621\n",
      "train loss:0.006265604749039339\n",
      "train loss:0.004522248439836635\n",
      "train loss:0.002520866833287106\n",
      "train loss:0.01037160178582621\n",
      "train loss:0.026369340792629297\n",
      "train loss:0.01804592958711914\n",
      "train loss:0.006123290224263651\n",
      "train loss:0.003406036507453436\n",
      "train loss:0.00406439793152156\n",
      "train loss:0.0017305916262128427\n",
      "train loss:0.004833151095674379\n",
      "train loss:0.04788344618096715\n",
      "train loss:0.007729679665269223\n",
      "train loss:0.0008288601161220535\n",
      "train loss:0.00535802136094109\n",
      "train loss:0.00303100394173313\n",
      "train loss:0.0010200341920529453\n",
      "train loss:0.007695536174447588\n",
      "train loss:0.0514489532847354\n",
      "train loss:0.00444510163436516\n",
      "train loss:0.010980274540568668\n",
      "train loss:0.002536038175159035\n",
      "train loss:0.023501551696057735\n",
      "train loss:0.010590272072004012\n",
      "train loss:0.01898399832937324\n",
      "train loss:0.03608555022962891\n",
      "train loss:0.004984172692614381\n",
      "train loss:0.0007853484343775177\n",
      "train loss:0.005052311335173748\n",
      "train loss:0.01878473469689339\n",
      "train loss:0.008296504820050076\n",
      "train loss:0.02041127202061156\n",
      "train loss:0.002114544776190944\n",
      "train loss:0.01671511482443734\n",
      "train loss:0.009798524119866649\n",
      "train loss:0.0056733322123091005\n",
      "train loss:0.022249834707396606\n",
      "train loss:0.008801183178839012\n",
      "train loss:0.02162789103107313\n",
      "train loss:0.007250291882210264\n",
      "train loss:0.05403180211298587\n",
      "train loss:0.09398412399897867\n",
      "train loss:0.011207985460828964\n",
      "train loss:0.0017758584756723587\n",
      "train loss:0.015100944740022007\n",
      "train loss:0.006466359582534938\n",
      "train loss:0.008786737421153558\n",
      "train loss:0.0018309215649095528\n",
      "train loss:0.029865450729611297\n",
      "train loss:0.022184155418442403\n",
      "train loss:0.01125313009445591\n",
      "train loss:0.009018509117507989\n",
      "train loss:0.006929770720192125\n",
      "train loss:0.009168264977494336\n",
      "train loss:0.002182689203414645\n",
      "train loss:0.0067841804995009015\n",
      "train loss:0.005504310905280692\n",
      "train loss:0.03668896458802\n",
      "train loss:0.06409828335930015\n",
      "train loss:0.02004069367872235\n",
      "train loss:0.016187868733048734\n",
      "train loss:0.006738123001194766\n",
      "train loss:0.06523862714277465\n",
      "train loss:0.02224134532039507\n",
      "train loss:0.006027056315805219\n",
      "train loss:0.006035407849323516\n",
      "train loss:0.04464465851892445\n",
      "train loss:0.0053671787161708095\n",
      "train loss:0.007855676732028227\n",
      "train loss:0.006877717071368281\n",
      "train loss:0.023269179857996834\n",
      "train loss:0.005192780238484025\n",
      "train loss:0.008229375810582116\n",
      "train loss:0.005399377738810286\n",
      "train loss:0.007499934198687488\n",
      "train loss:0.030151442049209182\n",
      "train loss:0.005012957798605159\n",
      "train loss:0.006774637537018105\n",
      "train loss:0.010805978556281341\n",
      "train loss:0.030294624827571573\n",
      "train loss:0.011970490250744014\n",
      "train loss:0.06279446490618742\n",
      "train loss:0.004706139422786396\n",
      "train loss:0.005606342798533269\n",
      "train loss:0.007202201131582058\n",
      "train loss:0.015692415858189767\n",
      "train loss:0.0056662067200934\n",
      "train loss:0.01039274091022897\n",
      "train loss:0.011437020304866359\n",
      "train loss:0.05018065053357141\n",
      "train loss:0.0031865881455150485\n",
      "train loss:0.007485409213409299\n",
      "train loss:0.0026951397650259003\n",
      "train loss:0.019528366979611265\n",
      "train loss:0.017912296865799798\n",
      "train loss:0.008859732043806414\n",
      "train loss:0.021684253396524883\n",
      "train loss:0.00851520583247107\n",
      "train loss:0.0013479628026205337\n",
      "train loss:0.005324948037546031\n",
      "train loss:0.0024983685714219522\n",
      "train loss:0.06012147996758374\n",
      "train loss:0.005609298761410664\n",
      "train loss:0.004141159280537695\n",
      "train loss:0.0029729722762082554\n",
      "train loss:0.007953440917903955\n",
      "train loss:0.0019595543308543574\n",
      "train loss:0.0061904150839960995\n",
      "train loss:0.013133063919438876\n",
      "train loss:0.03184905472249923\n",
      "train loss:0.05725665133279476\n",
      "train loss:0.045915382450241904\n",
      "train loss:0.0015434238964201013\n",
      "train loss:0.000616430090172505\n",
      "train loss:0.0019961731363377804\n",
      "train loss:0.005614135652849359\n",
      "train loss:0.003971861480143291\n",
      "train loss:0.001612424545144569\n",
      "train loss:0.016114570965773248\n",
      "train loss:0.004482929018995621\n",
      "train loss:0.0036449270477290265\n",
      "train loss:0.019445502254576016\n",
      "train loss:0.00485450257096728\n",
      "train loss:0.01665982614222993\n",
      "train loss:0.017614015947260718\n",
      "train loss:0.019447417183894807\n",
      "train loss:0.00142775819629103\n",
      "train loss:0.003440894988025116\n",
      "train loss:0.0038085731608772633\n",
      "train loss:0.010659944200187463\n",
      "train loss:0.005831184292781983\n",
      "train loss:0.010590340988374964\n",
      "train loss:0.0053391460460439286\n",
      "train loss:0.014381129056252762\n",
      "train loss:0.0011790795478505988\n",
      "train loss:0.0033176275713462976\n",
      "train loss:0.011744344193475854\n",
      "train loss:0.016122426639500458\n",
      "train loss:0.0051134350864783015\n",
      "train loss:0.01587374543799145\n",
      "train loss:0.007702898250636457\n",
      "train loss:0.0038817929670573494\n",
      "train loss:0.002724749571480908\n",
      "train loss:0.0038221422640445334\n",
      "train loss:0.021964116039360982\n",
      "train loss:0.0049811328525208014\n",
      "train loss:0.004683703672643515\n",
      "train loss:0.003476142709490295\n",
      "train loss:0.0035021480756626568\n",
      "train loss:0.0023798114881985006\n",
      "train loss:0.005838268997999508\n",
      "train loss:0.004284250976989706\n",
      "train loss:0.0019872408979848236\n",
      "train loss:0.0037072442379516056\n",
      "train loss:0.003485919805942588\n",
      "train loss:0.0010212662190369102\n",
      "train loss:0.005159843985883308\n",
      "train loss:0.019862118717446267\n",
      "train loss:0.006850602316496102\n",
      "train loss:0.00183052845125764\n",
      "train loss:0.004714081550504295\n",
      "train loss:0.005687412603261113\n",
      "train loss:0.0030212426260399932\n",
      "train loss:0.00029292161997586505\n",
      "train loss:0.006710597785799089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0048462804716621925\n",
      "train loss:0.0033297380251873913\n",
      "train loss:0.005659082247094398\n",
      "train loss:0.0019628925040363425\n",
      "train loss:0.018996894599921738\n",
      "train loss:0.02004976755368432\n",
      "train loss:0.011326431288499916\n",
      "train loss:0.038831733733838886\n",
      "train loss:0.010886026299309359\n",
      "=== epoch:11, train acc:0.993, test acc:0.987 ===\n",
      "train loss:0.007757396602594128\n",
      "train loss:0.027694483814314445\n",
      "train loss:0.001854631583722359\n",
      "train loss:0.0023148186755865574\n",
      "train loss:0.022783131860954885\n",
      "train loss:0.005369144409435356\n",
      "train loss:0.01305279257400261\n",
      "train loss:0.00612005504322645\n",
      "train loss:0.004049986720401767\n",
      "train loss:0.0039391725795692245\n",
      "train loss:0.005203847198696646\n",
      "train loss:0.00922874958092187\n",
      "train loss:0.008472135447139682\n",
      "train loss:0.010233032124597481\n",
      "train loss:0.005578666379792139\n",
      "train loss:0.0017789180858695996\n",
      "train loss:0.0030165351215495446\n",
      "train loss:0.012956524694715157\n",
      "train loss:0.0010958914455251074\n",
      "train loss:0.008231423457831254\n",
      "train loss:0.008378405623143445\n",
      "train loss:0.06476596577847563\n",
      "train loss:0.010487879260253057\n",
      "train loss:0.001153969028808247\n",
      "train loss:0.01168315565838212\n",
      "train loss:0.019388884074971226\n",
      "train loss:0.02349020271927332\n",
      "train loss:0.0069019435662083595\n",
      "train loss:0.006340446533086587\n",
      "train loss:0.0070688264287653265\n",
      "train loss:0.008253253825626264\n",
      "train loss:0.011965093760021459\n",
      "train loss:0.012360188976242591\n",
      "train loss:0.005553356715808127\n",
      "train loss:0.016465050206916125\n",
      "train loss:0.00260660789132942\n",
      "train loss:0.004262284392969675\n",
      "train loss:0.009344662701365284\n",
      "train loss:0.0043497937938131465\n",
      "train loss:0.003497847963183684\n",
      "train loss:0.028573309421039767\n",
      "train loss:0.003285952666646058\n",
      "train loss:0.0016300073049594942\n",
      "train loss:0.010199426999300251\n",
      "train loss:0.010496445984717346\n",
      "train loss:0.002360867306429097\n",
      "train loss:0.004785805854299493\n",
      "train loss:0.0021930700869440285\n",
      "train loss:0.002349964751324819\n",
      "train loss:0.003065210695091616\n",
      "train loss:0.00088394932073329\n",
      "train loss:0.010734847671208005\n",
      "train loss:0.013069815209196431\n",
      "train loss:0.013035245368224728\n",
      "train loss:0.00048427945631601384\n",
      "train loss:0.013061939428496063\n",
      "train loss:0.008724190859447057\n",
      "train loss:0.0010688999578332204\n",
      "train loss:0.04188307038979964\n",
      "train loss:0.0027746376105399063\n",
      "train loss:0.002529552612816504\n",
      "train loss:0.009211807380950504\n",
      "train loss:0.0021122216133820557\n",
      "train loss:0.0015308153297146077\n",
      "train loss:0.021035615867295562\n",
      "train loss:0.0073133262546877\n",
      "train loss:0.02766125626847793\n",
      "train loss:0.00737771049300326\n",
      "train loss:0.00035593500932621974\n",
      "train loss:0.0005558088967985411\n",
      "train loss:0.0034281316872990545\n",
      "train loss:0.003850468234368009\n",
      "train loss:0.003990580083824149\n",
      "train loss:0.005793276891357001\n",
      "train loss:0.0012793908970010898\n",
      "train loss:0.009835871173802602\n",
      "train loss:0.006742672554964014\n",
      "train loss:0.009172749412689718\n",
      "train loss:0.0009170810470104392\n",
      "train loss:0.0013599777616477837\n",
      "train loss:0.03461962008312968\n",
      "train loss:0.001674756034488852\n",
      "train loss:0.0015614000511248389\n",
      "train loss:0.0072021253084880036\n",
      "train loss:0.006212144429572411\n",
      "train loss:0.003243158070239669\n",
      "train loss:0.003622436644872446\n",
      "train loss:0.0034564864959766677\n",
      "train loss:0.0072084789667701986\n",
      "train loss:0.0022750754333088277\n",
      "train loss:0.040536175977901795\n",
      "train loss:0.008332098557221593\n",
      "train loss:0.007521231599145795\n",
      "train loss:0.009116198360455373\n",
      "train loss:0.0045307515361094515\n",
      "train loss:0.012223751903361356\n",
      "train loss:0.003936725088241855\n",
      "train loss:0.032408155354156795\n",
      "train loss:0.0016583032072770448\n",
      "train loss:0.04950979704424226\n",
      "train loss:0.010716271100206983\n",
      "train loss:0.004907944269355854\n",
      "train loss:0.0070164533666858256\n",
      "train loss:0.003976776011468314\n",
      "train loss:0.004732931988330345\n",
      "train loss:0.0055487383855423456\n",
      "train loss:0.009190048463730605\n",
      "train loss:0.005570918041773561\n",
      "train loss:0.0006442258830783281\n",
      "train loss:0.06789540479167677\n",
      "train loss:0.01320631121024954\n",
      "train loss:0.00208365837889778\n",
      "train loss:0.05004788895286136\n",
      "train loss:0.04900952147336796\n",
      "train loss:0.0024716752085502903\n",
      "train loss:0.0014253045044120463\n",
      "train loss:0.003349697636362174\n",
      "train loss:0.0035562055597379706\n",
      "train loss:0.03852954364840768\n",
      "train loss:0.01007757280212506\n",
      "train loss:0.003976751903090046\n",
      "train loss:0.005192480246306757\n",
      "train loss:0.008497998722169052\n",
      "train loss:0.016703251025676075\n",
      "train loss:0.07657506978659705\n",
      "train loss:0.024127758950194225\n",
      "train loss:0.007666576661659401\n",
      "train loss:0.0015270093619554486\n",
      "train loss:0.010322454253293662\n",
      "train loss:0.02442371458131988\n",
      "train loss:0.007378603118584646\n",
      "train loss:0.002788315960848248\n",
      "train loss:0.009990154100427518\n",
      "train loss:0.010238928598925095\n",
      "train loss:0.0059745310680708345\n",
      "train loss:0.007439049263395153\n",
      "train loss:0.007732761703453375\n",
      "train loss:0.011119752262638118\n",
      "train loss:0.02219998565930136\n",
      "train loss:0.023522022805013188\n",
      "train loss:0.008873040733526138\n",
      "train loss:0.02357998338922807\n",
      "train loss:0.00528874610594027\n",
      "train loss:0.010896824903684424\n",
      "train loss:0.015189520411182787\n",
      "train loss:0.009092930714262263\n",
      "train loss:0.011467546011810407\n",
      "train loss:0.016516321287949318\n",
      "train loss:0.007790451776077733\n",
      "train loss:0.005618549437460212\n",
      "train loss:0.009883265932599914\n",
      "train loss:0.008601019297743226\n",
      "train loss:0.005534022415489875\n",
      "train loss:0.008573736568295647\n",
      "train loss:0.005750859862990941\n",
      "train loss:0.006524208295481648\n",
      "train loss:0.004496624906757448\n",
      "train loss:0.0013668161128730038\n",
      "train loss:0.0011180236555008312\n",
      "train loss:0.0009318081212531635\n",
      "train loss:0.011070852526015062\n",
      "train loss:0.006731250626467514\n",
      "train loss:0.01081904422372141\n",
      "train loss:0.0016169259127161609\n",
      "train loss:0.007910208767496629\n",
      "train loss:0.04583578255974356\n",
      "train loss:0.0015375753632430541\n",
      "train loss:0.012415092913509482\n",
      "train loss:0.0008275470288781248\n",
      "train loss:0.003748966542457765\n",
      "train loss:0.003701891570537699\n",
      "train loss:0.007384215303687657\n",
      "train loss:0.0043287254718210365\n",
      "train loss:0.004960890328384962\n",
      "train loss:0.0031997577242374887\n",
      "train loss:0.003033277488454819\n",
      "train loss:0.009754000390033952\n",
      "train loss:0.000582892823438998\n",
      "train loss:0.013060441548494702\n",
      "train loss:0.019185976970992634\n",
      "train loss:0.006279891343803095\n",
      "train loss:0.0037981876377870868\n",
      "train loss:0.0008022107234926655\n",
      "train loss:0.004602359834180257\n",
      "train loss:0.0016366071287633385\n",
      "train loss:0.007993882745873364\n",
      "train loss:0.011177677726190131\n",
      "train loss:0.0029562907127527118\n",
      "train loss:0.00397002837177857\n",
      "train loss:0.009897489850483904\n",
      "train loss:0.013775453771092\n",
      "train loss:0.015007293983714387\n",
      "train loss:0.010483059078291916\n",
      "train loss:0.005800547570866755\n",
      "train loss:0.005437053498907511\n",
      "train loss:0.006462688455046089\n",
      "train loss:0.0077684284711887755\n",
      "train loss:0.0004158684527755296\n",
      "train loss:0.003324827885353954\n",
      "train loss:0.003205295760373607\n",
      "train loss:0.0095434172347415\n",
      "train loss:0.010315696584694476\n",
      "train loss:0.0015556208622729657\n",
      "train loss:0.004624785776011466\n",
      "train loss:0.000669399157506147\n",
      "train loss:0.015556447645037648\n",
      "train loss:0.030612659213129084\n",
      "train loss:0.004401487218757484\n",
      "train loss:0.005038990504324752\n",
      "train loss:0.0019438414421406025\n",
      "train loss:0.009769699992534176\n",
      "train loss:0.001515536841933418\n",
      "train loss:0.005177303168345808\n",
      "train loss:0.007649541928677887\n",
      "train loss:0.008440034505701258\n",
      "train loss:0.012023718994067454\n",
      "train loss:0.004643318026357252\n",
      "train loss:0.00682040799000653\n",
      "train loss:0.047843613091042875\n",
      "train loss:0.0006623192536151591\n",
      "train loss:0.00440618007882553\n",
      "train loss:0.008114668690588463\n",
      "train loss:0.0034696642598887046\n",
      "train loss:0.027495366082929542\n",
      "train loss:0.0626121682205154\n",
      "train loss:0.0020310655511952616\n",
      "train loss:0.005358019756653487\n",
      "train loss:0.007809815735589229\n",
      "train loss:0.002188053489123438\n",
      "train loss:0.00429903463772928\n",
      "train loss:0.009580057691409165\n",
      "train loss:0.0015683521474443784\n",
      "train loss:0.0011528964463488427\n",
      "train loss:0.009113718232081312\n",
      "train loss:0.010882992124198337\n",
      "train loss:0.006939974302888138\n",
      "train loss:0.004384618929356921\n",
      "train loss:0.0028495602285039047\n",
      "train loss:0.0007051241432654471\n",
      "train loss:0.022462366801472497\n",
      "train loss:0.021002696153737243\n",
      "train loss:0.0053099591544404435\n",
      "train loss:0.011957941062621514\n",
      "train loss:0.00832934728135383\n",
      "train loss:0.003341477979935626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0077956785435465345\n",
      "train loss:0.05361047595808143\n",
      "train loss:0.017785754106090713\n",
      "train loss:0.002752143062493083\n",
      "train loss:0.02977461877551652\n",
      "train loss:0.002282376499985917\n",
      "train loss:0.014845947966809998\n",
      "train loss:0.0016612842875990534\n",
      "train loss:0.017931192258573293\n",
      "train loss:0.0037317639464278813\n",
      "train loss:0.004259667854881459\n",
      "train loss:0.004401406808151716\n",
      "train loss:0.007314208967662142\n",
      "train loss:0.006664596811213571\n",
      "train loss:0.014738722729252108\n",
      "train loss:0.008147845270810278\n",
      "train loss:0.0015484777825240268\n",
      "train loss:0.0054372132260913884\n",
      "train loss:0.0010620644477127162\n",
      "train loss:0.0062041459683895624\n",
      "train loss:0.0014110673912923932\n",
      "train loss:0.0030044407659262284\n",
      "train loss:0.00498783195146248\n",
      "train loss:0.009265486784015781\n",
      "train loss:0.011046908733186636\n",
      "train loss:0.008030604173936227\n",
      "train loss:0.002361653253124873\n",
      "train loss:0.00729493150851794\n",
      "train loss:0.006710333556880701\n",
      "train loss:0.004537717707941949\n",
      "train loss:0.006763519843272158\n",
      "train loss:0.01374226034364365\n",
      "train loss:0.0019132094617053989\n",
      "train loss:0.001778440710938111\n",
      "train loss:0.0034563667707711103\n",
      "train loss:0.015250010849675462\n",
      "train loss:0.009798538622463162\n",
      "train loss:0.0012378041774805176\n",
      "train loss:0.002175926593163959\n",
      "train loss:0.01829589848233481\n",
      "train loss:0.011155014529882323\n",
      "train loss:0.0036066845116279034\n",
      "train loss:0.0029435496619712354\n",
      "train loss:0.02819479301467747\n",
      "train loss:0.0078052653201436065\n",
      "train loss:0.0065499515275999586\n",
      "train loss:0.0014400705554211083\n",
      "train loss:0.0030352244992464346\n",
      "train loss:0.0019846916368319247\n",
      "train loss:0.0014712513656320952\n",
      "train loss:0.004946870915928093\n",
      "train loss:0.00787317925503972\n",
      "train loss:0.006779667768007899\n",
      "train loss:0.003598949214069816\n",
      "train loss:0.0020932622534483897\n",
      "train loss:0.0020035239817701566\n",
      "train loss:0.001244027776725084\n",
      "train loss:0.026135398331368423\n",
      "train loss:0.03303993212440302\n",
      "train loss:0.014976376132118621\n",
      "train loss:0.007171684858041464\n",
      "train loss:0.0002923598070300341\n",
      "train loss:0.005640892551915692\n",
      "train loss:0.008995276480074496\n",
      "train loss:0.0006857121315112772\n",
      "train loss:0.0019916978041909835\n",
      "train loss:0.007284234244160332\n",
      "train loss:0.0007219646540266855\n",
      "train loss:0.01269207084304576\n",
      "train loss:0.005175113277198899\n",
      "train loss:0.00771397844696157\n",
      "train loss:0.006395840083553694\n",
      "train loss:0.003410765685873019\n",
      "train loss:0.0046860099117165144\n",
      "train loss:0.004234872863817297\n",
      "train loss:0.028271098852502532\n",
      "train loss:0.0008490258142228067\n",
      "train loss:0.005231824704872062\n",
      "train loss:0.014594096040686516\n",
      "train loss:0.017700114913242655\n",
      "train loss:0.02669284229646245\n",
      "train loss:0.023811065621968167\n",
      "train loss:0.004127910957061487\n",
      "train loss:0.009310850366200501\n",
      "train loss:0.004731464293509415\n",
      "train loss:0.002513815352999495\n",
      "train loss:0.007850435180470622\n",
      "train loss:0.0009538809319963735\n",
      "train loss:0.0032155912471572554\n",
      "train loss:0.0031025953081430546\n",
      "train loss:0.006694467128987156\n",
      "train loss:0.003998199541394571\n",
      "train loss:0.002211064850491259\n",
      "train loss:0.018057896543984323\n",
      "train loss:0.0033248538634259557\n",
      "train loss:0.007172284825323898\n",
      "train loss:0.006358944106999942\n",
      "train loss:0.009743138098598392\n",
      "train loss:0.0009570565852903954\n",
      "train loss:0.007946099715553214\n",
      "train loss:0.00929798929798748\n",
      "train loss:0.004068895876605216\n",
      "train loss:0.005287238184297115\n",
      "train loss:0.006448708414235277\n",
      "train loss:0.002963285502293752\n",
      "train loss:0.004185379961089563\n",
      "train loss:0.0034655909721731304\n",
      "train loss:0.0012471504044812667\n",
      "train loss:0.003213879078885369\n",
      "train loss:0.003344292768432089\n",
      "train loss:0.0027404717027492056\n",
      "train loss:0.009153843547685964\n",
      "train loss:0.006856486406110663\n",
      "train loss:0.007197777854233221\n",
      "train loss:0.0024155832787123655\n",
      "train loss:0.023512522424425954\n",
      "train loss:0.0041439570427229625\n",
      "train loss:0.001994511431626476\n",
      "train loss:0.0032311057492971705\n",
      "train loss:0.016026747957158412\n",
      "train loss:0.014758296796701964\n",
      "train loss:0.0017267349938291424\n",
      "train loss:0.005926723699056097\n",
      "train loss:0.03282467339219743\n",
      "train loss:0.0032188172357005868\n",
      "train loss:0.0038440554593467675\n",
      "train loss:0.0011970847305573069\n",
      "train loss:0.002207978427111198\n",
      "train loss:0.0025419335369067705\n",
      "train loss:0.021714755461751833\n",
      "train loss:0.0042974207189595956\n",
      "train loss:0.00911508616393551\n",
      "train loss:0.012576634327661143\n",
      "train loss:0.0013888591599481108\n",
      "train loss:0.007160867133718584\n",
      "train loss:0.004606259254037695\n",
      "train loss:0.011156339285066324\n",
      "train loss:0.005837010422922617\n",
      "train loss:0.0031686863085516174\n",
      "train loss:0.009792868868143489\n",
      "train loss:0.003333624919182914\n",
      "train loss:0.000789670057282144\n",
      "train loss:0.013443612266985941\n",
      "train loss:0.00953218464580536\n",
      "train loss:0.015661079965252376\n",
      "train loss:0.0009539202293802555\n",
      "train loss:0.0033371951093173124\n",
      "train loss:0.0037189315699317697\n",
      "train loss:0.007918977448432573\n",
      "train loss:0.005897201628028591\n",
      "train loss:0.0010968813836940365\n",
      "train loss:0.007361118059996642\n",
      "train loss:0.003941495187249582\n",
      "train loss:0.0008475240589589647\n",
      "train loss:0.007160708623601281\n",
      "train loss:0.015242250981747833\n",
      "train loss:0.0009326024464633025\n",
      "train loss:0.0033281315025147583\n",
      "train loss:0.014953663558786317\n",
      "train loss:0.002731172012521573\n",
      "train loss:0.019136250298938787\n",
      "train loss:0.0119024823161503\n",
      "train loss:0.003223248749202845\n",
      "train loss:0.0025150114551525256\n",
      "train loss:0.0002669462343544476\n",
      "train loss:0.0013534250658248479\n",
      "train loss:0.002970399155088044\n",
      "train loss:0.0034666144498443564\n",
      "train loss:0.007498055572861844\n",
      "train loss:0.014235244403094413\n",
      "train loss:0.0017702198895778237\n",
      "train loss:0.016162328700266154\n",
      "train loss:0.0032635827966805515\n",
      "train loss:0.0008622489945585346\n",
      "train loss:0.008026649104959762\n",
      "train loss:0.01060538703861471\n",
      "train loss:0.0009831847721069105\n",
      "train loss:0.004575049277685592\n",
      "train loss:0.0018189076362140073\n",
      "train loss:0.001032366889639122\n",
      "train loss:0.0003075705760954524\n",
      "train loss:0.016053168528730177\n",
      "train loss:0.004323992717890229\n",
      "train loss:0.002720903526664673\n",
      "train loss:0.0003147301831046435\n",
      "train loss:0.001979208486846146\n",
      "train loss:0.0011006198815932987\n",
      "train loss:0.015449838212772883\n",
      "train loss:0.008022442920929579\n",
      "train loss:0.0006460651892294826\n",
      "train loss:0.015551785481889617\n",
      "train loss:0.009918624786046179\n",
      "train loss:0.04093648563700933\n",
      "train loss:0.0033758111990625805\n",
      "train loss:0.042751623194912935\n",
      "train loss:0.0037270592862494885\n",
      "train loss:0.001797052120142649\n",
      "train loss:0.005856513378679861\n",
      "train loss:0.0037327241404060897\n",
      "train loss:0.028972177012383162\n",
      "train loss:0.0272141289709817\n",
      "train loss:0.0017872957952593848\n",
      "train loss:0.018177086233937274\n",
      "train loss:0.005207600117909168\n",
      "train loss:0.002633840737153715\n",
      "train loss:0.0028246517029438083\n",
      "train loss:0.0009575552637354067\n",
      "train loss:0.006677656592358909\n",
      "train loss:0.0027262029661687852\n",
      "train loss:0.00807462347220562\n",
      "train loss:0.005007854134801402\n",
      "train loss:0.0036266648237062615\n",
      "train loss:0.00200956145528869\n",
      "train loss:0.0045474574503375905\n",
      "train loss:0.009549228274057254\n",
      "train loss:0.016447570069157244\n",
      "train loss:0.007939469882582711\n",
      "train loss:0.001306006984790866\n",
      "train loss:0.017460653362001925\n",
      "train loss:0.003852454995471282\n",
      "train loss:0.006569525910719033\n",
      "train loss:0.009341332304961134\n",
      "train loss:0.0064740116940611514\n",
      "train loss:0.018657808117036295\n",
      "train loss:0.01856902738398427\n",
      "train loss:0.007138779573806491\n",
      "train loss:0.003844153318575269\n",
      "train loss:0.00586763781754226\n",
      "train loss:0.004053701137045058\n",
      "train loss:0.004819780824216649\n",
      "train loss:0.005869136297125433\n",
      "train loss:0.005246434227057291\n",
      "train loss:0.02899771561275899\n",
      "train loss:0.004359728473775735\n",
      "train loss:0.008159262272642217\n",
      "train loss:0.007081713808357445\n",
      "train loss:0.02790800667761568\n",
      "train loss:0.00357258954176086\n",
      "train loss:0.00697688551960711\n",
      "train loss:0.008973542499935573\n",
      "train loss:0.01005959905877438\n",
      "train loss:0.0013793937566524835\n",
      "train loss:0.0072357521427506896\n",
      "train loss:0.0050084331507318355\n",
      "train loss:0.07072797327378462\n",
      "train loss:0.003989003898480658\n",
      "train loss:0.003497092788508601\n",
      "train loss:0.0006173682356418139\n",
      "train loss:0.01747040501360818\n",
      "train loss:0.015890142077273416\n",
      "train loss:0.005432257264786077\n",
      "train loss:0.0003709251259139687\n",
      "train loss:0.03778567919440962\n",
      "train loss:0.021135354570033127\n",
      "train loss:0.0034357871085153586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0031510886817218086\n",
      "train loss:0.018511958607951132\n",
      "train loss:0.007992526377340346\n",
      "train loss:0.0008431303875061698\n",
      "train loss:0.008691522084635288\n",
      "train loss:0.011987069640221438\n",
      "train loss:0.0071412259677933665\n",
      "train loss:0.004678060956319558\n",
      "train loss:0.006843038338716292\n",
      "train loss:0.005145434896120855\n",
      "train loss:0.005673359880478298\n",
      "train loss:0.00691141339893878\n",
      "train loss:0.008458739245261077\n",
      "train loss:0.02394884166872211\n",
      "train loss:0.013981282705339389\n",
      "train loss:0.007194975873882982\n",
      "train loss:0.005158732860734617\n",
      "train loss:0.0028579697181409175\n",
      "train loss:0.010678569398198095\n",
      "train loss:0.001668210616165118\n",
      "train loss:0.012154314214826253\n",
      "train loss:0.010675520026912005\n",
      "train loss:0.014873978239062889\n",
      "train loss:0.0035979799353452902\n",
      "train loss:0.014326421334550012\n",
      "train loss:0.013444768319443703\n",
      "train loss:0.011012472444175494\n",
      "train loss:0.0023056745869072613\n",
      "train loss:0.001722517016241337\n",
      "train loss:0.0020696682267299887\n",
      "train loss:0.0058675306443630925\n",
      "train loss:0.004200645683600283\n",
      "train loss:0.013252384595400594\n",
      "train loss:0.0193284919263901\n",
      "train loss:0.007101961956628536\n",
      "train loss:0.001216221041421419\n",
      "train loss:0.0027466943811807615\n",
      "train loss:0.001927200215188109\n",
      "train loss:0.0014032035574934063\n",
      "train loss:0.03308048122528505\n",
      "train loss:0.001997357564337254\n",
      "train loss:0.0007481141835560508\n",
      "train loss:0.02807044181777084\n",
      "train loss:0.005357602307521061\n",
      "train loss:0.004816113067097024\n",
      "train loss:0.003380204282318427\n",
      "train loss:0.00039060643901678044\n",
      "train loss:0.005450640417361094\n",
      "train loss:0.01636824483417585\n",
      "train loss:0.006039722257382679\n",
      "train loss:0.003860621659391526\n",
      "train loss:0.0074116205096133704\n",
      "train loss:0.00038341662155923456\n",
      "train loss:0.00032278118297606666\n",
      "train loss:0.005284589134068726\n",
      "train loss:0.0195350284167679\n",
      "train loss:0.0012773336380506118\n",
      "train loss:0.013508248552699482\n",
      "train loss:0.005222826795153707\n",
      "train loss:0.00022808263621371884\n",
      "train loss:0.0027474049164604502\n",
      "train loss:0.01194442334594362\n",
      "train loss:0.003224911126642073\n",
      "train loss:0.01312595921273461\n",
      "train loss:0.008932442237483375\n",
      "train loss:0.003997996033047654\n",
      "train loss:0.0039642877321454184\n",
      "train loss:0.008422405438928835\n",
      "train loss:0.006411445568979539\n",
      "train loss:0.008790687116999372\n",
      "train loss:0.0010804561350430425\n",
      "train loss:0.0023247513278030567\n",
      "train loss:0.0016383937207086233\n",
      "train loss:0.017231608463811342\n",
      "train loss:0.017872764708463783\n",
      "train loss:0.0015259985483462323\n",
      "train loss:0.03291590392336337\n",
      "train loss:0.0027777659960817225\n",
      "train loss:0.0006965758460388085\n",
      "train loss:0.00869977504737735\n",
      "train loss:0.0021077578678603127\n",
      "train loss:0.001954320922761145\n",
      "train loss:0.007382429450383771\n",
      "train loss:0.0014028408972617376\n",
      "train loss:0.002766529144809798\n",
      "train loss:0.0036985216231495933\n",
      "train loss:0.007886923330161494\n",
      "train loss:0.0063775866967919585\n",
      "train loss:0.0006317289985767066\n",
      "train loss:0.01109828645427926\n",
      "train loss:0.0018506223363018712\n",
      "train loss:0.004514350578110835\n",
      "train loss:0.023115184889084362\n",
      "train loss:0.01497622850875475\n",
      "train loss:0.0035900941316443003\n",
      "train loss:0.020962250539476788\n",
      "train loss:0.001519823336189298\n",
      "train loss:0.005183555443552471\n",
      "train loss:0.01905947264938388\n",
      "train loss:0.0006161836385710266\n",
      "=== epoch:12, train acc:0.994, test acc:0.988 ===\n",
      "train loss:0.0014481410829027157\n",
      "train loss:0.004854444942028249\n",
      "train loss:0.0025533120107111306\n",
      "train loss:0.0015421017800073336\n",
      "train loss:0.006625654894595989\n",
      "train loss:0.0029756716828992498\n",
      "train loss:0.006032875423075857\n",
      "train loss:0.006658980526545937\n",
      "train loss:0.002341041445729315\n",
      "train loss:0.06388024445166715\n",
      "train loss:0.0049565150512416315\n",
      "train loss:0.006623229919279831\n",
      "train loss:0.0007221676258135512\n",
      "train loss:0.011599037026766875\n",
      "train loss:0.005716942310565279\n",
      "train loss:0.007986102636596971\n",
      "train loss:0.0014883280295053822\n",
      "train loss:0.035200357578953984\n",
      "train loss:0.013210621008734671\n",
      "train loss:0.02252042499370371\n",
      "train loss:0.0008793788641774222\n",
      "train loss:0.004909579503452443\n",
      "train loss:0.003554926448089298\n",
      "train loss:0.00331059671282918\n",
      "train loss:0.0005514009760445214\n",
      "train loss:0.007879656256746987\n",
      "train loss:0.005343218408739657\n",
      "train loss:0.0075529444843110615\n",
      "train loss:0.005904389467575659\n",
      "train loss:0.00043130920926271035\n",
      "train loss:0.0014292895892842603\n",
      "train loss:0.0012740750868692858\n",
      "train loss:0.0021927882458097404\n",
      "train loss:0.010490217962008292\n",
      "train loss:0.0027689076275076575\n",
      "train loss:0.02515362276671177\n",
      "train loss:0.0396022472780737\n",
      "train loss:0.01941633356805704\n",
      "train loss:0.000796464974652522\n",
      "train loss:0.016073903218189585\n",
      "train loss:0.0030852545629807804\n",
      "train loss:0.004772508978648779\n",
      "train loss:0.008191494948533244\n",
      "train loss:0.0008966704758307079\n",
      "train loss:0.009148589955902916\n",
      "train loss:0.009522352537749454\n",
      "train loss:0.002712515139313776\n",
      "train loss:0.004893884877139296\n",
      "train loss:0.014719808222778843\n",
      "train loss:0.00042685250340068515\n",
      "train loss:0.0046060573870927045\n",
      "train loss:0.004757996942530525\n",
      "train loss:0.0005496398172631314\n",
      "train loss:0.015879461105590405\n",
      "train loss:0.003485775630023607\n",
      "train loss:0.004888579998543132\n",
      "train loss:0.032136836029159246\n",
      "train loss:0.0016225027839114417\n",
      "train loss:0.008937473244742557\n",
      "train loss:0.0030914577134102945\n",
      "train loss:0.004332285758843239\n",
      "train loss:0.0018166890603738752\n",
      "train loss:0.006402327367403209\n",
      "train loss:0.002106388292170389\n",
      "train loss:0.006315047149843053\n",
      "train loss:0.004569001385321908\n",
      "train loss:0.003776319334081438\n",
      "train loss:0.007153181790091042\n",
      "train loss:0.007015554842133522\n",
      "train loss:0.0023972703252833545\n",
      "train loss:0.003634941285362356\n",
      "train loss:0.00132175694496291\n",
      "train loss:0.0036891155408071475\n",
      "train loss:0.008454350015746738\n",
      "train loss:0.0002818638732593421\n",
      "train loss:0.005852155885681945\n",
      "train loss:0.014123114319791774\n",
      "train loss:0.0023689383442447327\n",
      "train loss:0.00718870899687285\n",
      "train loss:0.002722731499587361\n",
      "train loss:0.0019001911994339054\n",
      "train loss:0.0006848669424446168\n",
      "train loss:0.004891664829288977\n",
      "train loss:0.022006420058852578\n",
      "train loss:0.018247255921234475\n",
      "train loss:0.004490966472969822\n",
      "train loss:0.0052719786922401455\n",
      "train loss:0.004002223308681576\n",
      "train loss:0.01705587575478225\n",
      "train loss:0.0020799051181569885\n",
      "train loss:0.0021786845386052023\n",
      "train loss:0.000704961999572028\n",
      "train loss:0.0019558260181886215\n",
      "train loss:0.001500874931357965\n",
      "train loss:0.005271903431388034\n",
      "train loss:0.003135157397880983\n",
      "train loss:0.003451414901386313\n",
      "train loss:0.0008736061728894397\n",
      "train loss:0.001576248993043331\n",
      "train loss:0.0018918467219602292\n",
      "train loss:0.009060218358678672\n",
      "train loss:0.009677744706509788\n",
      "train loss:0.0030485890697327343\n",
      "train loss:0.003508518419443114\n",
      "train loss:0.0011529972057348786\n",
      "train loss:0.003154406314826412\n",
      "train loss:0.004117193857291539\n",
      "train loss:0.0009621173502817934\n",
      "train loss:0.0016250518338525657\n",
      "train loss:0.0019149775351124682\n",
      "train loss:0.009385641753071024\n",
      "train loss:0.0008765686665672379\n",
      "train loss:0.0007563083610377134\n",
      "train loss:0.0015999531135618562\n",
      "train loss:0.022596891650842797\n",
      "train loss:0.002653942658163663\n",
      "train loss:0.0017014642090472905\n",
      "train loss:0.01546959157023774\n",
      "train loss:0.00600490071965988\n",
      "train loss:0.006559683254351326\n",
      "train loss:0.00030940315397347284\n",
      "train loss:0.0036904689286391943\n",
      "train loss:0.00465098941769496\n",
      "train loss:0.003036973414972892\n",
      "train loss:0.003927993813716106\n",
      "train loss:0.025799083073442763\n",
      "train loss:0.0019786555937666515\n",
      "train loss:0.011935393177045943\n",
      "train loss:0.01721611028721497\n",
      "train loss:0.0037915956709905435\n",
      "train loss:0.00497134424365147\n",
      "train loss:0.002685518990241064\n",
      "train loss:0.006634236293760461\n",
      "train loss:0.009722742680656869\n",
      "train loss:0.004832678406313944\n",
      "train loss:0.004939812317486798\n",
      "train loss:0.015920872485629192\n",
      "train loss:0.004371130442927938\n",
      "train loss:0.00615193924340619\n",
      "train loss:0.0168538466101838\n",
      "train loss:0.010207708349618485\n",
      "train loss:0.013159868115306773\n",
      "train loss:0.002054297996613561\n",
      "train loss:0.004475767658159029\n",
      "train loss:0.03801553583001061\n",
      "train loss:0.01741323087402994\n",
      "train loss:0.0022719295349890715\n",
      "train loss:0.0027665735440790696\n",
      "train loss:0.005597773337239151\n",
      "train loss:0.0031421758396563836\n",
      "train loss:0.004414727789724107\n",
      "train loss:0.011327701182251383\n",
      "train loss:0.002543118072067388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0070170637605683015\n",
      "train loss:0.009275570925268161\n",
      "train loss:0.00391972252774611\n",
      "train loss:0.025573942755568856\n",
      "train loss:0.0024742493596449345\n",
      "train loss:0.0018711724535456897\n",
      "train loss:0.0021110321435389924\n",
      "train loss:0.00044184024802352987\n",
      "train loss:0.01648566197656662\n",
      "train loss:0.0017925758207064026\n",
      "train loss:0.003331463370526906\n",
      "train loss:0.008957458659546782\n",
      "train loss:0.004477895208366137\n",
      "train loss:0.001865522404757954\n",
      "train loss:0.001187195280229997\n",
      "train loss:0.006113957908256144\n",
      "train loss:0.01197346378685997\n",
      "train loss:0.0038387698186758963\n",
      "train loss:0.026812791533342418\n",
      "train loss:0.0010657053691569486\n",
      "train loss:0.006925520750244023\n",
      "train loss:0.0021716872110992894\n",
      "train loss:0.03512063718101062\n",
      "train loss:0.0005315905466477168\n",
      "train loss:0.0017159003547559204\n",
      "train loss:0.0007303135382400147\n",
      "train loss:0.006437199018265513\n",
      "train loss:0.0047553098209992374\n",
      "train loss:0.006934372801804662\n",
      "train loss:0.0023615310354092992\n",
      "train loss:0.002928386242318503\n",
      "train loss:0.0007673139343988026\n",
      "train loss:0.12393378706963626\n",
      "train loss:0.0013261057696300651\n",
      "train loss:0.0552268892798231\n",
      "train loss:0.0010906041357869349\n",
      "train loss:0.0006143958740271376\n",
      "train loss:0.009174949118577946\n",
      "train loss:0.0017988041018731173\n",
      "train loss:0.0015123295284441435\n",
      "train loss:0.002909137749841821\n",
      "train loss:0.006473950408030957\n",
      "train loss:0.05686449172651838\n",
      "train loss:0.0014076005458147692\n",
      "train loss:0.0007044908093432082\n",
      "train loss:0.00405523000498188\n",
      "train loss:0.0019270868625660303\n",
      "train loss:0.006803768279074252\n",
      "train loss:0.010488273290633083\n",
      "train loss:0.0043700941927681605\n",
      "train loss:0.0037030781231444914\n",
      "train loss:0.007617147743417061\n",
      "train loss:0.006899941991975398\n",
      "train loss:0.0017386607435662443\n",
      "train loss:0.003087916715319409\n",
      "train loss:0.008316893816335217\n",
      "train loss:0.011493561159411194\n",
      "train loss:0.001841189476694221\n",
      "train loss:0.004245605741607336\n",
      "train loss:0.0016780010932033584\n",
      "train loss:0.024901308795895364\n",
      "train loss:0.00047007442817787674\n",
      "train loss:0.0006866852219777935\n",
      "train loss:0.0016496124769158167\n",
      "train loss:0.0029566896817893114\n",
      "train loss:0.00403317324587578\n",
      "train loss:0.0005755752768308222\n",
      "train loss:0.00357378707518779\n",
      "train loss:0.013184702259950382\n",
      "train loss:0.003029688551545453\n",
      "train loss:0.002341234680958536\n",
      "train loss:0.0009998067672421593\n",
      "train loss:0.0020628400950486463\n",
      "train loss:0.003082621732808458\n",
      "train loss:0.004749514246625872\n",
      "train loss:0.005911222748311169\n",
      "train loss:0.0015461199215511384\n",
      "train loss:0.014387020795028625\n",
      "train loss:0.00219231079511661\n",
      "train loss:0.0034511032730653595\n",
      "train loss:0.0022232241813071436\n",
      "train loss:0.004338418115185277\n",
      "train loss:0.0015478196982432694\n",
      "train loss:0.021438147187133258\n",
      "train loss:0.004569707203415484\n",
      "train loss:0.002825025886955024\n",
      "train loss:0.0027824921799099018\n",
      "train loss:0.00212753372294786\n",
      "train loss:0.001766514449086406\n",
      "train loss:0.0060985272134979306\n",
      "train loss:0.0010267213198522707\n",
      "train loss:0.002073095191204281\n",
      "train loss:0.013794607600404706\n",
      "train loss:0.003922446170458461\n",
      "train loss:0.012665984691043585\n",
      "train loss:0.0011075520660708488\n",
      "train loss:0.0007861994260511197\n",
      "train loss:0.003190838316178054\n",
      "train loss:0.00026529943411862195\n",
      "train loss:0.014236316200381863\n",
      "train loss:0.011282541283552001\n",
      "train loss:0.0018965081984857273\n",
      "train loss:0.001278058614409715\n",
      "train loss:0.005045210172624525\n",
      "train loss:0.004127962767707402\n",
      "train loss:0.047492244627253974\n",
      "train loss:0.0033402840448002276\n",
      "train loss:0.0015605830508970187\n",
      "train loss:0.006426849976328177\n",
      "train loss:0.015630428709984608\n",
      "train loss:0.0008024588383034798\n",
      "train loss:0.017854285503738063\n",
      "train loss:0.011836654567453381\n",
      "train loss:0.004158561572592859\n",
      "train loss:0.0055379279671087436\n",
      "train loss:0.006460302847205176\n",
      "train loss:0.001788074594810864\n",
      "train loss:0.003167921997835072\n",
      "train loss:0.006585569031505955\n",
      "train loss:0.001531205149021351\n",
      "train loss:0.0025376560370225496\n",
      "train loss:0.011340327159923723\n",
      "train loss:0.0053031974201053975\n",
      "train loss:0.003875519751826642\n",
      "train loss:0.0015291610007898068\n",
      "train loss:0.01021440502067182\n",
      "train loss:0.0034650915995098125\n",
      "train loss:0.0010559509235622488\n",
      "train loss:0.013710297604175468\n",
      "train loss:0.0023672084329891536\n",
      "train loss:0.007322875114045788\n",
      "train loss:0.0009356389328036785\n",
      "train loss:0.007832476289716523\n",
      "train loss:0.00371656015655899\n",
      "train loss:0.010955533865585659\n",
      "train loss:0.0037449822008249287\n",
      "train loss:0.009604730631196896\n",
      "train loss:0.002543681365997845\n",
      "train loss:0.003991301780446541\n",
      "train loss:0.003621006301266012\n",
      "train loss:0.0022214622987634597\n",
      "train loss:0.00853395765084014\n",
      "train loss:0.0005670447879424209\n",
      "train loss:0.003921157045401763\n",
      "train loss:0.0008776078639006186\n",
      "train loss:0.003439905329391789\n",
      "train loss:0.0022595092925835883\n",
      "train loss:0.009199702657124364\n",
      "train loss:0.02159177969062052\n",
      "train loss:0.004337283555093619\n",
      "train loss:0.0022390301461562316\n",
      "train loss:0.0014563669344911758\n",
      "train loss:0.006634883621778498\n",
      "train loss:0.011491315114539387\n",
      "train loss:0.008427973085258453\n",
      "train loss:0.0011369919299156971\n",
      "train loss:0.0020426828016806603\n",
      "train loss:0.00980668045981887\n",
      "train loss:0.0007699358215089276\n",
      "train loss:0.012909048968215318\n",
      "train loss:0.005523181139591227\n",
      "train loss:0.0029128025335813114\n",
      "train loss:0.0022649314585277314\n",
      "train loss:0.0005321999331126167\n",
      "train loss:0.009756328671368194\n",
      "train loss:0.007450903247593519\n",
      "train loss:0.0068820553417412765\n",
      "train loss:0.0012571344847023865\n",
      "train loss:0.02110757679027262\n",
      "train loss:0.0068992390678225615\n",
      "train loss:0.0006137924040868277\n",
      "train loss:0.007106641465817225\n",
      "train loss:0.0021278083278327563\n",
      "train loss:0.005019704439114111\n",
      "train loss:0.0048838556993473095\n",
      "train loss:0.0036919968339352775\n",
      "train loss:0.00830005365804647\n",
      "train loss:0.0023979286246217165\n",
      "train loss:0.011832737090627137\n",
      "train loss:0.001188405412431494\n",
      "train loss:0.02168083376865386\n",
      "train loss:0.010307589561107338\n",
      "train loss:0.001992151000428977\n",
      "train loss:0.006264917480716841\n",
      "train loss:0.0021071283706895665\n",
      "train loss:0.0010876177499048604\n",
      "train loss:0.00020173713806238936\n",
      "train loss:0.005437630535538431\n",
      "train loss:0.0011367974028923247\n",
      "train loss:0.029499062342957495\n",
      "train loss:0.013011670335975566\n",
      "train loss:0.0030971088449933764\n",
      "train loss:0.002364166666327197\n",
      "train loss:0.0021258409970465043\n",
      "train loss:0.008366844520330775\n",
      "train loss:0.010702793904004373\n",
      "train loss:0.006366256394661355\n",
      "train loss:0.001450002189424146\n",
      "train loss:0.012438270381667704\n",
      "train loss:0.06668847661478018\n",
      "train loss:0.011216545165021734\n",
      "train loss:0.006747883916841784\n",
      "train loss:0.00018086595477950586\n",
      "train loss:0.0059879018367059115\n",
      "train loss:0.007715550695188989\n",
      "train loss:0.015394677015494304\n",
      "train loss:0.00023318836887621392\n",
      "train loss:0.0005193427500822597\n",
      "train loss:0.031287378313902305\n",
      "train loss:0.00559299354974193\n",
      "train loss:0.005363132058158257\n",
      "train loss:0.0033772357290569803\n",
      "train loss:0.03933173245255894\n",
      "train loss:0.004385976473455974\n",
      "train loss:0.00302766699517162\n",
      "train loss:0.0025219680565530074\n",
      "train loss:0.015056518531234962\n",
      "train loss:0.003158242926717455\n",
      "train loss:0.030866784546680313\n",
      "train loss:0.005253269454436912\n",
      "train loss:0.001254762247487985\n",
      "train loss:0.013029091868483502\n",
      "train loss:0.0006720620034647204\n",
      "train loss:0.005848771047752466\n",
      "train loss:0.000524440567940023\n",
      "train loss:0.029368407240264013\n",
      "train loss:0.012676272567520724\n",
      "train loss:0.0046955519839348495\n",
      "train loss:0.012164055801823052\n",
      "train loss:0.014027352206656508\n",
      "train loss:0.0037603450269298967\n",
      "train loss:0.0028653426803827357\n",
      "train loss:0.008692049994447637\n",
      "train loss:0.00973573049029638\n",
      "train loss:0.008542444434849073\n",
      "train loss:0.004047143289757012\n",
      "train loss:0.0013569013261508856\n",
      "train loss:0.0016159346014009213\n",
      "train loss:0.00858865899804345\n",
      "train loss:0.050663541083011875\n",
      "train loss:0.013321087393793594\n",
      "train loss:0.005937205437849493\n",
      "train loss:0.0002456480805600816\n",
      "train loss:0.0014566620158317915\n",
      "train loss:0.0030106708745225607\n",
      "train loss:0.0035013573378003832\n",
      "train loss:0.004701725033296811\n",
      "train loss:0.008017820561533528\n",
      "train loss:0.002662357064675144\n",
      "train loss:0.0010296289215471792\n",
      "train loss:0.0012039768645033648\n",
      "train loss:0.006752265143346664\n",
      "train loss:0.00010309785750808504\n",
      "train loss:0.0013155091571958142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0026420453812329293\n",
      "train loss:0.00219644659137918\n",
      "train loss:0.005948840362192976\n",
      "train loss:0.0003207472063971762\n",
      "train loss:0.002377101261951686\n",
      "train loss:0.003112482774405559\n",
      "train loss:0.0159783611006588\n",
      "train loss:0.00855565385480383\n",
      "train loss:0.006443674233481616\n",
      "train loss:0.0023148598457706647\n",
      "train loss:0.011776389041176743\n",
      "train loss:0.00695024374562357\n",
      "train loss:0.005206279535852224\n",
      "train loss:0.0019094775536150574\n",
      "train loss:0.0015859927463321801\n",
      "train loss:0.004873831720878561\n",
      "train loss:0.001997785808978376\n",
      "train loss:0.002922241100104702\n",
      "train loss:0.0016259302628299568\n",
      "train loss:0.0006935323825236096\n",
      "train loss:0.002783449286430879\n",
      "train loss:0.011060055044916197\n",
      "train loss:0.001708556536489827\n",
      "train loss:0.005816844671587464\n",
      "train loss:0.020595270327253123\n",
      "train loss:0.004217551707578062\n",
      "train loss:0.009379596395058067\n",
      "train loss:0.009673606432558327\n",
      "train loss:0.06964993119749151\n",
      "train loss:0.0023970249583925235\n",
      "train loss:0.007524380595179269\n",
      "train loss:0.007463182211235757\n",
      "train loss:0.006933126617921543\n",
      "train loss:0.006471903431169248\n",
      "train loss:0.007312448355966503\n",
      "train loss:0.00535333643694132\n",
      "train loss:0.013203843489722507\n",
      "train loss:0.0006689793535897441\n",
      "train loss:0.002287802980665572\n",
      "train loss:0.05280264333377629\n",
      "train loss:0.009431994518890452\n",
      "train loss:0.005217095868723197\n",
      "train loss:0.003189825158607158\n",
      "train loss:0.0037769492003073436\n",
      "train loss:0.015925901042099466\n",
      "train loss:0.0006694768363359884\n",
      "train loss:0.0019947783702587846\n",
      "train loss:0.002287192519284273\n",
      "train loss:0.00035023081124439874\n",
      "train loss:0.0295489699613364\n",
      "train loss:0.0016633182668565388\n",
      "train loss:0.00548737365395998\n",
      "train loss:0.00396016065162054\n",
      "train loss:0.0049462993175713385\n",
      "train loss:0.004569645025891713\n",
      "train loss:0.012762223756858038\n",
      "train loss:0.011812156581877276\n",
      "train loss:0.004590160482290418\n",
      "train loss:0.0018231223617575774\n",
      "train loss:0.0032796864774002525\n",
      "train loss:0.004022847856967603\n",
      "train loss:0.0011729143442975928\n",
      "train loss:0.0025105993220687494\n",
      "train loss:0.0021781931394251877\n",
      "train loss:0.0029102105766240865\n",
      "train loss:0.009686406176879448\n",
      "train loss:0.0019932799250466223\n",
      "train loss:0.0007426684283453913\n",
      "train loss:0.03047716461567662\n",
      "train loss:0.00849850498701057\n",
      "train loss:0.006566363576108857\n",
      "train loss:0.0019368545195762945\n",
      "train loss:0.00043645140129522456\n",
      "train loss:0.01702777744520743\n",
      "train loss:0.0060295786545296074\n",
      "train loss:0.0016461391348138524\n",
      "train loss:0.0008918506501930486\n",
      "train loss:0.005833690414132485\n",
      "train loss:0.01127424407206749\n",
      "train loss:0.051327691826073\n",
      "train loss:0.009760987610903306\n",
      "train loss:0.021766725418238576\n",
      "train loss:0.00769409810328306\n",
      "train loss:0.004162336203058816\n",
      "train loss:0.0007896099084312174\n",
      "train loss:0.00010183282133613445\n",
      "train loss:0.0031670053622302207\n",
      "train loss:0.008429466837089613\n",
      "train loss:0.005905379946738203\n",
      "train loss:0.012622958374768156\n",
      "train loss:0.002942369460245516\n",
      "train loss:0.00743691003082267\n",
      "train loss:0.00809586761737774\n",
      "train loss:0.009567428087993326\n",
      "train loss:0.003933707259568816\n",
      "train loss:0.0007212715865707563\n",
      "train loss:0.010326697932756503\n",
      "train loss:0.0027431336521573464\n",
      "train loss:0.0026208974434140274\n",
      "train loss:0.0014295786286223236\n",
      "train loss:0.008726051646137383\n",
      "train loss:0.0023205742167594144\n",
      "train loss:0.017695324976962266\n",
      "train loss:0.012199115100914282\n",
      "train loss:0.010038160308418125\n",
      "train loss:0.00458335084143181\n",
      "train loss:0.0029852889303415005\n",
      "train loss:0.026384144558140664\n",
      "train loss:0.0014594436932050302\n",
      "train loss:0.0320422718616571\n",
      "train loss:0.000769092493591903\n",
      "train loss:0.0014363102936738165\n",
      "train loss:0.008072022010416827\n",
      "train loss:0.002627829429152388\n",
      "train loss:0.016941893814565363\n",
      "train loss:0.008172936233576478\n",
      "train loss:0.0038504983987693643\n",
      "train loss:0.02351762220224769\n",
      "train loss:0.001884234511909212\n",
      "train loss:0.011431901460404723\n",
      "train loss:0.026615875774543454\n",
      "train loss:0.004341422300034233\n",
      "train loss:0.0007726667742753275\n",
      "train loss:0.005455367209993745\n",
      "train loss:0.006959563086898962\n",
      "train loss:0.0211870619494464\n",
      "train loss:0.0055035094862642365\n",
      "train loss:0.0304674586235175\n",
      "train loss:0.024711541581237194\n",
      "train loss:0.0009643554767077045\n",
      "train loss:0.005212363873033699\n",
      "train loss:0.005670737593275458\n",
      "train loss:0.019816876167798536\n",
      "train loss:0.0037678891385568075\n",
      "train loss:0.005958539647849771\n",
      "train loss:0.0019075043078356194\n",
      "train loss:0.012798369412618436\n",
      "train loss:0.029105863616480283\n",
      "train loss:0.016498429229330022\n",
      "train loss:0.003969174818623572\n",
      "train loss:0.02122489074423424\n",
      "train loss:0.0037389413979959014\n",
      "train loss:0.003313863417805983\n",
      "train loss:0.013997600417196417\n",
      "train loss:0.0024821436690199107\n",
      "train loss:0.011313872655149082\n",
      "train loss:0.004661240760537253\n",
      "train loss:0.005078311479288422\n",
      "train loss:0.001489507443041233\n",
      "train loss:0.011171271192054513\n",
      "train loss:0.0043269164487403835\n",
      "train loss:0.0013067326283769185\n",
      "train loss:0.04555887357549456\n",
      "train loss:0.03611267189350687\n",
      "train loss:0.001205082158595192\n",
      "train loss:0.0031529222675523187\n",
      "train loss:0.0023579018844098786\n",
      "train loss:0.00681650439222588\n",
      "train loss:0.0342593692259034\n",
      "train loss:0.009715635997911466\n",
      "train loss:0.002041915006212451\n",
      "train loss:0.0023553448296133833\n",
      "train loss:0.02499033675576355\n",
      "train loss:0.004854703828822288\n",
      "train loss:0.0019291479457395424\n",
      "train loss:0.008055993227698604\n",
      "train loss:0.0014083544424735\n",
      "train loss:0.005561749932477946\n",
      "train loss:0.0033655133329384777\n",
      "train loss:0.0006288606928110675\n",
      "train loss:0.017698197621494115\n",
      "train loss:0.006532947290298773\n",
      "train loss:0.01680732477186532\n",
      "train loss:0.004604724985037068\n",
      "train loss:0.0018618141524192591\n",
      "train loss:0.004975602808754724\n",
      "train loss:0.007036291741316658\n",
      "train loss:0.010490080789067695\n",
      "train loss:0.011485059300864393\n",
      "train loss:0.0003751253399848344\n",
      "train loss:0.0016173831627490321\n",
      "train loss:0.008800142747672742\n",
      "train loss:0.004548076840632177\n",
      "train loss:0.0013527862767282758\n",
      "train loss:0.0031393149097556144\n",
      "train loss:0.0084376503336683\n",
      "train loss:0.027586768840587507\n",
      "train loss:0.007095855876476912\n",
      "train loss:0.007817924587207864\n",
      "train loss:0.001346955197291343\n",
      "train loss:0.007901724101759001\n",
      "train loss:0.0009349998825007409\n",
      "train loss:0.001184872922329231\n",
      "=== epoch:13, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.007304524709101704\n",
      "train loss:0.0004506337501535912\n",
      "train loss:0.003488687201285929\n",
      "train loss:0.0022195694190447293\n",
      "train loss:0.0014042892833786378\n",
      "train loss:0.0015332897740205629\n",
      "train loss:0.0005041177453309827\n",
      "train loss:0.002848758370866749\n",
      "train loss:0.001056503412267165\n",
      "train loss:0.005100512902387893\n",
      "train loss:0.008929755378402657\n",
      "train loss:0.005403170847905552\n",
      "train loss:0.012027240600185165\n",
      "train loss:0.004904187903368387\n",
      "train loss:0.002783590289124977\n",
      "train loss:0.003619773062453366\n",
      "train loss:0.002381955568502018\n",
      "train loss:0.009714037392944474\n",
      "train loss:0.0009304794978079371\n",
      "train loss:0.028279926654859674\n",
      "train loss:0.010816471069193827\n",
      "train loss:0.0005712418237553943\n",
      "train loss:0.006792098253951237\n",
      "train loss:0.0009850027719075305\n",
      "train loss:0.008253219669840306\n",
      "train loss:0.0016378687807516714\n",
      "train loss:0.0056368219119133445\n",
      "train loss:0.013131395342867652\n",
      "train loss:0.0013658899637883281\n",
      "train loss:0.0018237905478484084\n",
      "train loss:0.007262672744760028\n",
      "train loss:0.0013011748291510642\n",
      "train loss:0.0013904484024744263\n",
      "train loss:0.002949001035575426\n",
      "train loss:0.00041465875410153283\n",
      "train loss:0.0007437288868721266\n",
      "train loss:0.0018593269831703502\n",
      "train loss:0.0042249408697431715\n",
      "train loss:0.0056434652005691\n",
      "train loss:0.0004926059674215123\n",
      "train loss:0.017982411766046095\n",
      "train loss:0.0007276484218239936\n",
      "train loss:0.0015020931913821906\n",
      "train loss:0.008431859124456716\n",
      "train loss:0.001893490275978649\n",
      "train loss:0.001923636612263963\n",
      "train loss:0.00237342302268408\n",
      "train loss:0.0007147260032023005\n",
      "train loss:0.002018829037346041\n",
      "train loss:0.011322575005565922\n",
      "train loss:0.02921710840227728\n",
      "train loss:0.005210928115503282\n",
      "train loss:0.006203569881724203\n",
      "train loss:0.0024478699583495075\n",
      "train loss:0.0060511011590041784\n",
      "train loss:0.0010701870163668408\n",
      "train loss:0.003715739748625816\n",
      "train loss:0.005615940288233495\n",
      "train loss:0.002025375970109305\n",
      "train loss:0.0016109163958944633\n",
      "train loss:0.0090953106545822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01946934006669453\n",
      "train loss:0.0034966855253665526\n",
      "train loss:0.0009658971959358082\n",
      "train loss:0.0003796728893120829\n",
      "train loss:0.001311539675163026\n",
      "train loss:0.004863657522479849\n",
      "train loss:0.000887898592346667\n",
      "train loss:0.005809925756975158\n",
      "train loss:0.012125417124345752\n",
      "train loss:0.000629979602134714\n",
      "train loss:0.0022894276508278184\n",
      "train loss:0.0008357315574104763\n",
      "train loss:0.0012067097034330631\n",
      "train loss:0.0005753915117900326\n",
      "train loss:0.0018228265779991284\n",
      "train loss:0.007848990526392728\n",
      "train loss:0.0009093898615686797\n",
      "train loss:0.005711798848402545\n",
      "train loss:0.0025090630660504114\n",
      "train loss:0.002004256163372464\n",
      "train loss:0.0010559442634895757\n",
      "train loss:0.0003861404213998\n",
      "train loss:0.004445997298485942\n",
      "train loss:0.0009292899987463467\n",
      "train loss:0.0007595028136767503\n",
      "train loss:0.0026007117549204355\n",
      "train loss:0.0025470213046524504\n",
      "train loss:0.0021300128578355623\n",
      "train loss:0.01061966329006347\n",
      "train loss:0.0012825763020525732\n",
      "train loss:0.007804246538321483\n",
      "train loss:0.0004855236047255188\n",
      "train loss:0.013665379764267476\n",
      "train loss:0.0004947204296510451\n",
      "train loss:0.009506130281754555\n",
      "train loss:0.008860298321094461\n",
      "train loss:0.0017253929207427551\n",
      "train loss:0.0012730859687050248\n",
      "train loss:0.001996206929028705\n",
      "train loss:0.002392220335589129\n",
      "train loss:0.0027096390906383204\n",
      "train loss:0.0009733584992504626\n",
      "train loss:0.0034231816703745323\n",
      "train loss:0.0015105314584743343\n",
      "train loss:0.002138836355395396\n",
      "train loss:0.02384967975144232\n",
      "train loss:0.0017019674346369102\n",
      "train loss:0.006134039925813355\n",
      "train loss:0.006247486517875188\n",
      "train loss:0.005048546484352078\n",
      "train loss:0.0007628341111752956\n",
      "train loss:0.012869326426418247\n",
      "train loss:0.002131491724807257\n",
      "train loss:0.0022970057157446675\n",
      "train loss:0.003191848249583544\n",
      "train loss:0.012064040793726414\n",
      "train loss:0.0006099036823148008\n",
      "train loss:0.0016896434570593858\n",
      "train loss:0.008937510792227118\n",
      "train loss:0.002425566726014877\n",
      "train loss:0.002745680326570994\n",
      "train loss:0.0074212026887724\n",
      "train loss:0.00347428515361111\n",
      "train loss:0.005874089208756902\n",
      "train loss:0.005264122588712422\n",
      "train loss:0.0060013596669021485\n",
      "train loss:0.002137177982743522\n",
      "train loss:0.004024674222402963\n",
      "train loss:0.0010018120348824348\n",
      "train loss:0.004555480420043242\n",
      "train loss:0.006305271514714159\n",
      "train loss:0.006777058411574226\n",
      "train loss:0.004376169968967924\n",
      "train loss:0.0034399964760020566\n",
      "train loss:0.005009408884776847\n",
      "train loss:0.00933444875067648\n",
      "train loss:0.0016530622756542096\n",
      "train loss:0.004049787913829383\n",
      "train loss:0.00780997788108358\n",
      "train loss:0.0028275321198788423\n",
      "train loss:0.0009237955881156254\n",
      "train loss:0.002038780294209689\n",
      "train loss:0.0039031677412393077\n",
      "train loss:0.0018663434313629088\n",
      "train loss:0.0013013429858321492\n",
      "train loss:0.0006775002959787867\n",
      "train loss:0.002297271910908253\n",
      "train loss:0.00022998058377587531\n",
      "train loss:0.0034664874830176553\n",
      "train loss:0.009776706209104452\n",
      "train loss:0.0005801280358528378\n",
      "train loss:0.005721238378731275\n",
      "train loss:0.002705252222776895\n",
      "train loss:0.0013625744604628366\n",
      "train loss:0.015528448855026798\n",
      "train loss:0.0034941796623772416\n",
      "train loss:0.007761352871546165\n",
      "train loss:0.007604893458795119\n",
      "train loss:0.0018366035879315195\n",
      "train loss:0.00035442659268298084\n",
      "train loss:0.0008742332486120081\n",
      "train loss:0.0018885323431747896\n",
      "train loss:0.002329142203666695\n",
      "train loss:0.0015852230036641512\n",
      "train loss:0.0038116689349877763\n",
      "train loss:0.0015480169095911684\n",
      "train loss:0.0016411582408200334\n",
      "train loss:0.0012414401709560634\n",
      "train loss:0.0036603718978601364\n",
      "train loss:0.00018006600929308274\n",
      "train loss:0.0006426605140270515\n",
      "train loss:0.005636369611355512\n",
      "train loss:0.007065554955507921\n",
      "train loss:0.0013445000415215236\n",
      "train loss:7.542041286394517e-05\n",
      "train loss:0.0003940757087642605\n",
      "train loss:0.0008348577177439183\n",
      "train loss:0.00322615917695384\n",
      "train loss:0.0051225309186830395\n",
      "train loss:0.0030643071291440284\n",
      "train loss:0.0022364428087046015\n",
      "train loss:0.0015020126132366262\n",
      "train loss:0.004674875766558418\n",
      "train loss:0.0018226487731382095\n",
      "train loss:0.000958491948493024\n",
      "train loss:0.007631842630331473\n",
      "train loss:0.017355655908638582\n",
      "train loss:0.008358184911546844\n",
      "train loss:0.001415075365252331\n",
      "train loss:0.005492565503476987\n",
      "train loss:0.0003991891053217349\n",
      "train loss:0.00026529102976124964\n",
      "train loss:0.00900336360869948\n",
      "train loss:0.0017568311023139298\n",
      "train loss:0.0008726637887354262\n",
      "train loss:0.0008097333089598923\n",
      "train loss:0.0029460215103034614\n",
      "train loss:0.0013805912967695933\n",
      "train loss:0.0005177866077435215\n",
      "train loss:0.001936421570758917\n",
      "train loss:0.010824874017726234\n",
      "train loss:0.002809945668007031\n",
      "train loss:0.002706826648139067\n",
      "train loss:0.012819254382541468\n",
      "train loss:0.0049264680538749495\n",
      "train loss:0.002124637158638021\n",
      "train loss:0.003119918777340007\n",
      "train loss:0.0016159518361873529\n",
      "train loss:0.0005421735648528865\n",
      "train loss:0.00195783497339558\n",
      "train loss:0.002412883940806497\n",
      "train loss:0.002284585617755124\n",
      "train loss:0.0036230954794440858\n",
      "train loss:0.010178558957006369\n",
      "train loss:0.0008604668465836683\n",
      "train loss:0.002049305365982569\n",
      "train loss:0.0018059534014193696\n",
      "train loss:0.0006981414966283464\n",
      "train loss:0.0076609414225120125\n",
      "train loss:0.0014598235435564178\n",
      "train loss:0.006375248745869728\n",
      "train loss:0.000850012397095329\n",
      "train loss:0.002387555859105845\n",
      "train loss:0.001401117924183632\n",
      "train loss:0.007466378330781237\n",
      "train loss:0.004223055561554298\n",
      "train loss:0.012721042553689992\n",
      "train loss:0.0006199974674842834\n",
      "train loss:0.004002001206789268\n",
      "train loss:0.000317861869538804\n",
      "train loss:0.0017984470826873196\n",
      "train loss:0.0005255769211771823\n",
      "train loss:0.0015299009674652898\n",
      "train loss:0.0016823094354859302\n",
      "train loss:0.02381245046017209\n",
      "train loss:0.0008525062547968942\n",
      "train loss:0.0034870140907437668\n",
      "train loss:0.0017342497424025988\n",
      "train loss:0.0028611976500358687\n",
      "train loss:0.0009615760301765365\n",
      "train loss:0.0016874227732792957\n",
      "train loss:0.00543561893533389\n",
      "train loss:0.0010466084588923855\n",
      "train loss:0.002008280121480429\n",
      "train loss:0.002157226820675857\n",
      "train loss:0.0005777026153742654\n",
      "train loss:0.0010392297855775722\n",
      "train loss:0.0004229825874776437\n",
      "train loss:0.008800901531871188\n",
      "train loss:0.0013111997323651092\n",
      "train loss:0.0007259601386658631\n",
      "train loss:0.0642680013999436\n",
      "train loss:0.0025945028673794958\n",
      "train loss:0.01588651290426269\n",
      "train loss:0.0006457631107828289\n",
      "train loss:0.0055641133288990155\n",
      "train loss:0.0006388581618408517\n",
      "train loss:0.0021609705947333775\n",
      "train loss:0.006089811894735272\n",
      "train loss:0.0020395362687230657\n",
      "train loss:0.0008353929339436722\n",
      "train loss:0.003012783117067595\n",
      "train loss:0.0005468510162729668\n",
      "train loss:0.004429242769328024\n",
      "train loss:0.006263627969060565\n",
      "train loss:0.007912578652313533\n",
      "train loss:0.01063804295500458\n",
      "train loss:0.0024637416290070172\n",
      "train loss:0.005420137939998255\n",
      "train loss:0.005008491079494157\n",
      "train loss:0.0003953113930276046\n",
      "train loss:0.004637648942458771\n",
      "train loss:0.006165498135032248\n",
      "train loss:0.005046757386933064\n",
      "train loss:0.0017991586856080553\n",
      "train loss:0.01732581222996774\n",
      "train loss:0.003481988581286612\n",
      "train loss:0.001046082286908807\n",
      "train loss:0.0015512948634092527\n",
      "train loss:0.004237481428370155\n",
      "train loss:0.0010171434974716588\n",
      "train loss:0.00422881945482939\n",
      "train loss:0.021546972738464162\n",
      "train loss:0.0006763963855366908\n",
      "train loss:0.009593496274622432\n",
      "train loss:0.004873439122631823\n",
      "train loss:0.00338297869149366\n",
      "train loss:0.003321883063066046\n",
      "train loss:0.011049778809397255\n",
      "train loss:0.0013603092772574627\n",
      "train loss:0.004608190993460374\n",
      "train loss:0.0025733687378076673\n",
      "train loss:0.001159646518772214\n",
      "train loss:0.0010738441269563378\n",
      "train loss:0.006351930748637718\n",
      "train loss:0.0035660727340213684\n",
      "train loss:0.0004436371846893761\n",
      "train loss:0.01087156706218016\n",
      "train loss:0.004628121740297726\n",
      "train loss:0.011197327221863042\n",
      "train loss:0.007274020273076098\n",
      "train loss:0.0009575313615451174\n",
      "train loss:0.011240163301685965\n",
      "train loss:0.0036627119836061626\n",
      "train loss:0.008499562642155269\n",
      "train loss:0.006162711253683688\n",
      "train loss:0.0051147835418884615\n",
      "train loss:0.005577698871631842\n",
      "train loss:0.001519280515277762\n",
      "train loss:0.0006241435607869689\n",
      "train loss:0.0021441971760299146\n",
      "train loss:0.0003486210408980481\n",
      "train loss:0.002185470405058353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009518884746576529\n",
      "train loss:0.0018102367066971513\n",
      "train loss:0.004192976156906623\n",
      "train loss:0.00039528534905117755\n",
      "train loss:0.0023373531587789374\n",
      "train loss:0.003794667842805139\n",
      "train loss:0.0007518964312207995\n",
      "train loss:0.0019206673475865785\n",
      "train loss:0.004598928107319058\n",
      "train loss:0.006664721422931007\n",
      "train loss:0.0013318688474156445\n",
      "train loss:0.0007816845616445328\n",
      "train loss:0.003585020090012977\n",
      "train loss:0.0038765510067117776\n",
      "train loss:0.0025222302483043123\n",
      "train loss:0.00542858157623814\n",
      "train loss:0.0015577889048540344\n",
      "train loss:0.0019767449795220693\n",
      "train loss:0.02059475060581856\n",
      "train loss:0.0028585992624059766\n",
      "train loss:0.0030131927313395666\n",
      "train loss:0.0037113102936547886\n",
      "train loss:0.0029989394476872067\n",
      "train loss:0.005694657873796708\n",
      "train loss:0.0004864697108101334\n",
      "train loss:0.001841724497687076\n",
      "train loss:0.001462779867309873\n",
      "train loss:0.003305252724592853\n",
      "train loss:0.0015769114562858705\n",
      "train loss:0.004012493210362801\n",
      "train loss:0.002257203638701531\n",
      "train loss:0.0008873940984034859\n",
      "train loss:0.0018078734182232436\n",
      "train loss:0.0007692328672593544\n",
      "train loss:0.009027149283664682\n",
      "train loss:0.000690347585410927\n",
      "train loss:0.0037527746852839606\n",
      "train loss:0.003264714600817178\n",
      "train loss:0.002909354129154492\n",
      "train loss:0.012753263559963458\n",
      "train loss:0.0016171900103946508\n",
      "train loss:0.004783903123002692\n",
      "train loss:0.0026474570702148662\n",
      "train loss:0.007150756836406293\n",
      "train loss:0.001595494838034258\n",
      "train loss:0.015863146706419008\n",
      "train loss:0.0005331807460986343\n",
      "train loss:0.0006141419194547305\n",
      "train loss:0.005219294026196475\n",
      "train loss:0.03963645777830037\n",
      "train loss:0.004796336159105985\n",
      "train loss:0.0017796442214534993\n",
      "train loss:0.0019076009009406918\n",
      "train loss:0.00043057332139569826\n",
      "train loss:0.0006054939494939906\n",
      "train loss:0.004164044148707114\n",
      "train loss:0.0003916848191992637\n",
      "train loss:0.0013008906516313254\n",
      "train loss:0.005404194922400029\n",
      "train loss:0.006998016223840272\n",
      "train loss:0.001064611140609865\n",
      "train loss:0.0007409076522759191\n",
      "train loss:0.0010707819604295543\n",
      "train loss:0.001600413467144825\n",
      "train loss:0.001255324306379165\n",
      "train loss:0.0024642976351518815\n",
      "train loss:0.024152643097541966\n",
      "train loss:0.0005568449208918258\n",
      "train loss:0.010507455542005478\n",
      "train loss:0.0009979552886694256\n",
      "train loss:0.002715477358968991\n",
      "train loss:0.029823826119671448\n",
      "train loss:0.004758917647036038\n",
      "train loss:0.003546405583772447\n",
      "train loss:0.00218032846499177\n",
      "train loss:0.0019884394156939864\n",
      "train loss:0.004463674246267665\n",
      "train loss:0.001220765564363005\n",
      "train loss:0.0037860330242845976\n",
      "train loss:0.0013946617725424284\n",
      "train loss:0.0019129423907716379\n",
      "train loss:0.006426665158456147\n",
      "train loss:0.00093535092764702\n",
      "train loss:0.0037407205717867385\n",
      "train loss:0.0008638862543647115\n",
      "train loss:0.0011624496405258052\n",
      "train loss:0.0014454481739450053\n",
      "train loss:0.0006253282854043135\n",
      "train loss:0.0038913693636128755\n",
      "train loss:0.006220370385705124\n",
      "train loss:0.003413981206580895\n",
      "train loss:0.002490288824974637\n",
      "train loss:0.0007421436117718532\n",
      "train loss:0.004370111081727766\n",
      "train loss:0.0016578090982803842\n",
      "train loss:0.0004192323686852181\n",
      "train loss:0.002687478211489974\n",
      "train loss:0.01404313446638986\n",
      "train loss:0.0171469294565813\n",
      "train loss:0.004233909146046896\n",
      "train loss:0.0012473474526603888\n",
      "train loss:0.0018347224961917771\n",
      "train loss:0.0024857901797155336\n",
      "train loss:0.006396056415969743\n",
      "train loss:0.0007785098840023095\n",
      "train loss:0.0009252497294431676\n",
      "train loss:0.00043911808333368127\n",
      "train loss:0.0008650969386164378\n",
      "train loss:0.0033777140300092147\n",
      "train loss:0.00029435024043681534\n",
      "train loss:0.0020847166719434387\n",
      "train loss:0.003893247688984423\n",
      "train loss:0.005450735312604097\n",
      "train loss:0.007553959439370159\n",
      "train loss:0.004398021742264184\n",
      "train loss:0.0022687528711731425\n",
      "train loss:0.02830616502558718\n",
      "train loss:0.001212170882217648\n",
      "train loss:0.0008713293401788322\n",
      "train loss:0.012748279080153371\n",
      "train loss:0.0003387515865940893\n",
      "train loss:0.004648926314758263\n",
      "train loss:0.0028452205277588235\n",
      "train loss:0.002823389520627781\n",
      "train loss:0.0013640423257108597\n",
      "train loss:0.0020652287491948586\n",
      "train loss:0.0011826889763935165\n",
      "train loss:0.0017348671408986968\n",
      "train loss:0.0010205396653561313\n",
      "train loss:0.01005493548050342\n",
      "train loss:0.00024983672092303944\n",
      "train loss:0.0020209840440878393\n",
      "train loss:0.0020543010128595326\n",
      "train loss:0.0012387689628572567\n",
      "train loss:0.0034246661548229126\n",
      "train loss:0.0015686725761969362\n",
      "train loss:0.0020365371468614502\n",
      "train loss:0.014043659737473077\n",
      "train loss:0.004424497517114721\n",
      "train loss:0.001930970382691831\n",
      "train loss:0.003899710778705844\n",
      "train loss:0.0009341804986041564\n",
      "train loss:0.0006880478211401569\n",
      "train loss:0.00033644544797753516\n",
      "train loss:0.004212992130954898\n",
      "train loss:0.0004628356055533448\n",
      "train loss:0.01188518662596336\n",
      "train loss:0.0004735216222357856\n",
      "train loss:0.001921890071262405\n",
      "train loss:0.0028413001204343467\n",
      "train loss:0.0037380084299591526\n",
      "train loss:0.0008140220746171961\n",
      "train loss:0.005095153672620267\n",
      "train loss:0.002792593971008\n",
      "train loss:0.0019334392999892343\n",
      "train loss:0.00581562893316756\n",
      "train loss:0.001967496545125025\n",
      "train loss:0.004294717536319287\n",
      "train loss:0.0004323134924668809\n",
      "train loss:0.002597765472621016\n",
      "train loss:0.0033727723470408015\n",
      "train loss:0.007289842109835043\n",
      "train loss:0.004643225375883605\n",
      "train loss:0.0034562441918847774\n",
      "train loss:0.0025451129112579146\n",
      "train loss:0.0029743927136890807\n",
      "train loss:0.0012154789297095538\n",
      "train loss:0.0030494269158219595\n",
      "train loss:0.0008352835483829241\n",
      "train loss:0.00010030119031879915\n",
      "train loss:0.011849894591477951\n",
      "train loss:0.007922994201840925\n",
      "train loss:0.0007612580498452266\n",
      "train loss:0.0019364096307893195\n",
      "train loss:0.006589845639568478\n",
      "train loss:0.0006976149619494374\n",
      "train loss:0.004795015400179728\n",
      "train loss:0.0008731908231309724\n",
      "train loss:0.001464832888544039\n",
      "train loss:0.003886865616940139\n",
      "train loss:0.0015016765919562336\n",
      "train loss:0.003929661491320793\n",
      "train loss:0.00927705458963253\n",
      "train loss:0.006289626588868054\n",
      "train loss:0.0044495849623157205\n",
      "train loss:0.0005169460130424143\n",
      "train loss:0.008308793449971201\n",
      "train loss:0.023110960979478793\n",
      "train loss:0.0011332868337946343\n",
      "train loss:0.00014294910573617962\n",
      "train loss:0.0017125557698071845\n",
      "train loss:0.0070373637262934816\n",
      "train loss:0.002900512698065371\n",
      "train loss:0.00107609260601153\n",
      "train loss:0.015777933130207294\n",
      "train loss:0.0014405849066427725\n",
      "train loss:0.005923092264247035\n",
      "train loss:0.0027853038425809874\n",
      "train loss:0.0031016938100115994\n",
      "train loss:0.0031092486244711924\n",
      "train loss:0.001827757710189278\n",
      "train loss:0.003648894851076878\n",
      "train loss:0.0010669012248010238\n",
      "train loss:0.0011941884350153602\n",
      "train loss:0.006513804214668877\n",
      "train loss:0.001580512344963393\n",
      "train loss:0.003188087393151585\n",
      "train loss:0.0010299638751151497\n",
      "train loss:0.02001623784509848\n",
      "train loss:0.0033884772370837797\n",
      "train loss:0.0014439806682548947\n",
      "train loss:0.0018179109690570228\n",
      "train loss:0.008420609655356091\n",
      "train loss:0.00019948099199057468\n",
      "train loss:0.0047415362083008195\n",
      "train loss:0.001339023741049383\n",
      "train loss:0.0008305016307550302\n",
      "train loss:0.002816398238758956\n",
      "train loss:0.0038464575231790784\n",
      "train loss:0.000575771438020114\n",
      "train loss:0.006542392423104958\n",
      "train loss:0.001181653460031506\n",
      "train loss:0.0014201608792846249\n",
      "train loss:0.01656847213088255\n",
      "train loss:0.0017703940064357948\n",
      "train loss:0.014807541381990072\n",
      "train loss:0.01075669706992154\n",
      "train loss:0.0011821838550895294\n",
      "train loss:0.0010073695573709458\n",
      "train loss:0.0010943065061180227\n",
      "train loss:0.002111510437334142\n",
      "train loss:0.0003818257228938511\n",
      "train loss:0.0034517273867172866\n",
      "train loss:0.002311026402125614\n",
      "train loss:0.0012887522155493685\n",
      "train loss:0.006733900733368396\n",
      "train loss:0.011446626029760437\n",
      "train loss:0.007197214193341214\n",
      "train loss:0.004931656101040636\n",
      "train loss:0.013231334914854431\n",
      "train loss:0.005960992831584803\n",
      "train loss:0.003369247853242197\n",
      "train loss:0.0007069251049672676\n",
      "train loss:0.0011622924167450006\n",
      "train loss:0.000857362579356399\n",
      "train loss:0.0024616931601627074\n",
      "train loss:0.0022608787526620603\n",
      "train loss:0.00269271407617506\n",
      "train loss:0.003241764773522722\n",
      "train loss:0.001362801250301769\n",
      "train loss:0.00011479320704900795\n",
      "train loss:0.004039816098299173\n",
      "train loss:0.024480821643753668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006736433353853571\n",
      "train loss:0.024454461455207847\n",
      "train loss:0.013293963097958907\n",
      "train loss:0.006722712388884992\n",
      "train loss:0.02685248125147091\n",
      "train loss:0.0008231246081025345\n",
      "train loss:0.0013334987286008103\n",
      "train loss:0.008988055483620656\n",
      "train loss:0.0006775357795077575\n",
      "train loss:0.0015440187981810472\n",
      "train loss:0.0028620337938356135\n",
      "train loss:0.013597745524862497\n",
      "train loss:0.016507229884705037\n",
      "train loss:0.009185023127534112\n",
      "train loss:0.0014298648017225803\n",
      "train loss:0.0013976943254008166\n",
      "train loss:0.00801727504327745\n",
      "train loss:0.0027279071236847407\n",
      "train loss:0.0035598488019420054\n",
      "train loss:0.002439829894253557\n",
      "train loss:0.007041675722342735\n",
      "train loss:0.0003134413847316329\n",
      "train loss:0.0012050465444392768\n",
      "train loss:0.009869617912461166\n",
      "train loss:0.002589923460205439\n",
      "train loss:0.007540106665965049\n",
      "train loss:0.0012514642772581276\n",
      "train loss:0.014796677156122992\n",
      "train loss:0.0035052132109786843\n",
      "train loss:0.005312415070655123\n",
      "train loss:0.008079865303985533\n",
      "train loss:0.0022920723755530674\n",
      "train loss:0.007106381237445898\n",
      "=== epoch:14, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0016572020253958182\n",
      "train loss:0.003300814176638193\n",
      "train loss:0.013182027045720168\n",
      "train loss:0.003910586956580988\n",
      "train loss:0.00046582624355916044\n",
      "train loss:0.007014969757000352\n",
      "train loss:0.001974390280205021\n",
      "train loss:0.0031872290032629686\n",
      "train loss:0.0015904336897654297\n",
      "train loss:0.01886528095054385\n",
      "train loss:0.0028080363420652753\n",
      "train loss:0.0042493237828776734\n",
      "train loss:0.0010902841512572341\n",
      "train loss:0.015421049550324091\n",
      "train loss:0.003815366803652389\n",
      "train loss:0.004739638951443322\n",
      "train loss:0.002537319541192081\n",
      "train loss:0.0088253092303863\n",
      "train loss:0.0027217594344681284\n",
      "train loss:0.009175872890072944\n",
      "train loss:0.0046841825643815\n",
      "train loss:0.0021166827399414934\n",
      "train loss:0.014602710316424761\n",
      "train loss:0.0020234764726524117\n",
      "train loss:0.000986774008455091\n",
      "train loss:0.004414281280984885\n",
      "train loss:0.0008363392541359796\n",
      "train loss:0.002480274277834106\n",
      "train loss:0.016388061541648912\n",
      "train loss:0.06515373299140277\n",
      "train loss:0.005995616714663861\n",
      "train loss:0.0011445435855929995\n",
      "train loss:0.01575084791107781\n",
      "train loss:0.0002553990806435294\n",
      "train loss:0.001823862899780231\n",
      "train loss:0.0022297998024119973\n",
      "train loss:0.014550063296004055\n",
      "train loss:0.0044662041314697705\n",
      "train loss:0.009527371763272964\n",
      "train loss:0.0012988144551104033\n",
      "train loss:0.0017538529794727995\n",
      "train loss:0.002973790200208622\n",
      "train loss:0.006212876406312159\n",
      "train loss:0.0009997634726628287\n",
      "train loss:0.004268762254284813\n",
      "train loss:0.0014661480792471696\n",
      "train loss:0.002088259056167467\n",
      "train loss:0.0019798855215544878\n",
      "train loss:0.0022122951468599413\n",
      "train loss:0.003688867523666305\n",
      "train loss:0.0027777451030070264\n",
      "train loss:0.0004424537437357334\n",
      "train loss:0.00419219973697978\n",
      "train loss:0.002579617514164727\n",
      "train loss:0.003359458742348424\n",
      "train loss:0.0024260473730719607\n",
      "train loss:0.010551326292245668\n",
      "train loss:0.0026079706032198736\n",
      "train loss:0.0036996722876423654\n",
      "train loss:0.0028874771923745445\n",
      "train loss:0.0006569875607618396\n",
      "train loss:0.005545958326993874\n",
      "train loss:9.345923099074364e-05\n",
      "train loss:0.0050851472418439155\n",
      "train loss:0.0038795609738479634\n",
      "train loss:0.00025633642908558495\n",
      "train loss:0.014405708873563329\n",
      "train loss:0.0010786246485291055\n",
      "train loss:0.007470558681011112\n",
      "train loss:0.003822830846893234\n",
      "train loss:0.005300788571085395\n",
      "train loss:0.004097262957794117\n",
      "train loss:0.010101531120626643\n",
      "train loss:0.0014353491753016315\n",
      "train loss:0.0007243867311558805\n",
      "train loss:0.015507159062490774\n",
      "train loss:0.0017868437958294483\n",
      "train loss:0.00047586808036026315\n",
      "train loss:0.004983854940528379\n",
      "train loss:0.0006065285269859446\n",
      "train loss:0.004415447398242261\n",
      "train loss:0.006102089669265829\n",
      "train loss:0.00360994473644686\n",
      "train loss:0.0017953691435274508\n",
      "train loss:0.0010686999193157349\n",
      "train loss:0.008961514340692572\n",
      "train loss:0.0016047219379575698\n",
      "train loss:0.0054410010599740075\n",
      "train loss:0.0012583585131495851\n",
      "train loss:0.05509310312113169\n",
      "train loss:0.0015286112752395786\n",
      "train loss:0.003929246669095765\n",
      "train loss:0.0008696680064807159\n",
      "train loss:0.0005985202758678468\n",
      "train loss:0.0006129137338779809\n",
      "train loss:0.007601239627288567\n",
      "train loss:0.0006582690265789586\n",
      "train loss:0.007946092554902043\n",
      "train loss:0.0024877316777323546\n",
      "train loss:0.0022901586476335462\n",
      "train loss:0.006337331707726574\n",
      "train loss:0.005425317978304871\n",
      "train loss:0.004940883003049174\n",
      "train loss:0.0016745396450278016\n",
      "train loss:0.002612273423281935\n",
      "train loss:0.0068986357162693105\n",
      "train loss:0.005337418383316203\n",
      "train loss:0.00026955060706389814\n",
      "train loss:0.004248960019925287\n",
      "train loss:0.0016531520749062303\n",
      "train loss:0.05556379394010793\n",
      "train loss:0.0023792479129575135\n",
      "train loss:0.0006493467933292718\n",
      "train loss:0.0009378091463783773\n",
      "train loss:0.011118124214520426\n",
      "train loss:0.00272626168921074\n",
      "train loss:0.00033291101732009417\n",
      "train loss:0.007784759208293347\n",
      "train loss:0.001579492720111746\n",
      "train loss:0.0038682802364066893\n",
      "train loss:0.0298233419539101\n",
      "train loss:0.003995619095487054\n",
      "train loss:0.007517383877692225\n",
      "train loss:0.008848223203012684\n",
      "train loss:0.0002579123678273081\n",
      "train loss:0.00748429734026239\n",
      "train loss:0.0004921696994657389\n",
      "train loss:0.0036866318206181955\n",
      "train loss:0.0012357738689732344\n",
      "train loss:0.003720788363147338\n",
      "train loss:0.00047750879440875956\n",
      "train loss:0.008529292302942335\n",
      "train loss:0.007969276421900895\n",
      "train loss:0.05723023176870542\n",
      "train loss:0.00012158723189808607\n",
      "train loss:0.0002950201586719672\n",
      "train loss:0.0006118302744910707\n",
      "train loss:0.0015684207865157213\n",
      "train loss:0.00012076889968445689\n",
      "train loss:0.01007753300940844\n",
      "train loss:0.013470546875166174\n",
      "train loss:0.0003231775511676805\n",
      "train loss:0.0006366693963455962\n",
      "train loss:0.004576852008067622\n",
      "train loss:0.0029134644438377276\n",
      "train loss:0.006616235739257781\n",
      "train loss:0.0013482679833160744\n",
      "train loss:0.004626923375241284\n",
      "train loss:0.0012688980153549917\n",
      "train loss:0.008262773170599553\n",
      "train loss:0.0026191074710759667\n",
      "train loss:0.0026572185337607602\n",
      "train loss:0.00438869078446346\n",
      "train loss:0.0038780677640530485\n",
      "train loss:0.0011410514287164884\n",
      "train loss:0.0006722368712422309\n",
      "train loss:0.005122756490580899\n",
      "train loss:0.0008261060726552925\n",
      "train loss:0.0015336308381387262\n",
      "train loss:0.0021915768394334596\n",
      "train loss:0.0037834459103279774\n",
      "train loss:0.0018476929148251485\n",
      "train loss:0.004331543070183441\n",
      "train loss:0.0025741447871475524\n",
      "train loss:0.014768390895467545\n",
      "train loss:0.0005737251110927151\n",
      "train loss:0.0008881095977784869\n",
      "train loss:0.001266816327393315\n",
      "train loss:0.007306838687555566\n",
      "train loss:0.0020725653382994355\n",
      "train loss:0.0015382267946563105\n",
      "train loss:0.0010834517327984279\n",
      "train loss:0.0002831973941778974\n",
      "train loss:0.0005825265004767008\n",
      "train loss:0.001766119331859038\n",
      "train loss:0.0064186767988060126\n",
      "train loss:0.0009153985588710803\n",
      "train loss:0.004427892153851757\n",
      "train loss:0.0010769595213051637\n",
      "train loss:0.008008540106151756\n",
      "train loss:0.000855989946481516\n",
      "train loss:0.0021076432050283114\n",
      "train loss:0.0035456275552453297\n",
      "train loss:0.0025537849492667953\n",
      "train loss:0.005807983042913073\n",
      "train loss:0.00421098764058889\n",
      "train loss:0.0021595723458135885\n",
      "train loss:0.0009052323374405728\n",
      "train loss:0.033326831861793645\n",
      "train loss:0.0016513199600453354\n",
      "train loss:0.011657565031096839\n",
      "train loss:0.0025420993924681135\n",
      "train loss:0.007539185084859878\n",
      "train loss:0.0003562737114452183\n",
      "train loss:0.0003741771673704363\n",
      "train loss:0.0016136721871325497\n",
      "train loss:0.0016701324970968589\n",
      "train loss:0.0013941530504729947\n",
      "train loss:0.003003682408191219\n",
      "train loss:0.0006578329412483513\n",
      "train loss:0.00050939828567527\n",
      "train loss:0.0004391708514093207\n",
      "train loss:0.0005955488989466097\n",
      "train loss:0.005143362086600073\n",
      "train loss:0.042722666826873874\n",
      "train loss:0.0014773447306907256\n",
      "train loss:0.003461147807026403\n",
      "train loss:0.0013956775811352926\n",
      "train loss:0.006286096996511191\n",
      "train loss:0.009302431977734733\n",
      "train loss:0.001738882888963526\n",
      "train loss:0.004056791658149157\n",
      "train loss:0.0011101874179934835\n",
      "train loss:0.035834378230830154\n",
      "train loss:0.0003023511109491963\n",
      "train loss:0.0015539005179966048\n",
      "train loss:0.00448510301992261\n",
      "train loss:0.006099913873781638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014451232436357857\n",
      "train loss:0.0009731185488671878\n",
      "train loss:0.0018009035591944644\n",
      "train loss:0.0015922611386901065\n",
      "train loss:0.0013299923342786715\n",
      "train loss:0.009028651727183139\n",
      "train loss:0.007044042177908394\n",
      "train loss:0.0003673664263884364\n",
      "train loss:0.0025248668001580667\n",
      "train loss:0.001547575226013166\n",
      "train loss:0.004899333665910644\n",
      "train loss:0.005544693197834817\n",
      "train loss:0.006476035927675549\n",
      "train loss:0.0011893253944860005\n",
      "train loss:0.002756374160602501\n",
      "train loss:0.011784743880713678\n",
      "train loss:0.0012731058814134527\n",
      "train loss:0.003922678016094713\n",
      "train loss:0.019616331476967876\n",
      "train loss:0.004853233330519913\n",
      "train loss:0.0012060730525312775\n",
      "train loss:0.0007634763763843081\n",
      "train loss:0.004259091530504157\n",
      "train loss:0.0018409973465803627\n",
      "train loss:0.0008783242387827192\n",
      "train loss:0.001430155673551701\n",
      "train loss:0.0031451066633746056\n",
      "train loss:0.007095618235704977\n",
      "train loss:0.0021240746348178364\n",
      "train loss:0.004536908516541354\n",
      "train loss:0.00360414596401748\n",
      "train loss:0.0009062695501089037\n",
      "train loss:0.011622285949779652\n",
      "train loss:0.010882280992752838\n",
      "train loss:0.00328630795403957\n",
      "train loss:0.0028350926637840403\n",
      "train loss:0.0028754103751452782\n",
      "train loss:0.0002790857183072845\n",
      "train loss:0.0022534875525192467\n",
      "train loss:0.0030237043185542965\n",
      "train loss:0.014410805170883247\n",
      "train loss:0.014545149607741918\n",
      "train loss:0.0037079666155262797\n",
      "train loss:0.002983802137906668\n",
      "train loss:0.051964299456988605\n",
      "train loss:0.0018517023404909403\n",
      "train loss:0.0007749855551169618\n",
      "train loss:0.005511316255846398\n",
      "train loss:0.007613910974134456\n",
      "train loss:0.003807665085402799\n",
      "train loss:0.024520840918625778\n",
      "train loss:0.0020287492092581627\n",
      "train loss:0.0016870339097650967\n",
      "train loss:0.0020882294797632695\n",
      "train loss:0.004387082652220265\n",
      "train loss:0.0024765130629964415\n",
      "train loss:0.0015056567466185937\n",
      "train loss:0.009182164748467838\n",
      "train loss:0.002477282300347155\n",
      "train loss:0.010222072788536986\n",
      "train loss:0.001367073033858774\n",
      "train loss:0.0022764636476125793\n",
      "train loss:0.0031470821725255514\n",
      "train loss:0.004316034082122219\n",
      "train loss:0.0012317176536980454\n",
      "train loss:0.0005148810444028291\n",
      "train loss:0.003635762174838228\n",
      "train loss:0.007066970800134965\n",
      "train loss:0.005081542618580753\n",
      "train loss:0.002222858384748684\n",
      "train loss:0.0023200225576281435\n",
      "train loss:0.0026594074377803345\n",
      "train loss:0.000596742689575297\n",
      "train loss:0.004973140257606764\n",
      "train loss:0.00166976192367103\n",
      "train loss:0.005107467739559648\n",
      "train loss:0.0019384443327683776\n",
      "train loss:0.006716679918901576\n",
      "train loss:0.0007884254734579353\n",
      "train loss:0.0016366827585455991\n",
      "train loss:0.011946089955229746\n",
      "train loss:0.0004230507665003732\n",
      "train loss:0.002371670427725025\n",
      "train loss:0.000865888325798913\n",
      "train loss:0.004312254130353892\n",
      "train loss:0.007564151197332934\n",
      "train loss:0.014089764173568924\n",
      "train loss:0.0007994984179729495\n",
      "train loss:0.0030052834226163834\n",
      "train loss:0.0012432361738724097\n",
      "train loss:0.005900563105681055\n",
      "train loss:0.0008795288272513255\n",
      "train loss:0.010791306141451497\n",
      "train loss:0.0037248155686233518\n",
      "train loss:0.002089431323719257\n",
      "train loss:0.0073710917719201\n",
      "train loss:0.0031100828873222336\n",
      "train loss:0.016313381733381493\n",
      "train loss:0.003755819981157694\n",
      "train loss:0.0017191866345877523\n",
      "train loss:0.0011223146751714625\n",
      "train loss:0.001559355098230506\n",
      "train loss:0.0002999263820917449\n",
      "train loss:0.010296894155239916\n",
      "train loss:0.006731106643484503\n",
      "train loss:0.006157157013474927\n",
      "train loss:0.001045823262268363\n",
      "train loss:0.002399032861579949\n",
      "train loss:0.009817670130155989\n",
      "train loss:0.008595723193970655\n",
      "train loss:0.02335650937489648\n",
      "train loss:0.003207024688018776\n",
      "train loss:0.0009740005144803464\n",
      "train loss:0.002048450236599742\n",
      "train loss:0.0027466452602575987\n",
      "train loss:0.00046423218338244304\n",
      "train loss:0.0058911433432485534\n",
      "train loss:0.0013723434915689408\n",
      "train loss:0.0020792775915297267\n",
      "train loss:0.013262799239758592\n",
      "train loss:0.007197267806592442\n",
      "train loss:0.002118216607846641\n",
      "train loss:0.010905053132480257\n",
      "train loss:0.004050794061764448\n",
      "train loss:0.003861762535737519\n",
      "train loss:0.0002661225959749603\n",
      "train loss:0.022222545669106034\n",
      "train loss:0.0014997255129792814\n",
      "train loss:0.0012085336964685021\n",
      "train loss:0.00789435781194099\n",
      "train loss:0.006527537872350065\n",
      "train loss:0.0005350277567048474\n",
      "train loss:0.01094398063198384\n",
      "train loss:0.0037526115864799444\n",
      "train loss:0.005255962270560229\n",
      "train loss:0.0015619057064970516\n",
      "train loss:0.002004321960052477\n",
      "train loss:0.011312791654106322\n",
      "train loss:0.004368654476120063\n",
      "train loss:0.0005582270039779958\n",
      "train loss:0.010536375367443708\n",
      "train loss:0.005964932738059091\n",
      "train loss:0.0038424351626341123\n",
      "train loss:0.0018778249103045292\n",
      "train loss:0.006603643246109059\n",
      "train loss:0.0010553250996334555\n",
      "train loss:0.004243488447685054\n",
      "train loss:0.0006267530996094208\n",
      "train loss:0.000904667795823863\n",
      "train loss:0.0019512507778786476\n",
      "train loss:0.0029100148484503315\n",
      "train loss:0.0022329968998592658\n",
      "train loss:0.0006576898251458091\n",
      "train loss:0.0016741930248542676\n",
      "train loss:0.0012714638715258764\n",
      "train loss:0.01107126919548973\n",
      "train loss:0.0039177314286947505\n",
      "train loss:0.0025448433885836698\n",
      "train loss:0.028537548090887096\n",
      "train loss:0.0011518429497480746\n",
      "train loss:0.008526929953283543\n",
      "train loss:0.0016905979454649824\n",
      "train loss:0.0036610248978925283\n",
      "train loss:0.004461726982268564\n",
      "train loss:0.0009713371839382245\n",
      "train loss:0.0005543542365309672\n",
      "train loss:0.01276022655461895\n",
      "train loss:0.00161088256935107\n",
      "train loss:0.005504792980383245\n",
      "train loss:0.004558611287611587\n",
      "train loss:0.0065815221928831906\n",
      "train loss:0.0004988615308951323\n",
      "train loss:0.0077982074435646595\n",
      "train loss:0.0036671642407363697\n",
      "train loss:0.0032718305610834925\n",
      "train loss:0.004517015430086294\n",
      "train loss:0.0008095207646275343\n",
      "train loss:0.003207907417999361\n",
      "train loss:0.00028610413321345754\n",
      "train loss:0.0006290400055404935\n",
      "train loss:0.0010317147997531409\n",
      "train loss:0.004061642946092018\n",
      "train loss:0.0012077929285926237\n",
      "train loss:0.0021402959413059958\n",
      "train loss:0.001565404628131879\n",
      "train loss:0.0018161219548276267\n",
      "train loss:0.0009582053956022823\n",
      "train loss:0.00042966442210102716\n",
      "train loss:0.002935212437492571\n",
      "train loss:0.0043237171037814855\n",
      "train loss:0.0011194322492400204\n",
      "train loss:0.0021768055534244573\n",
      "train loss:0.010135684904474524\n",
      "train loss:0.00011083864307918329\n",
      "train loss:0.0008632409056812688\n",
      "train loss:0.003557507352808652\n",
      "train loss:0.001890144338163458\n",
      "train loss:0.0053352191078938575\n",
      "train loss:0.0022433450743844048\n",
      "train loss:0.0011255345071737358\n",
      "train loss:0.005879757743930658\n",
      "train loss:0.004866056064251733\n",
      "train loss:0.006200678188377959\n",
      "train loss:0.0011668430923281068\n",
      "train loss:0.00042185636580911566\n",
      "train loss:0.00271216052403972\n",
      "train loss:0.003546993480219995\n",
      "train loss:0.0023299828398477924\n",
      "train loss:0.0013804361873056585\n",
      "train loss:0.0006310886246362859\n",
      "train loss:0.0006933903708929304\n",
      "train loss:0.0006005332887949851\n",
      "train loss:0.003635586798585509\n",
      "train loss:0.0024388706357167055\n",
      "train loss:0.004740787472133743\n",
      "train loss:0.0012391273574223318\n",
      "train loss:0.0011762755159559657\n",
      "train loss:0.0007918247417606495\n",
      "train loss:0.0008109400682255881\n",
      "train loss:0.00048215182015242855\n",
      "train loss:0.00029560680192575845\n",
      "train loss:0.004221410955245329\n",
      "train loss:0.0022977772627021317\n",
      "train loss:0.0011591001473183473\n",
      "train loss:0.014919371107403837\n",
      "train loss:0.0010098146945926813\n",
      "train loss:0.0014391721379201261\n",
      "train loss:0.002679203338411429\n",
      "train loss:0.003440070362533393\n",
      "train loss:0.0013007600668421678\n",
      "train loss:0.0034589851270220113\n",
      "train loss:0.0018159359047927922\n",
      "train loss:0.004948757383478356\n",
      "train loss:0.0040702667499057125\n",
      "train loss:0.001544283786783404\n",
      "train loss:0.00626636696526034\n",
      "train loss:0.0034861425094519787\n",
      "train loss:8.279037949785481e-05\n",
      "train loss:0.006449214049918184\n",
      "train loss:0.0005204399959620644\n",
      "train loss:0.000937940446447684\n",
      "train loss:0.012909460912570841\n",
      "train loss:0.0009403954066907787\n",
      "train loss:0.0035555460747131156\n",
      "train loss:0.00852328632622395\n",
      "train loss:0.0019802206576793636\n",
      "train loss:0.0020038959907254165\n",
      "train loss:0.001526271034159991\n",
      "train loss:0.0035167140598924853\n",
      "train loss:0.0011010876027469428\n",
      "train loss:0.0415298231791836\n",
      "train loss:0.004686944620697695\n",
      "train loss:0.005804238493048085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000376537987853116\n",
      "train loss:0.002212958011159568\n",
      "train loss:0.0030182609478806833\n",
      "train loss:0.004677218695094194\n",
      "train loss:0.002903298047623218\n",
      "train loss:0.012753069714256042\n",
      "train loss:0.00448842970803884\n",
      "train loss:0.003972715626260151\n",
      "train loss:0.0021957286169902827\n",
      "train loss:0.002839977116886118\n",
      "train loss:0.008897569846426482\n",
      "train loss:0.011454729948979931\n",
      "train loss:0.0016197169959690145\n",
      "train loss:0.0012410800141738438\n",
      "train loss:0.010887321522439198\n",
      "train loss:0.0013239447931816036\n",
      "train loss:0.001820039837962791\n",
      "train loss:0.0022567141070961604\n",
      "train loss:0.002786490857255481\n",
      "train loss:0.0019565215412715616\n",
      "train loss:0.004285323269191962\n",
      "train loss:0.0042879535008682025\n",
      "train loss:0.01274081073019653\n",
      "train loss:0.008516007094036\n",
      "train loss:0.0046228295588776865\n",
      "train loss:0.0030535989154405934\n",
      "train loss:0.01624507212078098\n",
      "train loss:0.0007251738596929078\n",
      "train loss:0.000643635664775218\n",
      "train loss:0.0059966593303501965\n",
      "train loss:0.006972645791611991\n",
      "train loss:0.0010335980977558019\n",
      "train loss:0.005119808962352114\n",
      "train loss:0.0045655243970533525\n",
      "train loss:0.006051799516385652\n",
      "train loss:0.005159746984976502\n",
      "train loss:0.0012346342876424375\n",
      "train loss:0.004682824816149983\n",
      "train loss:0.015394195728215862\n",
      "train loss:0.03138513495618807\n",
      "train loss:0.0060982723636918736\n",
      "train loss:0.00046585117142707667\n",
      "train loss:0.004575545019137925\n",
      "train loss:0.002469662845540445\n",
      "train loss:0.009815418111463763\n",
      "train loss:0.007351019125698477\n",
      "train loss:0.0012546998852591374\n",
      "train loss:0.0024304732058263827\n",
      "train loss:0.00025665805523053216\n",
      "train loss:0.0005868612548808533\n",
      "train loss:0.0016827089244500371\n",
      "train loss:0.0022034607724232933\n",
      "train loss:0.0015527041502602574\n",
      "train loss:0.0007153573168190917\n",
      "train loss:0.0006203002505227891\n",
      "train loss:0.00021011131542186703\n",
      "train loss:0.0011253097670942099\n",
      "train loss:0.0008251160960909677\n",
      "train loss:0.00507605805775643\n",
      "train loss:0.0011759648383790346\n",
      "train loss:0.005661623267108856\n",
      "train loss:0.001188159914227858\n",
      "train loss:0.00034112662043800547\n",
      "train loss:0.005396288161925622\n",
      "train loss:0.010927619818011339\n",
      "train loss:0.00014001315661521348\n",
      "train loss:0.0007660578043340608\n",
      "train loss:0.0006837536261229588\n",
      "train loss:0.021549675134434083\n",
      "train loss:0.0007180347312266868\n",
      "train loss:0.0009578943028472703\n",
      "train loss:0.0004064885836211233\n",
      "train loss:0.002750791932473916\n",
      "train loss:0.0009886032960540346\n",
      "train loss:0.0008805221060051142\n",
      "train loss:0.0028503464150068246\n",
      "train loss:0.002780943516262904\n",
      "train loss:0.0011877635405863943\n",
      "train loss:0.0012715110806995984\n",
      "train loss:0.0037502029863398967\n",
      "train loss:0.001728480732465089\n",
      "train loss:0.0016756819586540898\n",
      "train loss:0.0021807174087025032\n",
      "train loss:0.00265067204028956\n",
      "train loss:0.008069126029505881\n",
      "train loss:0.0021587883539779702\n",
      "train loss:0.00037231246144748355\n",
      "train loss:0.0066950201128922575\n",
      "train loss:0.0009796894271881964\n",
      "train loss:0.000716177327440084\n",
      "train loss:0.0006256883627539079\n",
      "train loss:0.029250507998633872\n",
      "train loss:0.003242993555685621\n",
      "train loss:0.0028536782945560164\n",
      "train loss:0.0015624549552836905\n",
      "train loss:0.009453854014345488\n",
      "train loss:0.00015074795411696863\n",
      "train loss:0.005753026360202176\n",
      "train loss:0.00031200956886465647\n",
      "train loss:0.0033518009990623435\n",
      "train loss:0.0017505581826589695\n",
      "train loss:0.0011818240754740013\n",
      "train loss:0.0007936992692721046\n",
      "train loss:0.00011405228972625347\n",
      "train loss:0.0037580176248285303\n",
      "train loss:0.008303631527280659\n",
      "train loss:0.003145248758694842\n",
      "train loss:0.00024977301161815073\n",
      "train loss:0.0005285674544958214\n",
      "train loss:0.011630729521827038\n",
      "train loss:0.005487282030352262\n",
      "train loss:0.0005077131088988261\n",
      "train loss:0.005632400212705419\n",
      "train loss:0.003231053011265534\n",
      "train loss:0.0010068884891816024\n",
      "train loss:0.001590408192659377\n",
      "train loss:0.0002399270382820229\n",
      "train loss:0.0016120918529728399\n",
      "train loss:0.003212640854323607\n",
      "train loss:0.0011679989140238433\n",
      "train loss:0.028027017313573613\n",
      "train loss:0.0012501074233103326\n",
      "train loss:0.0017935088884149272\n",
      "train loss:0.0037310834852194736\n",
      "train loss:0.0011805873313271344\n",
      "train loss:0.0046876817562942754\n",
      "train loss:0.0038512652874988966\n",
      "train loss:0.0011903591948830914\n",
      "train loss:0.0006060535959472249\n",
      "=== epoch:15, train acc:0.999, test acc:0.987 ===\n",
      "train loss:0.0013181434983796797\n",
      "train loss:0.01144120720088706\n",
      "train loss:0.00022066836181033528\n",
      "train loss:0.0024221916767964897\n",
      "train loss:0.0014107975743924712\n",
      "train loss:0.002481309105101442\n",
      "train loss:0.001459763181999152\n",
      "train loss:0.010911509330238864\n",
      "train loss:0.0008370666400075577\n",
      "train loss:0.0001358641830954929\n",
      "train loss:0.0004613862835724971\n",
      "train loss:0.004539236560447802\n",
      "train loss:0.00015479164093479112\n",
      "train loss:0.0054989023296181825\n",
      "train loss:0.005462593558553387\n",
      "train loss:0.0005042367349462898\n",
      "train loss:0.004165599165218098\n",
      "train loss:0.001238363041343627\n",
      "train loss:0.0004199461456558778\n",
      "train loss:0.0016834799176171206\n",
      "train loss:0.015253706215384738\n",
      "train loss:0.0006099134077077148\n",
      "train loss:0.010191394602030425\n",
      "train loss:0.0022148063244550446\n",
      "train loss:0.0064127137917310015\n",
      "train loss:0.0024262316505811866\n",
      "train loss:0.0007405776766098731\n",
      "train loss:0.0013416933513206524\n",
      "train loss:0.007851131991187662\n",
      "train loss:0.007062793059938594\n",
      "train loss:0.0007680700416760751\n",
      "train loss:0.005662879758460744\n",
      "train loss:0.0017655725264510373\n",
      "train loss:0.002719640851837033\n",
      "train loss:7.002616978306446e-05\n",
      "train loss:0.0018808042809989104\n",
      "train loss:0.0087427806197059\n",
      "train loss:0.026656486875798198\n",
      "train loss:0.0005342401040609083\n",
      "train loss:0.0013338847850065515\n",
      "train loss:0.006518168436355309\n",
      "train loss:0.0002843640629552041\n",
      "train loss:0.001874629127302647\n",
      "train loss:0.002435338179205932\n",
      "train loss:0.007185917885690511\n",
      "train loss:0.010400187184781725\n",
      "train loss:0.012179483363484744\n",
      "train loss:0.0014130753594018303\n",
      "train loss:0.008239477790244684\n",
      "train loss:0.0034808135448053078\n",
      "train loss:0.002609225660773599\n",
      "train loss:0.010802455273475007\n",
      "train loss:0.001839836080831681\n",
      "train loss:0.004514323166586152\n",
      "train loss:0.004143637121291884\n",
      "train loss:0.004238479575829641\n",
      "train loss:0.0029676848990917767\n",
      "train loss:0.0022709091426390098\n",
      "train loss:0.009094702526121096\n",
      "train loss:0.0015735576354111644\n",
      "train loss:0.005630569387654252\n",
      "train loss:0.000822935875215336\n",
      "train loss:0.003811658990062946\n",
      "train loss:0.002154099908268079\n",
      "train loss:0.0022708597788126733\n",
      "train loss:0.0014562187780414698\n",
      "train loss:0.001822845955503302\n",
      "train loss:0.0006921416711235185\n",
      "train loss:0.0026902674796262698\n",
      "train loss:0.005631861707961924\n",
      "train loss:0.0051232189965741805\n",
      "train loss:0.0021464104833799113\n",
      "train loss:0.004565894164098298\n",
      "train loss:0.0038836086330693814\n",
      "train loss:0.0022103693013601003\n",
      "train loss:0.0011598436531691338\n",
      "train loss:0.0016826341469327745\n",
      "train loss:0.005904045145411037\n",
      "train loss:0.006830291286292779\n",
      "train loss:0.002866010657476387\n",
      "train loss:0.0028200106262667012\n",
      "train loss:0.014562093273704653\n",
      "train loss:0.002450953971509444\n",
      "train loss:0.00040241290878168976\n",
      "train loss:0.0007525102786524872\n",
      "train loss:0.047257108257597685\n",
      "train loss:0.002065728752302108\n",
      "train loss:0.007786041396451466\n",
      "train loss:0.007774898893324115\n",
      "train loss:0.003684934685073993\n",
      "train loss:0.005511338892386311\n",
      "train loss:0.002389250996223924\n",
      "train loss:0.0008646187343587944\n",
      "train loss:0.0018553036766170445\n",
      "train loss:0.002155700138158206\n",
      "train loss:0.006302875283909386\n",
      "train loss:0.00048302504270687075\n",
      "train loss:0.013879349413062491\n",
      "train loss:0.0004196637059340466\n",
      "train loss:0.0019083085686688785\n",
      "train loss:0.0016333984223877854\n",
      "train loss:0.007554531234292754\n",
      "train loss:0.00032130433952681786\n",
      "train loss:0.0014052273982783738\n",
      "train loss:0.0012715664432046065\n",
      "train loss:0.004477885011759069\n",
      "train loss:0.000863057885318488\n",
      "train loss:0.0022810748052251467\n",
      "train loss:0.01675852607389819\n",
      "train loss:0.007450836939962232\n",
      "train loss:0.0010298342236754734\n",
      "train loss:0.01946848064618386\n",
      "train loss:0.005183940482915272\n",
      "train loss:0.0008433658328276997\n",
      "train loss:0.00621302883894922\n",
      "train loss:0.0007422689680322363\n",
      "train loss:0.0010215325426134985\n",
      "train loss:0.00073344206219982\n",
      "train loss:0.00858861890662744\n",
      "train loss:0.0019560436152585635\n",
      "train loss:0.0018920004771533585\n",
      "train loss:0.02081243232149492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004168438673701987\n",
      "train loss:0.001621995637436308\n",
      "train loss:0.00042875973151584266\n",
      "train loss:0.000976383856396352\n",
      "train loss:0.0008036673766244212\n",
      "train loss:0.007997244874162472\n",
      "train loss:0.005284280947641387\n",
      "train loss:0.003366572739076538\n",
      "train loss:0.0038036570990172963\n",
      "train loss:0.0007595047990613381\n",
      "train loss:0.0006686199954934281\n",
      "train loss:0.0076127031902975305\n",
      "train loss:0.00197173673098559\n",
      "train loss:0.0004711848921989762\n",
      "train loss:0.004048971940056988\n",
      "train loss:0.002730650864268156\n",
      "train loss:0.005963508376600426\n",
      "train loss:0.0019961857695737465\n",
      "train loss:0.005035851059148825\n",
      "train loss:0.014159011572955356\n",
      "train loss:0.005933171648481639\n",
      "train loss:0.0024023200157646117\n",
      "train loss:0.0011011687136488412\n",
      "train loss:0.0023517152684303455\n",
      "train loss:0.007446505705936529\n",
      "train loss:0.0011688486757612999\n",
      "train loss:0.0010670947619319294\n",
      "train loss:0.00010536042689900496\n",
      "train loss:0.0010434393645243339\n",
      "train loss:0.0021562191953247165\n",
      "train loss:0.010401896289642339\n",
      "train loss:0.006343097008858113\n",
      "train loss:0.0013791872376946765\n",
      "train loss:0.010254438470828886\n",
      "train loss:0.0012579346421523437\n",
      "train loss:0.0055563006722965744\n",
      "train loss:0.005480831794010384\n",
      "train loss:0.0005773790212460248\n",
      "train loss:0.005724489200001972\n",
      "train loss:0.002173235610528078\n",
      "train loss:0.0018560224158560917\n",
      "train loss:0.00023340561382953517\n",
      "train loss:0.0020683529261510004\n",
      "train loss:0.003711292821676992\n",
      "train loss:0.007740578715113222\n",
      "train loss:0.0005292484234723537\n",
      "train loss:0.008568515061936448\n",
      "train loss:0.0006494635543860715\n",
      "train loss:0.0012852093867511516\n",
      "train loss:0.004781061227509664\n",
      "train loss:0.0008608033893525019\n",
      "train loss:0.001048319438222094\n",
      "train loss:0.0025507336899393083\n",
      "train loss:0.0008945333151510871\n",
      "train loss:0.0004120083983943082\n",
      "train loss:0.00073046490343328\n",
      "train loss:0.0027548348121653548\n",
      "train loss:0.005952301422979323\n",
      "train loss:0.000334316920637606\n",
      "train loss:0.002669232677242482\n",
      "train loss:0.001234403216392735\n",
      "train loss:0.0007734093087277783\n",
      "train loss:0.000412196845612378\n",
      "train loss:0.0015840552727292385\n",
      "train loss:0.0018079660139096454\n",
      "train loss:0.0005845588367080367\n",
      "train loss:0.00543987894468932\n",
      "train loss:0.0005010284112996962\n",
      "train loss:0.004229946991538982\n",
      "train loss:0.0015722590450526841\n",
      "train loss:0.0010791953549324114\n",
      "train loss:0.0003905837469451535\n",
      "train loss:0.0021646888985608157\n",
      "train loss:0.0028538764809963556\n",
      "train loss:0.00042425790330424026\n",
      "train loss:0.0024563806286379657\n",
      "train loss:9.953155356475318e-05\n",
      "train loss:0.011984620701505633\n",
      "train loss:0.0008933873482208555\n",
      "train loss:0.003719379582726533\n",
      "train loss:0.00029908685878513925\n",
      "train loss:0.0018437900258090317\n",
      "train loss:0.003617236893708796\n",
      "train loss:0.0002815968911350938\n",
      "train loss:8.928577411453218e-05\n",
      "train loss:0.003922113247432152\n",
      "train loss:0.0031704238786909506\n",
      "train loss:0.012845054127589238\n",
      "train loss:0.0030762706968205534\n",
      "train loss:0.0013219002236912704\n",
      "train loss:0.0025531182623989403\n",
      "train loss:0.0003041093182885845\n",
      "train loss:0.0005538866155737686\n",
      "train loss:0.0008090928348881238\n",
      "train loss:0.0014300542256364343\n",
      "train loss:0.0025687254702057272\n",
      "train loss:0.00041671083178015255\n",
      "train loss:0.004177960306893303\n",
      "train loss:0.0065368978389162115\n",
      "train loss:0.004318273471557718\n",
      "train loss:0.001542955028393338\n",
      "train loss:0.0016413654490487163\n",
      "train loss:0.004099623560122757\n",
      "train loss:0.0022659380552724115\n",
      "train loss:0.0008478183090979344\n",
      "train loss:0.002460290841389378\n",
      "train loss:0.0017760894378396478\n",
      "train loss:0.0033812982806658664\n",
      "train loss:0.021134157283010168\n",
      "train loss:0.0011700157937009255\n",
      "train loss:0.00202054407581253\n",
      "train loss:0.0003979149005270378\n",
      "train loss:0.0007754056903911542\n",
      "train loss:0.0010686988823656008\n",
      "train loss:0.00232071822587624\n",
      "train loss:0.0012091584111593614\n",
      "train loss:0.0077156043676459615\n",
      "train loss:0.001642437061317731\n",
      "train loss:0.0016377332725404823\n",
      "train loss:0.002786034417515345\n",
      "train loss:0.002090866913451743\n",
      "train loss:0.0019450268416958464\n",
      "train loss:0.0007433342541502373\n",
      "train loss:0.004365298006731965\n",
      "train loss:8.260244005325786e-05\n",
      "train loss:0.0012963632351783098\n",
      "train loss:0.001994107649994654\n",
      "train loss:0.0022691333440875254\n",
      "train loss:0.00026091581053768153\n",
      "train loss:0.00681684571092385\n",
      "train loss:0.0006614376246448936\n",
      "train loss:0.00022019088616485722\n",
      "train loss:0.0010546253747704423\n",
      "train loss:0.0006087544701751939\n",
      "train loss:0.012949388719690792\n",
      "train loss:0.0032662955497784417\n",
      "train loss:0.0014429907124165447\n",
      "train loss:0.005288180114964965\n",
      "train loss:0.00352489359946046\n",
      "train loss:0.012010280082841883\n",
      "train loss:0.0027736290464400047\n",
      "train loss:0.00411532097949758\n",
      "train loss:0.00010702971721333002\n",
      "train loss:0.00026790172221994983\n",
      "train loss:0.010648750060700879\n",
      "train loss:0.0021226534032934203\n",
      "train loss:0.0006408721517066778\n",
      "train loss:0.0009786188852873399\n",
      "train loss:0.0006695087604095273\n",
      "train loss:0.002024404515149566\n",
      "train loss:0.0011540659562959798\n",
      "train loss:0.010862354244986844\n",
      "train loss:0.005092168866441836\n",
      "train loss:0.028515019328610808\n",
      "train loss:0.0005536101818517699\n",
      "train loss:0.0003692073352508269\n",
      "train loss:0.001962448228117931\n",
      "train loss:0.004775036333700603\n",
      "train loss:0.01201715734832645\n",
      "train loss:0.006132278682417705\n",
      "train loss:0.0005142390329759182\n",
      "train loss:0.001603226841464822\n",
      "train loss:0.003530299060048145\n",
      "train loss:0.0005699476817392561\n",
      "train loss:0.01443090789531015\n",
      "train loss:0.004732702883959939\n",
      "train loss:0.007050365798052096\n",
      "train loss:0.0008156070575346126\n",
      "train loss:0.002033667411788541\n",
      "train loss:0.012406674633598702\n",
      "train loss:0.030802165771195232\n",
      "train loss:0.003975136462621711\n",
      "train loss:0.003452477283603558\n",
      "train loss:0.003424017503093322\n",
      "train loss:0.007841533290129267\n",
      "train loss:0.0005503477336378276\n",
      "train loss:0.002425966621032047\n",
      "train loss:0.03219506667703024\n",
      "train loss:0.006064237321624839\n",
      "train loss:0.019255246543258848\n",
      "train loss:0.016132084982727977\n",
      "train loss:0.0041697114275455775\n",
      "train loss:0.0018227009054049815\n",
      "train loss:0.013894750026399304\n",
      "train loss:0.003587023235340698\n",
      "train loss:0.0008197758966930585\n",
      "train loss:0.0007317602483772672\n",
      "train loss:0.0008626216165016547\n",
      "train loss:0.0011211106399570227\n",
      "train loss:0.0026926031668738936\n",
      "train loss:0.014207482588772701\n",
      "train loss:0.006504680833045197\n",
      "train loss:0.033187302893636604\n",
      "train loss:0.046709627766587644\n",
      "train loss:0.0021042020120086687\n",
      "train loss:0.0028252652048047938\n",
      "train loss:0.0017054210327293745\n",
      "train loss:0.005016252889655462\n",
      "train loss:0.005756761411564053\n",
      "train loss:0.0005782142287101736\n",
      "train loss:0.0021380496548715484\n",
      "train loss:0.002324050786702754\n",
      "train loss:0.0009290984869791065\n",
      "train loss:0.012986641866015647\n",
      "train loss:0.002419742051768092\n",
      "train loss:0.0020335450825348044\n",
      "train loss:0.0025092118225985517\n",
      "train loss:0.0012003378024513895\n",
      "train loss:0.0006318925765822626\n",
      "train loss:0.07932323676517267\n",
      "train loss:0.001038622854637553\n",
      "train loss:0.0072205405484076545\n",
      "train loss:0.0003133695791886049\n",
      "train loss:0.0009462532284349695\n",
      "train loss:0.0005233674409961871\n",
      "train loss:0.021984554818247685\n",
      "train loss:0.0008476941319154259\n",
      "train loss:0.002828102527982328\n",
      "train loss:0.003755929868764024\n",
      "train loss:0.005088206380200121\n",
      "train loss:0.0009516615643696952\n",
      "train loss:0.0018909921913826944\n",
      "train loss:0.003539545595444072\n",
      "train loss:0.0035316427753143017\n",
      "train loss:0.0013279938214437004\n",
      "train loss:0.008897752140919141\n",
      "train loss:0.0006649732989737911\n",
      "train loss:0.0006054796688790186\n",
      "train loss:0.0006882172019919187\n",
      "train loss:0.0036446868503646245\n",
      "train loss:0.0008881037426963569\n",
      "train loss:0.00020075494626841303\n",
      "train loss:0.0027540277871545386\n",
      "train loss:0.004782506643129682\n",
      "train loss:0.02288791906042621\n",
      "train loss:0.01004509914384521\n",
      "train loss:0.004491340740235594\n",
      "train loss:0.019898428990870822\n",
      "train loss:0.0011743065650249187\n",
      "train loss:0.0011719712733841265\n",
      "train loss:0.002055787647012933\n",
      "train loss:0.0005742177109769868\n",
      "train loss:0.025539879800314465\n",
      "train loss:0.0022608450090019837\n",
      "train loss:0.012455484873469121\n",
      "train loss:0.00027838285555742306\n",
      "train loss:0.0029289518467505832\n",
      "train loss:0.000557901124127434\n",
      "train loss:0.004005459317835779\n",
      "train loss:0.0003644947447754075\n",
      "train loss:0.007575598197971484\n",
      "train loss:0.0058430478658077715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005915642794457875\n",
      "train loss:0.003013904627693639\n",
      "train loss:0.0013299031926275653\n",
      "train loss:0.001506481269275616\n",
      "train loss:0.0010256905326365647\n",
      "train loss:0.0005307034777787636\n",
      "train loss:0.0005721588835208537\n",
      "train loss:0.0014006465324308361\n",
      "train loss:0.00043488614501939975\n",
      "train loss:0.0026962158791779384\n",
      "train loss:0.0010185350734791805\n",
      "train loss:0.03837316214174067\n",
      "train loss:0.014668029708812971\n",
      "train loss:0.009052536523623684\n",
      "train loss:0.0008810668599859961\n",
      "train loss:0.0018037904931238636\n",
      "train loss:0.00811418242502371\n",
      "train loss:0.0013455733291941495\n",
      "train loss:9.781800164522063e-05\n",
      "train loss:0.002292804327107494\n",
      "train loss:0.004796454628066068\n",
      "train loss:0.0004411413786810414\n",
      "train loss:0.004706683520733678\n",
      "train loss:0.003974650294829697\n",
      "train loss:0.002823505976752263\n",
      "train loss:0.02674746841983041\n",
      "train loss:0.0026138640911843314\n",
      "train loss:0.0008282385991964168\n",
      "train loss:0.0017608884079124032\n",
      "train loss:0.0009501813837160195\n",
      "train loss:0.00046110318655878945\n",
      "train loss:0.0012801953841380098\n",
      "train loss:0.0009609906863902817\n",
      "train loss:0.0020130407350868896\n",
      "train loss:0.0010862422228471505\n",
      "train loss:0.013562203046792539\n",
      "train loss:0.0009219390540782988\n",
      "train loss:4.974560477275569e-05\n",
      "train loss:0.00199212919722309\n",
      "train loss:0.002048100581423222\n",
      "train loss:0.0026778862542688135\n",
      "train loss:9.264861135948192e-05\n",
      "train loss:0.00011699395375849741\n",
      "train loss:0.0044487200773403205\n",
      "train loss:9.834491174031353e-05\n",
      "train loss:0.014309950771748672\n",
      "train loss:0.000349953792117287\n",
      "train loss:0.001639194175171306\n",
      "train loss:0.0029327482974517895\n",
      "train loss:0.004230718943171283\n",
      "train loss:0.0030796837469647727\n",
      "train loss:0.001980183675384652\n",
      "train loss:0.00033492814207066623\n",
      "train loss:0.01155102789307348\n",
      "train loss:0.005794519240099252\n",
      "train loss:0.0001817949737765044\n",
      "train loss:0.001397206286973047\n",
      "train loss:0.004511968357720983\n",
      "train loss:0.005118510639018973\n",
      "train loss:0.0023718391276548083\n",
      "train loss:0.0029514263336049714\n",
      "train loss:0.004598932727609136\n",
      "train loss:0.0025992812224383227\n",
      "train loss:0.0016345134980682383\n",
      "train loss:0.007081053925774888\n",
      "train loss:0.0016317938346416374\n",
      "train loss:0.0006264952007396792\n",
      "train loss:0.009688689153332469\n",
      "train loss:0.001109739595322227\n",
      "train loss:0.0008889576248031965\n",
      "train loss:0.0165269549496108\n",
      "train loss:0.006656067393136554\n",
      "train loss:0.02491420619288699\n",
      "train loss:0.0008696112448743573\n",
      "train loss:0.0005251305919722932\n",
      "train loss:0.0008852043761896848\n",
      "train loss:0.001607071272061929\n",
      "train loss:0.0008304039111131364\n",
      "train loss:0.0025884953373890578\n",
      "train loss:0.0035171937464154195\n",
      "train loss:0.0004861650952707574\n",
      "train loss:0.0012129599541717035\n",
      "train loss:0.0003981247412825097\n",
      "train loss:0.0006311357410021168\n",
      "train loss:0.0016191973763467022\n",
      "train loss:0.0008935463870575422\n",
      "train loss:0.0027163393299657686\n",
      "train loss:0.0005205092244102902\n",
      "train loss:0.0013937876291176233\n",
      "train loss:0.004254170710383295\n",
      "train loss:6.866673492511563e-05\n",
      "train loss:0.00045628005455620264\n",
      "train loss:0.0045051896156503264\n",
      "train loss:0.0032275797011004433\n",
      "train loss:0.0007092939180195637\n",
      "train loss:0.00013956609167884717\n",
      "train loss:0.005098474874499723\n",
      "train loss:0.003546820630126586\n",
      "train loss:0.0004859227076585433\n",
      "train loss:0.003694960876707216\n",
      "train loss:0.001609285809644555\n",
      "train loss:0.003454960333549266\n",
      "train loss:0.00320435703596687\n",
      "train loss:0.006098225630487354\n",
      "train loss:0.007458692495412232\n",
      "train loss:0.002281465413777325\n",
      "train loss:0.0003196535579952141\n",
      "train loss:0.0003595101795129113\n",
      "train loss:0.001994458556704929\n",
      "train loss:0.0024574430615578705\n",
      "train loss:0.00313460188144574\n",
      "train loss:0.0008681853453167113\n",
      "train loss:0.03405839091137005\n",
      "train loss:0.0014776993550891296\n",
      "train loss:0.0007921974353479916\n",
      "train loss:0.00044544692736070093\n",
      "train loss:0.001689904187379906\n",
      "train loss:0.005599996560683444\n",
      "train loss:0.0005278198409459549\n",
      "train loss:0.0016405014518215736\n",
      "train loss:0.0003410377029002354\n",
      "train loss:0.001861469601231104\n",
      "train loss:0.0008153993739641843\n",
      "train loss:0.0033928961366346947\n",
      "train loss:0.0012310402002315792\n",
      "train loss:0.0006675174723502254\n",
      "train loss:0.003893943337780977\n",
      "train loss:0.003738052175684051\n",
      "train loss:0.010374964257726932\n",
      "train loss:0.0005924965014728439\n",
      "train loss:0.0008432613654656795\n",
      "train loss:0.003258718297602282\n",
      "train loss:0.0005371952350148766\n",
      "train loss:0.0005156425742916951\n",
      "train loss:0.0006465699918397911\n",
      "train loss:0.011523659032670157\n",
      "train loss:0.0022004688735023804\n",
      "train loss:0.0015653484850638422\n",
      "train loss:0.0005572334494886687\n",
      "train loss:0.016986845839941207\n",
      "train loss:0.004644521968158152\n",
      "train loss:0.00018294430174376722\n",
      "train loss:0.0013624005493203164\n",
      "train loss:0.0017180615577651304\n",
      "train loss:0.0019814666459157092\n",
      "train loss:0.0024368586601804234\n",
      "train loss:0.00922858078091398\n",
      "train loss:0.0030955083498510946\n",
      "train loss:0.002017536550845048\n",
      "train loss:0.00256470101508497\n",
      "train loss:0.004425306660406574\n",
      "train loss:0.002084275531755097\n",
      "train loss:0.000883232040169927\n",
      "train loss:0.00165230227790136\n",
      "train loss:0.0013610091775641642\n",
      "train loss:0.0005607395618642506\n",
      "train loss:0.0022711996265808413\n",
      "train loss:0.0026683112951422193\n",
      "train loss:0.00319392188187886\n",
      "train loss:0.00013772213613442107\n",
      "train loss:0.0013565340634359901\n",
      "train loss:0.0029546959049528204\n",
      "train loss:0.00015950496538016365\n",
      "train loss:0.0018294831675465912\n",
      "train loss:0.0012146097548732882\n",
      "train loss:0.0021905085596626984\n",
      "train loss:0.003717959080965416\n",
      "train loss:0.004119939262601496\n",
      "train loss:0.0029538108299898853\n",
      "train loss:0.00011079317377486419\n",
      "train loss:0.001328300584937778\n",
      "train loss:0.0018496731743641783\n",
      "train loss:0.03841170038718702\n",
      "train loss:0.009710483200943656\n",
      "train loss:0.00047663112217385066\n",
      "train loss:0.001061676589463492\n",
      "train loss:0.0002886158236649828\n",
      "train loss:0.0009598563478429859\n",
      "train loss:0.0009252924923689885\n",
      "train loss:0.0007839611093638063\n",
      "train loss:0.004750143082076579\n",
      "train loss:0.0068442936760707606\n",
      "train loss:0.0009407243097118753\n",
      "train loss:0.0015764161276917118\n",
      "train loss:0.0030724274004849143\n",
      "train loss:0.0016103370881691875\n",
      "train loss:0.0002596399994502027\n",
      "train loss:0.00032525687419872773\n",
      "train loss:0.00262271471305758\n",
      "train loss:0.0006187334036718426\n",
      "train loss:0.000791568281039379\n",
      "train loss:0.0009235294718531367\n",
      "train loss:0.0014524474545669405\n",
      "train loss:0.0003160033133965467\n",
      "train loss:0.008491788686526877\n",
      "train loss:0.00047871574449816245\n",
      "train loss:0.0052031942911902876\n",
      "train loss:0.02650291945861911\n",
      "train loss:0.0010724227273976048\n",
      "train loss:0.012599518447405289\n",
      "train loss:0.008598243611740301\n",
      "train loss:0.0023087452697825176\n",
      "train loss:0.0003782844883866487\n",
      "train loss:0.002578267418204482\n",
      "train loss:0.0023121897112894116\n",
      "train loss:0.004850476291406757\n",
      "train loss:0.0012666038165172558\n",
      "train loss:0.002339166472899326\n",
      "train loss:0.007262649864336776\n",
      "train loss:0.00237187201401444\n",
      "train loss:0.0009258484782929884\n",
      "train loss:0.0016184197073388106\n",
      "train loss:0.005583148900944495\n",
      "train loss:0.004242188648838302\n",
      "train loss:0.008543357695510859\n",
      "train loss:0.0025813696712806765\n",
      "train loss:0.0032376504523029385\n",
      "train loss:0.001534273998987287\n",
      "train loss:0.005963265033381194\n",
      "train loss:8.724171595364946e-05\n",
      "train loss:0.00249889026592744\n",
      "train loss:0.0006967866054234368\n",
      "train loss:0.0018959409114174806\n",
      "train loss:0.0016588075814632083\n",
      "train loss:0.016727565160347048\n",
      "train loss:0.003438017706918608\n",
      "=== epoch:16, train acc:0.998, test acc:0.986 ===\n",
      "train loss:0.008629067775472642\n",
      "train loss:0.003689861435343407\n",
      "train loss:0.02076517642432433\n",
      "train loss:0.00024017573121684957\n",
      "train loss:0.0007393686809638847\n",
      "train loss:0.0006124113913020364\n",
      "train loss:0.03550257612934302\n",
      "train loss:0.0021316616721985793\n",
      "train loss:0.0051288040656968185\n",
      "train loss:7.71212832828489e-05\n",
      "train loss:0.007215839592954667\n",
      "train loss:0.0032322605164145308\n",
      "train loss:0.006302560600140445\n",
      "train loss:0.0007559011283874731\n",
      "train loss:0.0018535328312567021\n",
      "train loss:0.031437569914729305\n",
      "train loss:0.013127423088318798\n",
      "train loss:0.0006398546047465345\n",
      "train loss:0.001968737105527282\n",
      "train loss:0.0014039426718119275\n",
      "train loss:0.001569780662508535\n",
      "train loss:0.0012905723713506425\n",
      "train loss:0.0007785549297416483\n",
      "train loss:0.0040387758490517504\n",
      "train loss:0.001021104730313598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004305110254147667\n",
      "train loss:0.0010290789583595264\n",
      "train loss:0.00024987522167776495\n",
      "train loss:0.002395994741143249\n",
      "train loss:0.0007301470996510863\n",
      "train loss:0.0006739078422048345\n",
      "train loss:0.0018809434575240021\n",
      "train loss:0.001840428646963613\n",
      "train loss:0.0007741132664441405\n",
      "train loss:0.0029693571225026336\n",
      "train loss:0.0001236263653467149\n",
      "train loss:0.0015146578196870261\n",
      "train loss:0.00023125936289194305\n",
      "train loss:0.0021148711122124988\n",
      "train loss:0.001728359646069755\n",
      "train loss:0.0002002279450676232\n",
      "train loss:0.008310383600119098\n",
      "train loss:0.0036437061809772775\n",
      "train loss:0.003016089184075624\n",
      "train loss:0.0023886850685162233\n",
      "train loss:0.0006650047325391555\n",
      "train loss:0.0048540321129783215\n",
      "train loss:0.015479850405191044\n",
      "train loss:0.001818874494108613\n",
      "train loss:0.0005719230062281637\n",
      "train loss:0.0009066840270201047\n",
      "train loss:0.005601922563329893\n",
      "train loss:0.0003873115738576986\n",
      "train loss:0.0009303340330663134\n",
      "train loss:0.0012029378431872085\n",
      "train loss:0.0019392248027619056\n",
      "train loss:0.0006109905173325356\n",
      "train loss:0.003235823894097112\n",
      "train loss:0.0025182782181725626\n",
      "train loss:0.0009349534709763486\n",
      "train loss:0.0014796915396533652\n",
      "train loss:0.0026036025604564412\n",
      "train loss:0.0010426534499259925\n",
      "train loss:0.00020376479925208115\n",
      "train loss:0.0031512731749705975\n",
      "train loss:0.0015457292815477836\n",
      "train loss:0.0007111495982323328\n",
      "train loss:0.0004214112446441549\n",
      "train loss:0.001324462390754688\n",
      "train loss:0.0011203580802899094\n",
      "train loss:0.0010142325551258911\n",
      "train loss:0.0013306037974022086\n",
      "train loss:0.0002904937477364753\n",
      "train loss:0.0005239489781035222\n",
      "train loss:0.031055149002736537\n",
      "train loss:0.001620082577404401\n",
      "train loss:0.0001980870700124959\n",
      "train loss:0.005814515901476037\n",
      "train loss:0.004522262787158726\n",
      "train loss:0.006467879254826385\n",
      "train loss:0.0013481280798031436\n",
      "train loss:0.0020483264993871285\n",
      "train loss:0.0005127753762435227\n",
      "train loss:0.0029509789754178966\n",
      "train loss:0.0021994421651838365\n",
      "train loss:0.0026876133520131002\n",
      "train loss:0.010144102304798293\n",
      "train loss:0.0019652105655963855\n",
      "train loss:4.442476895240817e-05\n",
      "train loss:0.00016206936549364114\n",
      "train loss:0.0021460041564269074\n",
      "train loss:0.0026821001840366234\n",
      "train loss:0.0018973182365366334\n",
      "train loss:0.0011226792526490318\n",
      "train loss:0.0013398403533860814\n",
      "train loss:0.005579201897757713\n",
      "train loss:0.0006590215181531332\n",
      "train loss:0.0025095382568272656\n",
      "train loss:0.013115986950228333\n",
      "train loss:0.011869436960641501\n",
      "train loss:0.00014506540483081814\n",
      "train loss:7.444657654560292e-05\n",
      "train loss:0.0017039851744820836\n",
      "train loss:0.0008508281659027083\n",
      "train loss:0.0008867384756754886\n",
      "train loss:0.0018037027717104609\n",
      "train loss:0.0002077599456018578\n",
      "train loss:0.021072730546140984\n",
      "train loss:0.0011599564328409028\n",
      "train loss:0.0010109164628837228\n",
      "train loss:0.0004968627524872636\n",
      "train loss:0.0015179253713636196\n",
      "train loss:0.0030967247581394556\n",
      "train loss:0.004947286445318072\n",
      "train loss:0.0013972596562113254\n",
      "train loss:0.0002702292691431776\n",
      "train loss:0.0007950717705351593\n",
      "train loss:0.005526397979338903\n",
      "train loss:0.0014335242382473863\n",
      "train loss:0.003427390923584661\n",
      "train loss:0.00016911887634321444\n",
      "train loss:0.001493764495213815\n",
      "train loss:0.0024176192172527555\n",
      "train loss:0.00044781879272434087\n",
      "train loss:0.0010415958196245212\n",
      "train loss:0.002367223589282999\n",
      "train loss:0.0007603328868916205\n",
      "train loss:0.00199534527646583\n",
      "train loss:0.001258841905374838\n",
      "train loss:0.003783544149368356\n",
      "train loss:0.003513508556090664\n",
      "train loss:0.0007806118525830262\n",
      "train loss:0.0005284635487143316\n",
      "train loss:0.0010436261365474367\n",
      "train loss:0.00749117386482455\n",
      "train loss:0.0014017077535931639\n",
      "train loss:0.0006381630446718899\n",
      "train loss:0.00179294472842403\n",
      "train loss:0.0014872836117880823\n",
      "train loss:0.0005745899604859802\n",
      "train loss:0.0013161024851215727\n",
      "train loss:0.008039149570323116\n",
      "train loss:0.0011421301271416127\n",
      "train loss:0.0019943836236738406\n",
      "train loss:0.0005535031329375139\n",
      "train loss:0.002331394031534078\n",
      "train loss:0.005363960255706297\n",
      "train loss:0.004283887673257181\n",
      "train loss:0.0017243878733602513\n",
      "train loss:0.0010372054064411828\n",
      "train loss:0.001159603936360441\n",
      "train loss:0.0030468940930903493\n",
      "train loss:0.0023410022277950086\n",
      "train loss:0.00631499277588101\n",
      "train loss:0.00037651112743030085\n",
      "train loss:0.001562079635546098\n",
      "train loss:0.006264318922969768\n",
      "train loss:0.0018560523921309989\n",
      "train loss:0.004684622448358101\n",
      "train loss:0.0025858686932787645\n",
      "train loss:0.0016470442321451246\n",
      "train loss:0.006610688806887266\n",
      "train loss:0.0007461077548733511\n",
      "train loss:0.02441895314977481\n",
      "train loss:0.0027535646567411324\n",
      "train loss:0.001286814179788491\n",
      "train loss:0.00016345339608438578\n",
      "train loss:0.0012921141420109133\n",
      "train loss:0.0023330438322666713\n",
      "train loss:0.00040059292536126\n",
      "train loss:0.006481896062946984\n",
      "train loss:0.004614112745238592\n",
      "train loss:0.00931452525434539\n",
      "train loss:0.00017530324851799755\n",
      "train loss:0.0017209015732425142\n",
      "train loss:0.001328803278584162\n",
      "train loss:0.017879740986948785\n",
      "train loss:0.007449765511054312\n",
      "train loss:0.00026059806476352035\n",
      "train loss:0.00040188558357769544\n",
      "train loss:0.0034184949022902844\n",
      "train loss:0.001883635439189689\n",
      "train loss:0.00014247263792720684\n",
      "train loss:0.022650866715190676\n",
      "train loss:0.0025461182459210374\n",
      "train loss:0.0015465628435101294\n",
      "train loss:0.00028405300801681804\n",
      "train loss:0.0025347288954671006\n",
      "train loss:0.001960134221457201\n",
      "train loss:0.005225460966217767\n",
      "train loss:0.0006087118651910187\n",
      "train loss:0.008724203991271967\n",
      "train loss:0.00026544630536348636\n",
      "train loss:0.0016793629566443375\n",
      "train loss:0.0001537923160569682\n",
      "train loss:0.0008681547095586022\n",
      "train loss:0.0002665370202258752\n",
      "train loss:0.00044730252242790357\n",
      "train loss:0.0005679860788209301\n",
      "train loss:0.0008765315636648687\n",
      "train loss:0.0009035521642249074\n",
      "train loss:0.0007353485941018181\n",
      "train loss:0.0003715966035055586\n",
      "train loss:0.004340981332249663\n",
      "train loss:0.016956228983391483\n",
      "train loss:0.002486913471920548\n",
      "train loss:0.001813050538474359\n",
      "train loss:0.00032500648661475416\n",
      "train loss:0.0037302487065819768\n",
      "train loss:0.0005709572305410744\n",
      "train loss:0.0004945001509577816\n",
      "train loss:9.076084662952673e-05\n",
      "train loss:0.0012001225666777844\n",
      "train loss:0.001829579896099622\n",
      "train loss:0.00040295251745129117\n",
      "train loss:0.000437622630301323\n",
      "train loss:0.0011671164152582902\n",
      "train loss:0.0005920700331016863\n",
      "train loss:0.0027420648174596497\n",
      "train loss:0.017758046470559143\n",
      "train loss:0.0019700116770677858\n",
      "train loss:0.003972682694913731\n",
      "train loss:0.00047519418798913513\n",
      "train loss:0.0016625471286759327\n",
      "train loss:0.004942263314231945\n",
      "train loss:0.0008240742862453046\n",
      "train loss:0.0006010618297060048\n",
      "train loss:0.013414080871880129\n",
      "train loss:0.0013179796042127594\n",
      "train loss:0.0012512005214398605\n",
      "train loss:0.01568044793390798\n",
      "train loss:0.0023261178250787795\n",
      "train loss:0.0007184572027069507\n",
      "train loss:0.006236061960173466\n",
      "train loss:0.006261394786820072\n",
      "train loss:0.0028867577686649015\n",
      "train loss:0.0007874624005444589\n",
      "train loss:0.0035858625820899253\n",
      "train loss:0.001698585481760964\n",
      "train loss:0.011020106495671467\n",
      "train loss:0.00233129319198437\n",
      "train loss:0.013743887547843767\n",
      "train loss:0.005578078686531757\n",
      "train loss:0.005726367430707298\n",
      "train loss:0.0008713759146950102\n",
      "train loss:0.0027268817074117147\n",
      "train loss:0.00026273103331510815\n",
      "train loss:0.0010005337739367342\n",
      "train loss:0.0009426323002770119\n",
      "train loss:0.0007410281111687357\n",
      "train loss:0.0005856601125929872\n",
      "train loss:0.0012890381841242826\n",
      "train loss:0.0012150523292892446\n",
      "train loss:0.009476352004349474\n",
      "train loss:0.00023899316168546038\n",
      "train loss:0.0390025252049016\n",
      "train loss:0.0017628609223154115\n",
      "train loss:0.00025581827849584265\n",
      "train loss:0.00019622235988944764\n",
      "train loss:0.0002538730285799431\n",
      "train loss:0.02731187576394864\n",
      "train loss:0.0009504785599313128\n",
      "train loss:0.006774818683877897\n",
      "train loss:0.001176069800076573\n",
      "train loss:0.0013075938506094218\n",
      "train loss:0.001755926159356089\n",
      "train loss:0.00605914189988899\n",
      "train loss:0.002372516942608868\n",
      "train loss:0.003861506033205077\n",
      "train loss:0.001161690873270167\n",
      "train loss:0.0006151589200407414\n",
      "train loss:0.0021871286354382424\n",
      "train loss:0.004473034820426048\n",
      "train loss:0.0010656378481045787\n",
      "train loss:4.5437804023306055e-05\n",
      "train loss:0.010256285400116489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006344723761584854\n",
      "train loss:0.0008088133133895438\n",
      "train loss:0.0032337235619874973\n",
      "train loss:0.006136500812395278\n",
      "train loss:0.0003016636590979245\n",
      "train loss:0.001492948254572456\n",
      "train loss:0.009479348672328396\n",
      "train loss:0.003416353647289883\n",
      "train loss:0.0025949421803357947\n",
      "train loss:0.0024931497316533907\n",
      "train loss:0.001615616218751636\n",
      "train loss:0.0010831309759422817\n",
      "train loss:0.008052407044518787\n",
      "train loss:0.0024795821740381213\n",
      "train loss:0.0011491912240128945\n",
      "train loss:0.0071377929388330656\n",
      "train loss:0.0017439100253761387\n",
      "train loss:0.00024277938935074228\n",
      "train loss:0.007669930269810988\n",
      "train loss:0.002362119638051741\n",
      "train loss:0.0027490746670130366\n",
      "train loss:0.011160395723040792\n",
      "train loss:0.0037848808574107514\n",
      "train loss:0.002137167856459639\n",
      "train loss:0.0012008013919120055\n",
      "train loss:0.00037693378261787993\n",
      "train loss:0.0014813642332732427\n",
      "train loss:0.0026775623108846788\n",
      "train loss:0.0007043543181679082\n",
      "train loss:0.002027396223068646\n",
      "train loss:0.001029527671949933\n",
      "train loss:0.011285455272137857\n",
      "train loss:0.0016064025139513724\n",
      "train loss:0.0023117940186569517\n",
      "train loss:0.00033944273116465396\n",
      "train loss:0.000284884884903364\n",
      "train loss:0.0002399643819865305\n",
      "train loss:0.0019608195400914142\n",
      "train loss:0.0019540440659607367\n",
      "train loss:0.00018515456172866506\n",
      "train loss:0.003901322782863924\n",
      "train loss:0.0027457897739615288\n",
      "train loss:0.004038655018979748\n",
      "train loss:0.0043596410841928715\n",
      "train loss:0.0011688601653370334\n",
      "train loss:0.0020250130271631628\n",
      "train loss:0.0019440127814953632\n",
      "train loss:0.0012060941360911492\n",
      "train loss:0.004129946675987524\n",
      "train loss:0.0004116646950904992\n",
      "train loss:0.005563226380980625\n",
      "train loss:0.006470735680216637\n",
      "train loss:2.6431438134076452e-05\n",
      "train loss:0.0011927277419873175\n",
      "train loss:0.0069486596090823725\n",
      "train loss:0.001607508614094039\n",
      "train loss:0.00012516380632339067\n",
      "train loss:0.001117229301252191\n",
      "train loss:0.004673542283897249\n",
      "train loss:0.00026552494482607133\n",
      "train loss:0.00018159460716158732\n",
      "train loss:3.367014061265668e-05\n",
      "train loss:0.0009904169019804207\n",
      "train loss:0.001143666542445459\n",
      "train loss:0.0007402872964870434\n",
      "train loss:0.001205226944931144\n",
      "train loss:0.003557346982415154\n",
      "train loss:0.0033114581993387367\n",
      "train loss:0.002822465988302745\n",
      "train loss:0.005790955051269345\n",
      "train loss:0.03870920008465471\n",
      "train loss:0.0007651370161827079\n",
      "train loss:0.001970204332322952\n",
      "train loss:0.004236092192878701\n",
      "train loss:0.0007940604055428405\n",
      "train loss:0.0009474334921887031\n",
      "train loss:0.0007423374410377996\n",
      "train loss:0.0015059680652118887\n",
      "train loss:0.0026564223756051692\n",
      "train loss:0.0008149280651880034\n",
      "train loss:0.001282987556595174\n",
      "train loss:0.0005385285161581475\n",
      "train loss:0.0006129155078564024\n",
      "train loss:0.0036711938556108076\n",
      "train loss:0.0009429326606556248\n",
      "train loss:0.006616916777810288\n",
      "train loss:0.00014992738558388793\n",
      "train loss:0.002151887079209676\n",
      "train loss:0.0016404029599051066\n",
      "train loss:0.001028738988265347\n",
      "train loss:9.253612383186534e-05\n",
      "train loss:7.956733952581123e-05\n",
      "train loss:0.0007293786400235205\n",
      "train loss:0.0018085662054959063\n",
      "train loss:0.0019288953570461584\n",
      "train loss:0.0002246505931094403\n",
      "train loss:0.00014371927573768054\n",
      "train loss:0.0010058846435210768\n",
      "train loss:0.0013699170092503746\n",
      "train loss:0.0012748999749444096\n",
      "train loss:0.001971613734547621\n",
      "train loss:0.00012180145317338511\n",
      "train loss:0.05518652258801407\n",
      "train loss:0.0017606162203690754\n",
      "train loss:0.0044908200664832065\n",
      "train loss:0.004702856924150236\n",
      "train loss:8.037337534635083e-05\n",
      "train loss:0.00038672974574541\n",
      "train loss:0.0002871307712387233\n",
      "train loss:0.0005456221192402018\n",
      "train loss:0.009722593244203364\n",
      "train loss:0.0008961508735826462\n",
      "train loss:0.00042933522493300504\n",
      "train loss:0.003229512588697791\n",
      "train loss:0.0012836573284027487\n",
      "train loss:0.0005685394361302376\n",
      "train loss:0.0008845750697026584\n",
      "train loss:0.0002813793667524495\n",
      "train loss:0.0004845251322609408\n",
      "train loss:0.0029060032488518665\n",
      "train loss:0.008691386624809859\n",
      "train loss:0.005904771731924805\n",
      "train loss:0.0021588373916561847\n",
      "train loss:9.249475796922429e-05\n",
      "train loss:0.0016502470932866977\n",
      "train loss:0.0065431237267049944\n",
      "train loss:0.00816671682647636\n",
      "train loss:0.0029020062490414623\n",
      "train loss:0.000716322889233509\n",
      "train loss:0.002179707978377718\n",
      "train loss:0.0010940579062680886\n",
      "train loss:0.0020494606355523364\n",
      "train loss:0.011578944141428493\n",
      "train loss:0.00048189506582964613\n",
      "train loss:0.0073169017160015426\n",
      "train loss:0.004283815129650736\n",
      "train loss:0.00011278189199257045\n",
      "train loss:0.00011008606543218028\n",
      "train loss:0.0012013171805873115\n",
      "train loss:0.003449588224352053\n",
      "train loss:2.8149018761667344e-05\n",
      "train loss:0.00035244906982203104\n",
      "train loss:0.0026406108948079615\n",
      "train loss:0.0006807659643851416\n",
      "train loss:0.004218100060902102\n",
      "train loss:0.0012733388955616027\n",
      "train loss:0.0010432398800034209\n",
      "train loss:0.0006561450708005745\n",
      "train loss:0.0023285486403644778\n",
      "train loss:0.001056004868878349\n",
      "train loss:0.043784994788357456\n",
      "train loss:0.001167439151261649\n",
      "train loss:0.0006569529913753292\n",
      "train loss:0.004670795534031492\n",
      "train loss:0.004272636243737438\n",
      "train loss:0.00042159289234487083\n",
      "train loss:0.00044295577091267807\n",
      "train loss:0.002875112688310172\n",
      "train loss:0.000386251080697266\n",
      "train loss:0.002473265369109108\n",
      "train loss:0.00028377992679991715\n",
      "train loss:0.00022439795392699844\n",
      "train loss:0.0003095859006031638\n",
      "train loss:0.00024408229971154344\n",
      "train loss:0.0015778078389950662\n",
      "train loss:0.0017967646623326772\n",
      "train loss:0.014817706725747138\n",
      "train loss:0.0019143333142552362\n",
      "train loss:0.0005165562039108373\n",
      "train loss:0.00442418326334159\n",
      "train loss:0.00048639738721642094\n",
      "train loss:0.0024642300029882745\n",
      "train loss:0.0004379804263686002\n",
      "train loss:0.0006516900736832956\n",
      "train loss:0.0015362209012486942\n",
      "train loss:0.005958632471539895\n",
      "train loss:0.0009799071999804163\n",
      "train loss:0.005920730836024406\n",
      "train loss:0.0018962148374322982\n",
      "train loss:0.0014258821131844595\n",
      "train loss:0.005012513502781694\n",
      "train loss:0.0007528569817042474\n",
      "train loss:0.00035467526847306164\n",
      "train loss:0.0015928416406324245\n",
      "train loss:0.0012111605529541197\n",
      "train loss:0.00016897279817703744\n",
      "train loss:0.0032513134343454832\n",
      "train loss:0.00013608902507050068\n",
      "train loss:0.0038353117794966245\n",
      "train loss:0.0019084959326122952\n",
      "train loss:0.00016635662296513804\n",
      "train loss:0.0016804442111350588\n",
      "train loss:0.0020225869380231278\n",
      "train loss:0.001037116034721103\n",
      "train loss:0.00021451081370985105\n",
      "train loss:0.0011919058732123913\n",
      "train loss:0.000889331682846802\n",
      "train loss:0.001022952798672528\n",
      "train loss:0.00017301284350611034\n",
      "train loss:0.004572602843637412\n",
      "train loss:0.0007605347912470899\n",
      "train loss:0.0002837748121935055\n",
      "train loss:0.0026057476123246422\n",
      "train loss:0.00027228636292228717\n",
      "train loss:0.00029199672992000095\n",
      "train loss:0.0017764533199663918\n",
      "train loss:0.0006498466449447253\n",
      "train loss:8.044079758294048e-05\n",
      "train loss:0.010266787525692368\n",
      "train loss:0.0024779622010043857\n",
      "train loss:0.0007749337373582691\n",
      "train loss:0.002136795335329785\n",
      "train loss:0.003432601346247752\n",
      "train loss:0.0006848481736452533\n",
      "train loss:0.006043092654280359\n",
      "train loss:0.00418862485265626\n",
      "train loss:0.0011224217682485823\n",
      "train loss:0.00028408139027804897\n",
      "train loss:0.0003025460274963611\n",
      "train loss:0.0002081598680154607\n",
      "train loss:0.0037879393677928115\n",
      "train loss:0.008323220101739422\n",
      "train loss:0.001217252478968106\n",
      "train loss:0.0019684219277335906\n",
      "train loss:0.0038211160113153296\n",
      "train loss:0.00036987930728923826\n",
      "train loss:0.003157272505450873\n",
      "train loss:0.0020659906837550666\n",
      "train loss:0.000537669932949655\n",
      "train loss:0.0027193011323524913\n",
      "train loss:0.002514768627394101\n",
      "train loss:0.0014100410710876005\n",
      "train loss:0.0005712394591761284\n",
      "train loss:0.010951983893832387\n",
      "train loss:0.002102617954085199\n",
      "train loss:0.006148774366235009\n",
      "train loss:0.0032274688098761772\n",
      "train loss:0.0018052451558687721\n",
      "train loss:0.0086422946733944\n",
      "train loss:0.003358644468196753\n",
      "train loss:0.0019155549742945288\n",
      "train loss:0.0028493469757989594\n",
      "train loss:0.00089933144161253\n",
      "train loss:0.0011070930257632468\n",
      "train loss:0.002567398514987021\n",
      "train loss:0.0007938395824658996\n",
      "train loss:0.003241129818143009\n",
      "train loss:0.010685559381324624\n",
      "train loss:0.0025420164000860158\n",
      "train loss:0.0002069628735213764\n",
      "train loss:0.01404546818554584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001606447921037052\n",
      "train loss:0.022953201982331105\n",
      "train loss:0.0023606789373193967\n",
      "train loss:0.0007728461014002228\n",
      "train loss:0.0055152402191683105\n",
      "train loss:0.0020909952169963224\n",
      "train loss:0.0008494782563219436\n",
      "train loss:0.00449559791564694\n",
      "train loss:0.000362259059888733\n",
      "train loss:0.025793891522220364\n",
      "train loss:0.0008741610154741133\n",
      "train loss:0.0048998834258653125\n",
      "train loss:0.0020157704411934902\n",
      "train loss:0.00735306208590183\n",
      "train loss:0.00478325300131417\n",
      "train loss:0.0021949657811056217\n",
      "train loss:0.00047648367389294404\n",
      "train loss:0.0009729501094390905\n",
      "train loss:0.0017109916030271731\n",
      "train loss:0.0017372553567827202\n",
      "train loss:0.0015563455598977516\n",
      "train loss:0.0004625059498496915\n",
      "train loss:0.005921694222923193\n",
      "train loss:0.0006879699622912705\n",
      "train loss:0.005519565937009697\n",
      "train loss:0.0002798374046241128\n",
      "train loss:0.002802117369329249\n",
      "train loss:0.0003748158188271656\n",
      "train loss:0.0010156656455256748\n",
      "train loss:0.002385391515061518\n",
      "train loss:0.002758599084713033\n",
      "train loss:0.0003567110584245059\n",
      "train loss:0.0015140263808986478\n",
      "train loss:0.002233050917150939\n",
      "train loss:0.015382782362125678\n",
      "train loss:0.00016833050124531845\n",
      "train loss:0.0010978048705928816\n",
      "train loss:0.0011488490579522736\n",
      "train loss:0.007208753887466177\n",
      "train loss:0.001137079181829527\n",
      "train loss:0.0006697259715911028\n",
      "train loss:0.0005828802065094363\n",
      "train loss:0.004078494078823766\n",
      "train loss:0.0003649094706770773\n",
      "train loss:0.00044029361979695857\n",
      "train loss:0.00017352699778888262\n",
      "train loss:0.0002595092193590084\n",
      "train loss:0.00024953157302981077\n",
      "train loss:0.0035456060627644314\n",
      "train loss:0.001131230567271573\n",
      "train loss:0.001789287353550068\n",
      "train loss:0.00015613480856581637\n",
      "train loss:0.0006882186840552582\n",
      "train loss:0.0020323619208306005\n",
      "train loss:0.010307819613603138\n",
      "train loss:0.0013158082572107402\n",
      "train loss:0.005068599828120939\n",
      "train loss:0.00010365462567370552\n",
      "train loss:0.0007693055180956936\n",
      "train loss:0.000360407902505247\n",
      "train loss:0.000699704620226449\n",
      "train loss:0.0019365358333015225\n",
      "train loss:0.0010630858017574897\n",
      "train loss:0.000644645400427773\n",
      "train loss:0.001589925756108726\n",
      "train loss:0.004510088868289612\n",
      "train loss:6.83141527878278e-05\n",
      "train loss:0.0006770566676369059\n",
      "train loss:0.00010463751070789727\n",
      "train loss:0.00017213657217050478\n",
      "train loss:0.0002173816211782031\n",
      "train loss:0.0013797871824343477\n",
      "train loss:0.0010549849854775732\n",
      "=== epoch:17, train acc:0.999, test acc:0.985 ===\n",
      "train loss:0.0011063506265693007\n",
      "train loss:0.0030075544601383813\n",
      "train loss:0.004717115315339796\n",
      "train loss:0.00029173802920256847\n",
      "train loss:0.0016973032788809425\n",
      "train loss:0.0004260698528161009\n",
      "train loss:0.00012963424294973756\n",
      "train loss:0.00033760574827693346\n",
      "train loss:0.0019531091878727425\n",
      "train loss:0.0003236925882739579\n",
      "train loss:0.0011959566096433902\n",
      "train loss:0.0019164230580102177\n",
      "train loss:0.0024144232522269418\n",
      "train loss:0.0011873888674126228\n",
      "train loss:0.0030828903317279928\n",
      "train loss:0.002406017108506021\n",
      "train loss:0.0009874006772810225\n",
      "train loss:0.0031693934298364563\n",
      "train loss:0.00030378689873945044\n",
      "train loss:0.00281354960771636\n",
      "train loss:0.001010117897877192\n",
      "train loss:0.0005219871484353393\n",
      "train loss:0.001853857773815562\n",
      "train loss:0.00026642931821594084\n",
      "train loss:0.0009314126209431944\n",
      "train loss:0.0044327041339658705\n",
      "train loss:0.0030866805972263344\n",
      "train loss:0.0008568162160640188\n",
      "train loss:0.0005876049407094432\n",
      "train loss:0.005224493727906687\n",
      "train loss:0.0003601121716974423\n",
      "train loss:0.0003148044687433337\n",
      "train loss:0.0009131277709196453\n",
      "train loss:0.0004439642953538942\n",
      "train loss:0.001851058094027671\n",
      "train loss:0.0010100703357071095\n",
      "train loss:0.00022604905857462513\n",
      "train loss:7.76277815604062e-05\n",
      "train loss:0.000536896653416886\n",
      "train loss:0.0006175169110124796\n",
      "train loss:0.0034243909473034894\n",
      "train loss:0.000989563635880279\n",
      "train loss:0.0017552323868109778\n",
      "train loss:0.0002672946818483554\n",
      "train loss:0.0010274070861100533\n",
      "train loss:0.0027178397559029736\n",
      "train loss:5.031513779170461e-05\n",
      "train loss:0.0009941774781835758\n",
      "train loss:0.0010350895553500653\n",
      "train loss:0.0004651176861803973\n",
      "train loss:0.0016155287639255192\n",
      "train loss:0.002893912733635773\n",
      "train loss:0.0015685504661387445\n",
      "train loss:0.0009564161871720141\n",
      "train loss:0.0016211026141431772\n",
      "train loss:0.0024642149872917767\n",
      "train loss:0.0012110758242486958\n",
      "train loss:5.180135644512753e-05\n",
      "train loss:0.0011067333586904093\n",
      "train loss:0.002013565157977482\n",
      "train loss:0.00012228350600398843\n",
      "train loss:0.00913033593348674\n",
      "train loss:0.00012946243185893823\n",
      "train loss:0.001209217988045206\n",
      "train loss:0.0002052207852097656\n",
      "train loss:0.002476249753640692\n",
      "train loss:0.013010254545088203\n",
      "train loss:0.00369847976872825\n",
      "train loss:0.0018965887341277213\n",
      "train loss:1.004159423797839e-05\n",
      "train loss:0.0005639133657696418\n",
      "train loss:0.0016355217410897631\n",
      "train loss:0.0013761876196650563\n",
      "train loss:0.0006377010195986852\n",
      "train loss:0.005795195146683978\n",
      "train loss:0.0019437848825105733\n",
      "train loss:0.0007799648778908748\n",
      "train loss:0.0011463324834555383\n",
      "train loss:0.00027813232316462977\n",
      "train loss:0.002414800935426461\n",
      "train loss:0.018492716267894685\n",
      "train loss:0.00010621912563223382\n",
      "train loss:0.005487803070682976\n",
      "train loss:0.0012273981738678253\n",
      "train loss:0.0015396647921139966\n",
      "train loss:0.001523153157174953\n",
      "train loss:0.0005358456116382554\n",
      "train loss:0.00010198615405967366\n",
      "train loss:0.0030858830578421644\n",
      "train loss:0.0017079157793942238\n",
      "train loss:0.0010564538640638883\n",
      "train loss:0.002083904144328935\n",
      "train loss:0.000354899267587052\n",
      "train loss:0.00040495331109723087\n",
      "train loss:0.004228099802528082\n",
      "train loss:0.003369814985673226\n",
      "train loss:0.0033067974975860255\n",
      "train loss:0.002684812045349816\n",
      "train loss:0.002055801330110185\n",
      "train loss:0.0002555177530886578\n",
      "train loss:0.001314530977493204\n",
      "train loss:0.0007046379729249159\n",
      "train loss:0.011520490824067748\n",
      "train loss:0.005098223690381332\n",
      "train loss:3.549158236651477e-05\n",
      "train loss:0.004572157101296136\n",
      "train loss:0.0041987446853669315\n",
      "train loss:0.0015121608662346804\n",
      "train loss:0.002076806152141902\n",
      "train loss:0.0001213464887303661\n",
      "train loss:0.00029693032562514923\n",
      "train loss:0.005288457058783804\n",
      "train loss:0.001970666251672132\n",
      "train loss:0.0005681456894695952\n",
      "train loss:0.0006787234629333972\n",
      "train loss:0.0023409907569316457\n",
      "train loss:0.0008218852082579391\n",
      "train loss:0.0019280209135081117\n",
      "train loss:0.00022006141344571247\n",
      "train loss:7.460119546708415e-05\n",
      "train loss:0.000862812380396688\n",
      "train loss:0.001254701228344826\n",
      "train loss:0.0013564811242448294\n",
      "train loss:0.000795928888692365\n",
      "train loss:0.0018712193407658545\n",
      "train loss:0.0007441359136186914\n",
      "train loss:0.0008623744255586947\n",
      "train loss:0.00022824470991529826\n",
      "train loss:0.006556503351472829\n",
      "train loss:0.008117882317979195\n",
      "train loss:0.0005185808881207957\n",
      "train loss:0.0014775439210991024\n",
      "train loss:0.000450759702489918\n",
      "train loss:0.00147075601130136\n",
      "train loss:0.003686145191053507\n",
      "train loss:0.0005716137071871041\n",
      "train loss:0.0036095309631907963\n",
      "train loss:0.0005658926687826072\n",
      "train loss:0.0022397450238660875\n",
      "train loss:0.0010091015786699304\n",
      "train loss:0.0006655043974166524\n",
      "train loss:0.0005114509443927095\n",
      "train loss:0.005270976574021843\n",
      "train loss:0.0017306802247768394\n",
      "train loss:0.005194011463325778\n",
      "train loss:0.0032103066788635413\n",
      "train loss:0.00047503912735155315\n",
      "train loss:0.0013096668094236671\n",
      "train loss:0.0049627704154204645\n",
      "train loss:0.0011687502787280169\n",
      "train loss:0.0022596080807735213\n",
      "train loss:0.0022013519603272837\n",
      "train loss:0.0007276517642934583\n",
      "train loss:0.005004354279180668\n",
      "train loss:0.03560039217846164\n",
      "train loss:0.0031728789917599438\n",
      "train loss:0.0006660474783761219\n",
      "train loss:0.0002579589790445569\n",
      "train loss:0.0023087183183594716\n",
      "train loss:0.012359408792969461\n",
      "train loss:0.00041956355548066144\n",
      "train loss:8.173950715453329e-05\n",
      "train loss:0.0010394314203202703\n",
      "train loss:0.0003524361666447939\n",
      "train loss:0.001060274147539195\n",
      "train loss:0.005184594170582926\n",
      "train loss:0.002675198650248413\n",
      "train loss:0.0002851714464849289\n",
      "train loss:0.00396880096359358\n",
      "train loss:0.004315232778239777\n",
      "train loss:0.045218599464704926\n",
      "train loss:0.0005431124296391886\n",
      "train loss:0.00013328403003419093\n",
      "train loss:0.0005002113616757579\n",
      "train loss:0.0007703720517466292\n",
      "train loss:0.006573220787243669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002482219037813479\n",
      "train loss:0.0002850338237749185\n",
      "train loss:0.000828324917267011\n",
      "train loss:0.0014430686532432681\n",
      "train loss:0.00024629016981193917\n",
      "train loss:0.003008884727873114\n",
      "train loss:7.562456627240065e-05\n",
      "train loss:0.0009759242996719792\n",
      "train loss:0.0017407286733830266\n",
      "train loss:0.0020744917807900506\n",
      "train loss:0.0021657281571146516\n",
      "train loss:0.004204434154585502\n",
      "train loss:0.004131518662453368\n",
      "train loss:0.016583964087023572\n",
      "train loss:0.009600943297937698\n",
      "train loss:0.0011397195779487448\n",
      "train loss:0.008692330162174338\n",
      "train loss:0.012388744179560795\n",
      "train loss:0.0016730519109756608\n",
      "train loss:0.008518555112496285\n",
      "train loss:0.00021000921525724566\n",
      "train loss:0.000861970833631248\n",
      "train loss:0.0004475854584431893\n",
      "train loss:0.0006607278637893839\n",
      "train loss:0.0006363036317550906\n",
      "train loss:0.0051513481942720265\n",
      "train loss:0.003134371539197026\n",
      "train loss:0.003790855851852097\n",
      "train loss:0.00019817916744503322\n",
      "train loss:0.0012135025810974668\n",
      "train loss:0.0035678719797273195\n",
      "train loss:0.0015730357720676502\n",
      "train loss:0.0006450552635983062\n",
      "train loss:0.0006798560892562512\n",
      "train loss:0.002551916620391696\n",
      "train loss:0.002717801769873475\n",
      "train loss:0.00013195318449275842\n",
      "train loss:0.0013843001271427863\n",
      "train loss:0.0005567123689836852\n",
      "train loss:0.0006305426035338373\n",
      "train loss:0.0002276269104325313\n",
      "train loss:0.00254957365118911\n",
      "train loss:0.0008769398008257274\n",
      "train loss:0.0005848307513435124\n",
      "train loss:0.0011394299506009115\n",
      "train loss:0.0001821858578517444\n",
      "train loss:0.0013653340932709506\n",
      "train loss:0.019360410843686223\n",
      "train loss:0.013960520091060635\n",
      "train loss:0.003343608982274169\n",
      "train loss:0.0002751108293138368\n",
      "train loss:0.00012503899818237183\n",
      "train loss:0.0021602317254187727\n",
      "train loss:0.00044763279850817446\n",
      "train loss:0.0028434577266050766\n",
      "train loss:0.004504968864913115\n",
      "train loss:0.001552958180931973\n",
      "train loss:0.001977602509124982\n",
      "train loss:0.0015338681865777067\n",
      "train loss:0.0003251088521735604\n",
      "train loss:0.00018989019352861513\n",
      "train loss:0.002972456698233034\n",
      "train loss:0.004711869116398737\n",
      "train loss:0.0007307063103355178\n",
      "train loss:0.003979333690776958\n",
      "train loss:0.006210920853859064\n",
      "train loss:0.0016327098870552762\n",
      "train loss:0.0016157806925575307\n",
      "train loss:0.0037214047464404843\n",
      "train loss:0.0008093210723487645\n",
      "train loss:0.010668920536222211\n",
      "train loss:0.010161375062901384\n",
      "train loss:0.001451295726324913\n",
      "train loss:0.002431860073616145\n",
      "train loss:0.00012514404337429446\n",
      "train loss:0.0006706112246354166\n",
      "train loss:0.0008829594926524521\n",
      "train loss:0.00048352693259448825\n",
      "train loss:0.002283530857230039\n",
      "train loss:0.00444228736263885\n",
      "train loss:0.00042212407246545834\n",
      "train loss:0.0010825294108543384\n",
      "train loss:0.0008390282769588979\n",
      "train loss:0.002553410009208108\n",
      "train loss:0.0014963700400712704\n",
      "train loss:0.00014644419648793605\n",
      "train loss:0.002928308556499649\n",
      "train loss:0.0008592705260754556\n",
      "train loss:0.00016216796842060663\n",
      "train loss:0.00015339421783285546\n",
      "train loss:0.0018011812293643368\n",
      "train loss:0.003128660703485283\n",
      "train loss:0.0021284556024468147\n",
      "train loss:0.0013993364676868358\n",
      "train loss:0.0013785189066913683\n",
      "train loss:0.0005911727209303338\n",
      "train loss:0.0039055018853393292\n",
      "train loss:0.00019452419869451357\n",
      "train loss:0.0006856820745930738\n",
      "train loss:0.004099507125487761\n",
      "train loss:9.35288516891432e-05\n",
      "train loss:0.001930714378559765\n",
      "train loss:0.00019872393395352285\n",
      "train loss:0.000457339152682223\n",
      "train loss:0.0015047304967668994\n",
      "train loss:0.0005943514742058169\n",
      "train loss:0.009805121359560447\n",
      "train loss:0.002569958068597914\n",
      "train loss:0.0008797292351701347\n",
      "train loss:0.00245970951281778\n",
      "train loss:0.0010588179636646783\n",
      "train loss:0.00038911916749956267\n",
      "train loss:0.007784237802576538\n",
      "train loss:0.003246370338572662\n",
      "train loss:0.00637311011339822\n",
      "train loss:0.0022923251298058085\n",
      "train loss:0.0002337719127277212\n",
      "train loss:0.002105497181140482\n",
      "train loss:0.0003116507459105603\n",
      "train loss:0.0007289901501689848\n",
      "train loss:0.00108086416165133\n",
      "train loss:0.0017043970757419963\n",
      "train loss:7.827721321027543e-05\n",
      "train loss:0.005950361098797038\n",
      "train loss:0.0026858320581992757\n",
      "train loss:0.00040840630215671273\n",
      "train loss:0.010725664380930677\n",
      "train loss:0.005836405786747108\n",
      "train loss:0.0006250002392747889\n",
      "train loss:0.0031121994765204953\n",
      "train loss:0.0015278654496869778\n",
      "train loss:0.0012716006674932173\n",
      "train loss:0.005116935486903256\n",
      "train loss:0.006001965187256391\n",
      "train loss:0.0037941610473203676\n",
      "train loss:0.002046009107696467\n",
      "train loss:0.0017456714735399504\n",
      "train loss:0.0036267946731311732\n",
      "train loss:0.0007489120497635432\n",
      "train loss:0.007982495291925617\n",
      "train loss:0.00016696966514390864\n",
      "train loss:0.0051074213744986205\n",
      "train loss:0.0035861690245568793\n",
      "train loss:0.005163441867444229\n",
      "train loss:0.00123131830910186\n",
      "train loss:0.00029010370279072167\n",
      "train loss:0.000266803804072955\n",
      "train loss:0.007449210008166012\n",
      "train loss:0.002001334858263768\n",
      "train loss:0.0003629480836711871\n",
      "train loss:0.0010806219452176508\n",
      "train loss:0.005665069223458307\n",
      "train loss:0.003626148423181859\n",
      "train loss:0.0007301932814492593\n",
      "train loss:0.0016476589401223376\n",
      "train loss:0.0009703388573103207\n",
      "train loss:0.003645820645776787\n",
      "train loss:0.0006388518756245002\n",
      "train loss:0.007608633631596326\n",
      "train loss:0.009561907782822081\n",
      "train loss:0.00027221259148558016\n",
      "train loss:0.0050301199883177675\n",
      "train loss:0.0014780459236686287\n",
      "train loss:0.0011921289131445712\n",
      "train loss:0.004633451793539652\n",
      "train loss:0.0007324754682798358\n",
      "train loss:0.0017236186349755727\n",
      "train loss:0.0010679185776646099\n",
      "train loss:0.03581619860831105\n",
      "train loss:0.004025365238061498\n",
      "train loss:0.0007864404801540457\n",
      "train loss:0.0012567428125609206\n",
      "train loss:0.003618502855682395\n",
      "train loss:0.0032460481754469995\n",
      "train loss:0.013271241991042912\n",
      "train loss:0.0027254274913498825\n",
      "train loss:0.0004431223649969035\n",
      "train loss:0.004734111318585795\n",
      "train loss:0.00011196185827217728\n",
      "train loss:5.164744316803875e-05\n",
      "train loss:0.0007531277958489427\n",
      "train loss:0.00018689688477027848\n",
      "train loss:0.00600008901834403\n",
      "train loss:0.0006290462907836903\n",
      "train loss:0.0005504571215532903\n",
      "train loss:0.0017318428387702249\n",
      "train loss:0.003926231798084604\n",
      "train loss:0.0007107936942174896\n",
      "train loss:0.006193242552171289\n",
      "train loss:0.004971897444896151\n",
      "train loss:0.003371399227441\n",
      "train loss:0.030385552054517748\n",
      "train loss:0.000976606191247859\n",
      "train loss:0.004523875681037466\n",
      "train loss:0.0003033519812385401\n",
      "train loss:0.0006641291957574019\n",
      "train loss:0.0039675722643210485\n",
      "train loss:0.0013354546522364426\n",
      "train loss:0.00044765852783576325\n",
      "train loss:0.0033461964441835767\n",
      "train loss:0.0038523050036272277\n",
      "train loss:0.005598911717790767\n",
      "train loss:3.757708645960016e-05\n",
      "train loss:0.0012649707903780367\n",
      "train loss:0.0006859094893590343\n",
      "train loss:0.004175249726325164\n",
      "train loss:0.0020109313843019185\n",
      "train loss:0.00034853151538361514\n",
      "train loss:0.00015604810821782218\n",
      "train loss:7.738025874940423e-05\n",
      "train loss:0.002443321553261851\n",
      "train loss:0.0001003993009997904\n",
      "train loss:0.0008757664032264883\n",
      "train loss:0.001052944071118475\n",
      "train loss:0.001482224342909249\n",
      "train loss:0.0014384951069648158\n",
      "train loss:0.00589569112556047\n",
      "train loss:0.00032692543437467777\n",
      "train loss:0.003551610667705185\n",
      "train loss:0.004400182452057353\n",
      "train loss:0.000648315531824973\n",
      "train loss:0.0013019421725500786\n",
      "train loss:0.0012706990552177094\n",
      "train loss:0.0008279330903938309\n",
      "train loss:0.0018620141934898582\n",
      "train loss:0.012127840618191802\n",
      "train loss:0.003485992210616762\n",
      "train loss:0.00026301316397186537\n",
      "train loss:4.8797931118302605e-05\n",
      "train loss:0.0014322418766162047\n",
      "train loss:0.003017533026751487\n",
      "train loss:6.684714992007796e-05\n",
      "train loss:0.0061315556260488095\n",
      "train loss:0.00014004889017911273\n",
      "train loss:0.0005608865525357901\n",
      "train loss:0.007127553681747532\n",
      "train loss:0.0006948950031104333\n",
      "train loss:0.0028652774059565516\n",
      "train loss:0.0102135718471053\n",
      "train loss:0.0027438115606510157\n",
      "train loss:0.0015398983224822358\n",
      "train loss:0.002558339423098246\n",
      "train loss:0.0007839826871347846\n",
      "train loss:0.0027455313333980096\n",
      "train loss:0.00033013898030968917\n",
      "train loss:0.005918594777158643\n",
      "train loss:0.00037929587276311284\n",
      "train loss:0.01946101927266361\n",
      "train loss:0.001885882973644375\n",
      "train loss:0.008053743821657381\n",
      "train loss:0.005959735700041574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:7.608879486532897e-05\n",
      "train loss:0.000729764891382694\n",
      "train loss:0.002340712914328158\n",
      "train loss:0.000685910396146786\n",
      "train loss:0.0002399293206826907\n",
      "train loss:0.00037095306969153687\n",
      "train loss:0.005555663667038594\n",
      "train loss:0.000573978692996084\n",
      "train loss:0.0008209899846271766\n",
      "train loss:0.0010271093456611002\n",
      "train loss:0.0017491106420354108\n",
      "train loss:5.221191031916369e-05\n",
      "train loss:0.0007538285044220467\n",
      "train loss:0.0003207054944829172\n",
      "train loss:0.0009150093826693202\n",
      "train loss:0.0014113940918110007\n",
      "train loss:0.0011790715463609234\n",
      "train loss:4.528189710738222e-05\n",
      "train loss:0.0028514405773845397\n",
      "train loss:0.008320175069127177\n",
      "train loss:0.0056249530254498074\n",
      "train loss:0.0009220307030470696\n",
      "train loss:0.0020215932031265966\n",
      "train loss:0.00633892382209969\n",
      "train loss:0.005649966357161309\n",
      "train loss:0.001010765852452895\n",
      "train loss:0.008398456142299358\n",
      "train loss:0.008387168306438052\n",
      "train loss:0.000314376371507325\n",
      "train loss:0.0017455860850748822\n",
      "train loss:0.000914711963700269\n",
      "train loss:0.0005307959496063258\n",
      "train loss:0.0008988516231765917\n",
      "train loss:0.0021738551711576255\n",
      "train loss:0.0007943782421556975\n",
      "train loss:0.0007691987110593764\n",
      "train loss:0.00019547744617332428\n",
      "train loss:0.004055262586862438\n",
      "train loss:0.000507522425533462\n",
      "train loss:0.0014578329069380158\n",
      "train loss:0.0010970907679050687\n",
      "train loss:0.0004553798788948101\n",
      "train loss:0.00339334007081334\n",
      "train loss:0.005169868847765655\n",
      "train loss:0.0003259137996558117\n",
      "train loss:0.0010919282517527556\n",
      "train loss:0.0007823224822043984\n",
      "train loss:0.002990923076176828\n",
      "train loss:0.00088681634831874\n",
      "train loss:0.00309844768313273\n",
      "train loss:0.000512945714861366\n",
      "train loss:0.0027433515524741044\n",
      "train loss:0.0016555703080616227\n",
      "train loss:0.0049302761313944335\n",
      "train loss:0.0021815062053199535\n",
      "train loss:0.002332366880578258\n",
      "train loss:0.0009944948980314327\n",
      "train loss:0.0021504816811494746\n",
      "train loss:3.73863351302283e-05\n",
      "train loss:0.00010146138677840603\n",
      "train loss:0.0005775692212919683\n",
      "train loss:0.0016653260736523173\n",
      "train loss:0.00034010512591329937\n",
      "train loss:0.00040124583235274776\n",
      "train loss:0.00022020800161169407\n",
      "train loss:4.1323649396940306e-05\n",
      "train loss:0.001173128985601843\n",
      "train loss:0.0006859259457023106\n",
      "train loss:0.0005510521702862609\n",
      "train loss:0.00012388687555676397\n",
      "train loss:0.0008750391875863274\n",
      "train loss:0.004095289134355723\n",
      "train loss:0.002039697269303025\n",
      "train loss:0.0024817404827042764\n",
      "train loss:0.0030221110890243964\n",
      "train loss:0.000859195628480467\n",
      "train loss:0.0022970552129769704\n",
      "train loss:0.0018059323633156641\n",
      "train loss:0.0020375748971498573\n",
      "train loss:0.00014232038310518772\n",
      "train loss:0.0022947841536651217\n",
      "train loss:0.00103537150550601\n",
      "train loss:0.013292109282007476\n",
      "train loss:0.002676120147830379\n",
      "train loss:0.00014495531817589012\n",
      "train loss:0.0007499666271850356\n",
      "train loss:0.003265992293027231\n",
      "train loss:0.0024864117369482663\n",
      "train loss:0.0005002588374542435\n",
      "train loss:0.0011426899854270346\n",
      "train loss:5.1958878495401254e-05\n",
      "train loss:0.004874840261404042\n",
      "train loss:0.00031767458044753996\n",
      "train loss:0.0007169373394047307\n",
      "train loss:0.000772867489492068\n",
      "train loss:0.0005802707052155783\n",
      "train loss:0.007627952947608532\n",
      "train loss:0.0020838809198992538\n",
      "train loss:9.105493472621695e-05\n",
      "train loss:0.0029141095193130372\n",
      "train loss:0.0068441830109986475\n",
      "train loss:0.0006388418987919157\n",
      "train loss:0.00033950973837440274\n",
      "train loss:0.0036036328025194193\n",
      "train loss:0.0016023748206190269\n",
      "train loss:0.0023053561659902807\n",
      "train loss:0.0033962526292307537\n",
      "train loss:0.00028590103064536436\n",
      "train loss:0.00012525105208797022\n",
      "train loss:0.0018540008918360954\n",
      "train loss:9.122891879117391e-05\n",
      "train loss:0.002566117086186221\n",
      "train loss:0.006792126578830484\n",
      "train loss:0.002829854210445644\n",
      "train loss:0.00041458145909459526\n",
      "train loss:0.001543030164681678\n",
      "train loss:0.00010525490194611514\n",
      "train loss:0.0010457471013522062\n",
      "train loss:0.0005141314189209195\n",
      "train loss:0.0001747382070904701\n",
      "train loss:0.0020996130928098225\n",
      "train loss:8.798701436772719e-05\n",
      "train loss:0.0004981864317811733\n",
      "train loss:0.002502737097307119\n",
      "train loss:0.003187731763569554\n",
      "train loss:0.0011171243453251469\n",
      "train loss:0.0022227622778185703\n",
      "train loss:0.009681020064680728\n",
      "train loss:0.016462058663047518\n",
      "train loss:0.0007067758105270728\n",
      "train loss:0.00043749750391962154\n",
      "train loss:0.005804018617244765\n",
      "train loss:0.016020869613924987\n",
      "train loss:0.0031465330249072364\n",
      "train loss:0.00048468680220241665\n",
      "train loss:0.0015831794232432075\n",
      "train loss:0.0014685623649105522\n",
      "train loss:0.0016726185221405932\n",
      "train loss:0.0020471194616613285\n",
      "train loss:0.00031109236870088705\n",
      "train loss:5.2549048140489866e-05\n",
      "train loss:0.00505492519569869\n",
      "train loss:0.014113084319285419\n",
      "train loss:0.004455570980636377\n",
      "train loss:0.0015658772444366142\n",
      "train loss:0.000855245983655481\n",
      "train loss:0.00641356316801185\n",
      "train loss:0.000930994050084974\n",
      "train loss:0.001585790625767592\n",
      "train loss:0.0005041130644072155\n",
      "train loss:0.0010071490121110963\n",
      "train loss:0.0009509054527134106\n",
      "train loss:0.005792818981358718\n",
      "train loss:0.0033146038719188277\n",
      "train loss:0.003869908711311903\n",
      "train loss:0.002059743962883321\n",
      "train loss:0.0008856043277388397\n",
      "train loss:0.0034926952496070625\n",
      "train loss:0.002150248817993143\n",
      "train loss:0.0009146902342330514\n",
      "train loss:0.0014084634797714812\n",
      "train loss:0.004651384239720277\n",
      "train loss:0.0006693349827856339\n",
      "train loss:0.0006338746020994809\n",
      "train loss:0.0005151066833839976\n",
      "train loss:0.0020308149756020793\n",
      "train loss:0.0008808028816850896\n",
      "train loss:0.0010349908927632257\n",
      "train loss:0.0006535570211053141\n",
      "train loss:0.0016863227087732247\n",
      "train loss:0.00014327207747424694\n",
      "train loss:0.003463515634135403\n",
      "train loss:0.001859063218163344\n",
      "=== epoch:18, train acc:0.996, test acc:0.982 ===\n",
      "train loss:0.0013119824918874634\n",
      "train loss:0.0004130822879082244\n",
      "train loss:0.004286155915631231\n",
      "train loss:6.0694863698527695e-05\n",
      "train loss:0.011489350566497823\n",
      "train loss:0.0003898483217696233\n",
      "train loss:0.0011870510636890245\n",
      "train loss:0.0012618336054982743\n",
      "train loss:3.090664950198034e-05\n",
      "train loss:0.0020046488426417085\n",
      "train loss:0.0005712619856974821\n",
      "train loss:0.0004755356382195451\n",
      "train loss:0.0010223701676441252\n",
      "train loss:0.002140395707171717\n",
      "train loss:0.0002829253725585944\n",
      "train loss:0.0002893479878659282\n",
      "train loss:0.00047240190745285825\n",
      "train loss:0.002930633772111566\n",
      "train loss:0.00012275846276606404\n",
      "train loss:0.0002336868405814204\n",
      "train loss:0.0009239968239471049\n",
      "train loss:0.0002547194255567757\n",
      "train loss:0.0008984255577534127\n",
      "train loss:0.001030533113776925\n",
      "train loss:0.0015023753328441073\n",
      "train loss:0.00022143040527471851\n",
      "train loss:0.0006266601799856585\n",
      "train loss:0.00798217779471158\n",
      "train loss:0.003103357330954198\n",
      "train loss:0.004922377790439861\n",
      "train loss:0.003525582581815649\n",
      "train loss:0.0002873483501284865\n",
      "train loss:0.0010724987804987746\n",
      "train loss:0.0006561961521871429\n",
      "train loss:0.0005435604077412095\n",
      "train loss:7.495977971984536e-05\n",
      "train loss:0.0002567800849497207\n",
      "train loss:0.0019768852926307177\n",
      "train loss:0.0006078098437778633\n",
      "train loss:0.0004811332261203594\n",
      "train loss:0.0008247273322680022\n",
      "train loss:0.002032090568769901\n",
      "train loss:2.1985640929496898e-05\n",
      "train loss:0.0003352705405851302\n",
      "train loss:0.0005484362522340493\n",
      "train loss:0.0017873212450781033\n",
      "train loss:0.0014788571388483429\n",
      "train loss:0.0013971335183368852\n",
      "train loss:0.0002724113128316056\n",
      "train loss:0.0007677223677359101\n",
      "train loss:0.0017957089914717164\n",
      "train loss:0.006423300219774247\n",
      "train loss:0.00013461306701793488\n",
      "train loss:0.005197291938601035\n",
      "train loss:0.0005655702243637217\n",
      "train loss:0.00045137084806058187\n",
      "train loss:0.0010243886553703556\n",
      "train loss:0.001403493871076621\n",
      "train loss:0.002024974489897723\n",
      "train loss:0.002141597760847708\n",
      "train loss:0.0023818588105087982\n",
      "train loss:0.0016316393979665938\n",
      "train loss:0.002320412514061822\n",
      "train loss:0.002925787834043329\n",
      "train loss:0.0013762575156208183\n",
      "train loss:0.0005166248807802202\n",
      "train loss:0.000922665943025049\n",
      "train loss:0.001164388621535683\n",
      "train loss:0.001508796708364283\n",
      "train loss:0.001957764528430983\n",
      "train loss:0.00013157120024716353\n",
      "train loss:0.0007403821158690506\n",
      "train loss:0.00018734907912927142\n",
      "train loss:0.0005278633761005253\n",
      "train loss:0.00291691012015684\n",
      "train loss:0.00426204684593788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:3.730138393846152e-05\n",
      "train loss:0.00027240657226641307\n",
      "train loss:2.8292642653195477e-05\n",
      "train loss:0.0016745468099483587\n",
      "train loss:0.0002453114970831862\n",
      "train loss:0.00028247739944547984\n",
      "train loss:0.0016031822647870583\n",
      "train loss:0.009391613621498363\n",
      "train loss:0.0008013188606054096\n",
      "train loss:0.002289098537928963\n",
      "train loss:0.0003399835746500057\n",
      "train loss:0.0036179842231731717\n",
      "train loss:0.0020051549726893773\n",
      "train loss:0.0005074711199292979\n",
      "train loss:0.002520281687661355\n",
      "train loss:0.003327043072414429\n",
      "train loss:0.0019270825629296045\n",
      "train loss:0.016211046130737136\n",
      "train loss:0.00047673962425081435\n",
      "train loss:0.0005860015683535726\n",
      "train loss:0.00011704838434884476\n",
      "train loss:0.0008651115695052323\n",
      "train loss:0.008509333738986049\n",
      "train loss:0.021696852684105067\n",
      "train loss:0.0004632033413354101\n",
      "train loss:0.0011338501407184612\n",
      "train loss:0.00027843777942954714\n",
      "train loss:0.0020371384891182676\n",
      "train loss:0.0012705218920920855\n",
      "train loss:0.017646515335021585\n",
      "train loss:0.0018833011589245662\n",
      "train loss:0.054501814284076265\n",
      "train loss:0.0007825729878250692\n",
      "train loss:0.00023927487585009003\n",
      "train loss:0.003482193622903661\n",
      "train loss:0.0016023948285486958\n",
      "train loss:0.010000426907973765\n",
      "train loss:0.014838661117972034\n",
      "train loss:0.00035404833868937986\n",
      "train loss:0.00023550711285720574\n",
      "train loss:0.0012730383535165275\n",
      "train loss:0.0014233089878304664\n",
      "train loss:0.0008931557649828907\n",
      "train loss:0.002525539994472351\n",
      "train loss:0.000889659140977394\n",
      "train loss:0.0021115227451030776\n",
      "train loss:0.002456949313921168\n",
      "train loss:0.0008341838753933323\n",
      "train loss:0.0031249384148120947\n",
      "train loss:0.0032501696200708673\n",
      "train loss:0.008066267666216412\n",
      "train loss:0.011479715204330476\n",
      "train loss:0.000997444273301585\n",
      "train loss:0.0015339120444331424\n",
      "train loss:4.6021996910028864e-05\n",
      "train loss:0.000176671519412998\n",
      "train loss:0.00029509196754899203\n",
      "train loss:0.0024997632704502155\n",
      "train loss:0.00018648920942939448\n",
      "train loss:0.0016900166287933819\n",
      "train loss:0.00011493449156994276\n",
      "train loss:5.943222731782498e-05\n",
      "train loss:0.0014094131472046259\n",
      "train loss:0.001937929904856622\n",
      "train loss:0.0006203334082739849\n",
      "train loss:0.0017108345869580176\n",
      "train loss:0.0024504927312239593\n",
      "train loss:0.00023054056323394345\n",
      "train loss:0.0019237687740572918\n",
      "train loss:0.0012460264670047388\n",
      "train loss:0.00034792490961309047\n",
      "train loss:0.0022659415288105045\n",
      "train loss:0.002585343440377226\n",
      "train loss:0.0028070462043128506\n",
      "train loss:0.00023915698067762447\n",
      "train loss:0.003098589171652903\n",
      "train loss:0.002282903665477402\n",
      "train loss:0.0011425172511843127\n",
      "train loss:0.003104241171424404\n",
      "train loss:0.00024905935610174075\n",
      "train loss:0.00014964201154958913\n",
      "train loss:0.0016032272976276426\n",
      "train loss:0.0027435293673685863\n",
      "train loss:0.0005673747392860705\n",
      "train loss:0.0004020296448229549\n",
      "train loss:6.168257748683134e-05\n",
      "train loss:0.002675789025870149\n",
      "train loss:0.0010566225765461477\n",
      "train loss:0.0074110417223678775\n",
      "train loss:0.011415769751350278\n",
      "train loss:0.0038272869668016973\n",
      "train loss:8.362567501811545e-05\n",
      "train loss:0.00026116947157631723\n",
      "train loss:0.004072151608853102\n",
      "train loss:0.00033815309803113605\n",
      "train loss:0.0010913965117328593\n",
      "train loss:0.003240960816360288\n",
      "train loss:0.002314733816040767\n",
      "train loss:0.0012040663756049924\n",
      "train loss:0.0006593289208352149\n",
      "train loss:0.007659985840180047\n",
      "train loss:0.004418285684102585\n",
      "train loss:0.0006206867361721816\n",
      "train loss:0.0010916308649227113\n",
      "train loss:0.0019682270911725633\n",
      "train loss:0.004503807573710764\n",
      "train loss:0.003397368857229684\n",
      "train loss:0.003178583676045259\n",
      "train loss:0.001463745605769678\n",
      "train loss:0.0019207306594266646\n",
      "train loss:0.0009699710036810739\n",
      "train loss:0.0021409602826485572\n",
      "train loss:0.004849635779937996\n",
      "train loss:0.00013500461932255836\n",
      "train loss:0.0005201183506176365\n",
      "train loss:0.007770066696636147\n",
      "train loss:0.0017423321834730038\n",
      "train loss:0.0005666498877708773\n",
      "train loss:0.000783690371147285\n",
      "train loss:0.0009019725985391541\n",
      "train loss:0.0015050607765837746\n",
      "train loss:0.0064876630981356605\n",
      "train loss:0.001405178600069708\n",
      "train loss:0.0017173780184979138\n",
      "train loss:0.0005732324834591084\n",
      "train loss:0.0007747712542966129\n",
      "train loss:0.0012082129224476581\n",
      "train loss:0.0034903277455732647\n",
      "train loss:0.00034234297419532823\n",
      "train loss:0.0005913890484419738\n",
      "train loss:0.0042836752922706875\n",
      "train loss:0.0007945628474089106\n",
      "train loss:0.0017114368108258518\n",
      "train loss:0.0017651678420026243\n",
      "train loss:0.001586597737310177\n",
      "train loss:0.0007491233030314801\n",
      "train loss:0.000332509791183719\n",
      "train loss:0.0001359181895406793\n",
      "train loss:0.001108043772380212\n",
      "train loss:0.0009947303481597529\n",
      "train loss:0.000903094362868582\n",
      "train loss:0.008955161510020149\n",
      "train loss:0.00045404446542842195\n",
      "train loss:0.0006131954967911311\n",
      "train loss:0.00034014702611686985\n",
      "train loss:0.0014292758646749506\n",
      "train loss:0.003780043447008132\n",
      "train loss:0.00024200737367528332\n",
      "train loss:0.0033319538164850106\n",
      "train loss:0.0013045056748316219\n",
      "train loss:0.0011399126333362676\n",
      "train loss:0.0011388034226401421\n",
      "train loss:0.00010432022779489467\n",
      "train loss:0.004962872073738232\n",
      "train loss:0.00040377143534945937\n",
      "train loss:0.001129784699544018\n",
      "train loss:0.011662944210842028\n",
      "train loss:0.0001882575263319907\n",
      "train loss:0.00039814577397535937\n",
      "train loss:0.023099157426066306\n",
      "train loss:0.0012566207045364695\n",
      "train loss:0.0014203166368468938\n",
      "train loss:0.001346983158347106\n",
      "train loss:7.135428964579416e-05\n",
      "train loss:5.721666114270913e-05\n",
      "train loss:0.0013196667496869167\n",
      "train loss:1.3383688274181063e-05\n",
      "train loss:0.0013320219058938008\n",
      "train loss:0.000674713933214405\n",
      "train loss:0.0002570304477445357\n",
      "train loss:0.0027261367631854438\n",
      "train loss:5.319806526284169e-05\n",
      "train loss:0.0012534267456088537\n",
      "train loss:0.004393352120735485\n",
      "train loss:0.002593056966021986\n",
      "train loss:0.001161339017512138\n",
      "train loss:0.0004028955100712504\n",
      "train loss:0.0002942161792952877\n",
      "train loss:0.0005909003980479021\n",
      "train loss:0.0008615427118012006\n",
      "train loss:0.00040896839394402454\n",
      "train loss:0.0001816068509697258\n",
      "train loss:0.002425301650097349\n",
      "train loss:8.098149616709109e-05\n",
      "train loss:0.0022496862091301636\n",
      "train loss:0.0010745888897555956\n",
      "train loss:0.0008691866567310459\n",
      "train loss:0.0008553483577729695\n",
      "train loss:0.00013590907862711085\n",
      "train loss:0.00013568215306935752\n",
      "train loss:0.00019476461465082635\n",
      "train loss:0.0002624850464836646\n",
      "train loss:0.0006933109811348391\n",
      "train loss:0.000325110580182223\n",
      "train loss:0.002490569168565561\n",
      "train loss:0.000874722694603505\n",
      "train loss:0.0001958087544729541\n",
      "train loss:0.0014907738992573235\n",
      "train loss:0.0008501985443011154\n",
      "train loss:0.0032166292356459237\n",
      "train loss:8.511658215901319e-05\n",
      "train loss:0.0003410467342718761\n",
      "train loss:0.0018021425155431002\n",
      "train loss:0.0002816183187644873\n",
      "train loss:0.003354316690776494\n",
      "train loss:0.0017264121699738528\n",
      "train loss:0.0002782741302416111\n",
      "train loss:0.0017729586070170248\n",
      "train loss:0.004425659914440657\n",
      "train loss:0.0018736982401902464\n",
      "train loss:0.00011893178791931314\n",
      "train loss:0.00016269488545732507\n",
      "train loss:0.0013715732154779274\n",
      "train loss:0.0010937957494452251\n",
      "train loss:0.0009297508033539339\n",
      "train loss:0.00029949292587861406\n",
      "train loss:0.0007474653285732872\n",
      "train loss:0.00023891291419110582\n",
      "train loss:0.00011739925174600969\n",
      "train loss:0.00027308877791360164\n",
      "train loss:0.0030423629128633954\n",
      "train loss:0.007484102033759851\n",
      "train loss:0.002065615332643982\n",
      "train loss:0.0002794733607496955\n",
      "train loss:9.1887738550669e-05\n",
      "train loss:0.0012204791864150611\n",
      "train loss:0.003409884135862501\n",
      "train loss:0.0006336121076766714\n",
      "train loss:0.0006102504689754941\n",
      "train loss:0.00014434218602226782\n",
      "train loss:0.00010867917365860049\n",
      "train loss:0.0002795326457162314\n",
      "train loss:0.001865202546094989\n",
      "train loss:0.00022027605939287844\n",
      "train loss:0.0006364844068715778\n",
      "train loss:0.0008020242784461503\n",
      "train loss:0.0001252323879302088\n",
      "train loss:0.00048626878955075484\n",
      "train loss:0.0005039550952826077\n",
      "train loss:0.0019259250911723477\n",
      "train loss:0.00037888266891268553\n",
      "train loss:0.0022633651830300918\n",
      "train loss:0.0012305896052148416\n",
      "train loss:0.0009820808120433646\n",
      "train loss:0.0006236619387378069\n",
      "train loss:0.000140719692641501\n",
      "train loss:0.005138418389462713\n",
      "train loss:0.000189182246447967\n",
      "train loss:0.00036585404014698874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00029059164739701207\n",
      "train loss:0.00011420145871835532\n",
      "train loss:0.00048193541942160407\n",
      "train loss:0.000912017450674608\n",
      "train loss:0.0014637472823123407\n",
      "train loss:0.00015545388651960743\n",
      "train loss:0.00019057816401358473\n",
      "train loss:0.0005596989701221115\n",
      "train loss:6.606158656206085e-05\n",
      "train loss:0.0021543371115187904\n",
      "train loss:0.0002384969756174378\n",
      "train loss:0.0005028172188086546\n",
      "train loss:4.707659275677042e-06\n",
      "train loss:6.659663705818997e-05\n",
      "train loss:0.002527500833701275\n",
      "train loss:0.00024383853471554795\n",
      "train loss:0.0009797649913698885\n",
      "train loss:6.076488418843732e-05\n",
      "train loss:0.0010581324992363478\n",
      "train loss:0.0006172065980229164\n",
      "train loss:0.0008938479754712256\n",
      "train loss:0.0015049670015857698\n",
      "train loss:0.0005157684812162755\n",
      "train loss:0.00030493324537648564\n",
      "train loss:0.0015492165841313225\n",
      "train loss:4.878531770731604e-05\n",
      "train loss:0.00023510098855783853\n",
      "train loss:0.00027568330864774125\n",
      "train loss:0.0004777843787348276\n",
      "train loss:0.0007490146961706104\n",
      "train loss:0.00020301642946117505\n",
      "train loss:0.001335540902587991\n",
      "train loss:0.0014263504281998391\n",
      "train loss:0.0004369784206042321\n",
      "train loss:0.0005275900384799655\n",
      "train loss:0.00019627610837162743\n",
      "train loss:0.0001695304518585866\n",
      "train loss:0.00254829556724393\n",
      "train loss:5.069197601601565e-05\n",
      "train loss:3.481793008311068e-05\n",
      "train loss:0.0015116969299770063\n",
      "train loss:2.7997260233734423e-05\n",
      "train loss:0.0005881354206353888\n",
      "train loss:0.001104350804144654\n",
      "train loss:0.00027648532535599814\n",
      "train loss:7.289185433536709e-05\n",
      "train loss:0.000759618778031733\n",
      "train loss:0.0011204060686299698\n",
      "train loss:0.00042253762205837867\n",
      "train loss:0.0010954945348725443\n",
      "train loss:0.0019769375622701287\n",
      "train loss:0.0006622860510521128\n",
      "train loss:1.7843308130453226e-05\n",
      "train loss:0.001328993409968506\n",
      "train loss:0.0005345963753603546\n",
      "train loss:0.0007918047906670765\n",
      "train loss:0.0028057509364136325\n",
      "train loss:3.409274129637722e-05\n",
      "train loss:0.0006653167437997924\n",
      "train loss:0.0006222660629780074\n",
      "train loss:0.0001451730669430999\n",
      "train loss:1.6665484177562895e-05\n",
      "train loss:0.00034347448000670926\n",
      "train loss:0.0002251703041793565\n",
      "train loss:1.1095889282343081e-05\n",
      "train loss:0.0005220245247738878\n",
      "train loss:7.650970898538256e-05\n",
      "train loss:0.0008269388205977632\n",
      "train loss:0.0019264287119175397\n",
      "train loss:0.00023949926042566647\n",
      "train loss:0.001620849288738609\n",
      "train loss:0.004070579009907133\n",
      "train loss:0.0004535991402798079\n",
      "train loss:0.0002998922705508481\n",
      "train loss:0.000344715360285106\n",
      "train loss:0.0034685463985942877\n",
      "train loss:0.00019179486492731747\n",
      "train loss:0.0017366751707125416\n",
      "train loss:8.544640963830676e-05\n",
      "train loss:0.000193971334588676\n",
      "train loss:0.0014301735953023253\n",
      "train loss:0.00014097422000677079\n",
      "train loss:0.00036205483426847586\n",
      "train loss:0.001269553206703987\n",
      "train loss:0.0001942393273694495\n",
      "train loss:0.00011146908010429543\n",
      "train loss:0.00033531124074401357\n",
      "train loss:0.0013219100952742014\n",
      "train loss:0.00013321030293270223\n",
      "train loss:0.0003713439782962063\n",
      "train loss:0.0035985788026379716\n",
      "train loss:1.4782937665154755e-05\n",
      "train loss:0.0032757934682292105\n",
      "train loss:0.006604335673710634\n",
      "train loss:0.000176455684501368\n",
      "train loss:8.709812583463088e-05\n",
      "train loss:0.002323005171941466\n",
      "train loss:0.000294329464330278\n",
      "train loss:0.0016607783438066276\n",
      "train loss:9.218828490541559e-05\n",
      "train loss:0.0012171583584841628\n",
      "train loss:0.0002220116140880132\n",
      "train loss:0.004301465245881615\n",
      "train loss:0.0014937169134988796\n",
      "train loss:0.003614728129120298\n",
      "train loss:0.0005632249985878513\n",
      "train loss:0.008790338467175675\n",
      "train loss:0.0014006258805532557\n",
      "train loss:7.139091938864424e-05\n",
      "train loss:9.931523570208267e-05\n",
      "train loss:0.0002819714464485959\n",
      "train loss:0.005173420010035404\n",
      "train loss:0.0018204353288628805\n",
      "train loss:0.004738213941388931\n",
      "train loss:0.0002181943816623946\n",
      "train loss:0.002609288381691296\n",
      "train loss:0.0006260389960656798\n",
      "train loss:8.715850541523726e-05\n",
      "train loss:0.0006657960610243038\n",
      "train loss:4.635764712283802e-05\n",
      "train loss:0.003523008651548064\n",
      "train loss:0.000495716714413319\n",
      "train loss:0.0020362314116827165\n",
      "train loss:0.00043073816540230596\n",
      "train loss:0.0013569380734521194\n",
      "train loss:0.0011047787881376932\n",
      "train loss:0.0003051256789621785\n",
      "train loss:0.0005548486225720144\n",
      "train loss:0.0022098333367898946\n",
      "train loss:0.010240301135505604\n",
      "train loss:0.0008168883280898909\n",
      "train loss:0.0026077123969665667\n",
      "train loss:0.00013812807402585606\n",
      "train loss:4.599307323475896e-05\n",
      "train loss:1.6865109289483918e-05\n",
      "train loss:0.00020650673931237637\n",
      "train loss:0.00024403085421425768\n",
      "train loss:5.921735443374111e-05\n",
      "train loss:0.0003182532033961337\n",
      "train loss:0.00022407326713093096\n",
      "train loss:8.873992231310534e-06\n",
      "train loss:0.00015253678616053507\n",
      "train loss:0.0036478805271947766\n",
      "train loss:0.0008753367342803429\n",
      "train loss:0.0006831040607247401\n",
      "train loss:0.0009021993990728628\n",
      "train loss:0.0001349098446255904\n",
      "train loss:0.0013882134272366771\n",
      "train loss:0.02798807986510626\n",
      "train loss:0.0016736023077470292\n",
      "train loss:0.0007160384094787892\n",
      "train loss:0.00129451905750189\n",
      "train loss:0.00037435292535422006\n",
      "train loss:0.00017727592761207088\n",
      "train loss:0.00019006695836515166\n",
      "train loss:0.000962018193756255\n",
      "train loss:9.12268277343935e-05\n",
      "train loss:0.0024527324518344015\n",
      "train loss:0.0034882163360471174\n",
      "train loss:0.005486576073353966\n",
      "train loss:0.0032036687290209116\n",
      "train loss:0.0012710972366744434\n",
      "train loss:0.0048353962891504445\n",
      "train loss:0.003268022518253761\n",
      "train loss:3.831586718285235e-05\n",
      "train loss:0.0015787123596534879\n",
      "train loss:0.0008728766944118763\n",
      "train loss:0.003009539330155628\n",
      "train loss:0.006849016992015919\n",
      "train loss:1.503312511730681e-05\n",
      "train loss:0.0007229154116366946\n",
      "train loss:0.003060082530401694\n",
      "train loss:0.006011259759233323\n",
      "train loss:0.006943219167651692\n",
      "train loss:0.00040833656348758204\n",
      "train loss:0.0007706149653599584\n",
      "train loss:0.0011504865264065087\n",
      "train loss:0.0009119704386430698\n",
      "train loss:0.0018346946916933688\n",
      "train loss:0.0004959362316847049\n",
      "train loss:0.00018480554127795843\n",
      "train loss:0.00180285981960453\n",
      "train loss:0.00025907865901966473\n",
      "train loss:9.268070706928223e-05\n",
      "train loss:0.0027926903019159987\n",
      "train loss:0.00019545292251147583\n",
      "train loss:0.0021985871227284933\n",
      "train loss:0.004442203517990411\n",
      "train loss:0.0002497826947663799\n",
      "train loss:0.002883854831341112\n",
      "train loss:0.00308306785677719\n",
      "train loss:0.0002979415776601692\n",
      "train loss:0.00033291671820730325\n",
      "train loss:0.0007266500398190343\n",
      "train loss:0.00011865974259658727\n",
      "train loss:0.000737019992218989\n",
      "train loss:0.00034620726735076323\n",
      "train loss:0.005326419312973815\n",
      "train loss:0.0005961191059188327\n",
      "train loss:0.00503483193652556\n",
      "train loss:0.0006490116069169204\n",
      "train loss:0.0001091226315166049\n",
      "train loss:0.002600347290317242\n",
      "train loss:0.0015495657160484184\n",
      "train loss:0.003932669738784967\n",
      "train loss:9.56001554140964e-05\n",
      "train loss:0.0016229484507143336\n",
      "train loss:0.0011584906122289696\n",
      "train loss:0.0004639015951184902\n",
      "train loss:0.0020578374165937975\n",
      "train loss:0.0006611887097404429\n",
      "train loss:0.0011330793030460908\n",
      "train loss:0.004025508763294373\n",
      "train loss:0.0022635324849466527\n",
      "train loss:0.0007929047233006664\n",
      "train loss:0.001302181753898084\n",
      "train loss:0.00018059844467779529\n",
      "train loss:0.012809760303054812\n",
      "train loss:7.163471193983243e-05\n",
      "train loss:0.005848130558469039\n",
      "train loss:9.768045082655385e-05\n",
      "train loss:0.0011529712620652543\n",
      "train loss:0.0039876313084095645\n",
      "train loss:0.004527569722141015\n",
      "train loss:0.009259917419403739\n",
      "train loss:0.008353947079523484\n",
      "train loss:0.015151983341275392\n",
      "train loss:0.0009138288454868664\n",
      "train loss:0.00024869500472089637\n",
      "train loss:0.001417361224796024\n",
      "train loss:0.006306086518603982\n",
      "train loss:0.0007155748519093206\n",
      "train loss:0.002427936331006868\n",
      "train loss:0.002284935237514487\n",
      "train loss:0.005287010395961222\n",
      "train loss:0.0033945993545187116\n",
      "train loss:0.0006490608937328287\n",
      "train loss:0.0023564510898640627\n",
      "train loss:0.0014512360449744515\n",
      "train loss:0.003623970139443552\n",
      "train loss:0.002302854520878381\n",
      "train loss:0.0005136752391569647\n",
      "train loss:0.0011472133150644487\n",
      "train loss:0.00032124096247736797\n",
      "train loss:0.000969397324593398\n",
      "train loss:0.0004448039944983531\n",
      "train loss:0.00050157739442964\n",
      "train loss:0.004578048950762108\n",
      "train loss:0.0011922387528331922\n",
      "train loss:0.0007051154455718924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0068007280573989795\n",
      "train loss:0.002391756314312459\n",
      "train loss:0.0021487977967133177\n",
      "train loss:0.004310712536386527\n",
      "train loss:0.0003195888123058287\n",
      "train loss:0.0013123206715096034\n",
      "train loss:0.0014678368706051532\n",
      "train loss:0.0026186447867263206\n",
      "train loss:0.0007074751318339103\n",
      "train loss:0.00024099113077748744\n",
      "train loss:0.0002893104545351825\n",
      "train loss:0.0002470208121316395\n",
      "train loss:0.0013675041153108924\n",
      "train loss:0.0016322058020580622\n",
      "train loss:0.0033970541923055465\n",
      "train loss:0.006005436284487527\n",
      "train loss:0.0011792758047604768\n",
      "train loss:0.0005750705223318103\n",
      "train loss:0.001588797383896563\n",
      "train loss:0.000828107922511855\n",
      "train loss:0.004138790911222664\n",
      "train loss:0.0018531361081091748\n",
      "train loss:0.008324983470272157\n",
      "train loss:0.004728985935332716\n",
      "train loss:0.0008728972827467326\n",
      "=== epoch:19, train acc:1.0, test acc:0.988 ===\n",
      "train loss:0.001948567358335687\n",
      "train loss:0.0016284969989023858\n",
      "train loss:0.0022483234155887748\n",
      "train loss:0.0002750509181723502\n",
      "train loss:6.009245000513639e-05\n",
      "train loss:0.0034454588574638545\n",
      "train loss:0.004437110656497421\n",
      "train loss:0.0008170618898718664\n",
      "train loss:0.002170041686562537\n",
      "train loss:0.001802047693538828\n",
      "train loss:0.0007332863618527077\n",
      "train loss:0.0038198811369866224\n",
      "train loss:0.0008086971299185556\n",
      "train loss:0.0021198866038593827\n",
      "train loss:0.00037470362707896595\n",
      "train loss:0.00013387448453923214\n",
      "train loss:0.0031557856429817494\n",
      "train loss:0.000867486798162393\n",
      "train loss:0.0032717007196740523\n",
      "train loss:0.011220949460859353\n",
      "train loss:0.00013666814758220007\n",
      "train loss:0.0024888784748347127\n",
      "train loss:9.392378083741704e-05\n",
      "train loss:0.0018167823244714968\n",
      "train loss:0.0003450867382052873\n",
      "train loss:0.004263613109837881\n",
      "train loss:0.006299681974264746\n",
      "train loss:0.036440318326824636\n",
      "train loss:0.005274773891614722\n",
      "train loss:0.007067012976704107\n",
      "train loss:4.498096841077898e-05\n",
      "train loss:0.007967902272238678\n",
      "train loss:0.0032360349741831244\n",
      "train loss:0.0009304615353683716\n",
      "train loss:0.017922396814978946\n",
      "train loss:0.0010340285814118826\n",
      "train loss:0.005618813968271789\n",
      "train loss:0.0019245266330262078\n",
      "train loss:4.351008499651973e-05\n",
      "train loss:0.0008484383699843394\n",
      "train loss:0.0030833525792961186\n",
      "train loss:0.0023832074485723455\n",
      "train loss:0.0021667241744173955\n",
      "train loss:0.01258685282987728\n",
      "train loss:0.0010297085244094818\n",
      "train loss:0.0018366384723969584\n",
      "train loss:0.00042764143647145146\n",
      "train loss:0.001423837370087603\n",
      "train loss:0.004911738763059852\n",
      "train loss:0.00012035875195872794\n",
      "train loss:0.00017284831576939007\n",
      "train loss:0.0008602499414491221\n",
      "train loss:9.088850619056498e-05\n",
      "train loss:0.00032111220039283164\n",
      "train loss:0.0009708706442570495\n",
      "train loss:0.004225944366300347\n",
      "train loss:0.002027943981325293\n",
      "train loss:0.003980689712177652\n",
      "train loss:0.0014049343580998267\n",
      "train loss:0.00011227840353601829\n",
      "train loss:0.00016357462430893337\n",
      "train loss:0.002903576114417754\n",
      "train loss:0.0007693720797230812\n",
      "train loss:0.0005157799123155523\n",
      "train loss:0.0010866380059276761\n",
      "train loss:0.0006679779090807761\n",
      "train loss:0.0005819417188714032\n",
      "train loss:0.002016456556469665\n",
      "train loss:0.005688122050724388\n",
      "train loss:0.00015893994020283494\n",
      "train loss:0.0022600506404695836\n",
      "train loss:0.0012752574971196936\n",
      "train loss:0.0008291823281243818\n",
      "train loss:0.00011153136046298212\n",
      "train loss:0.0077766492007868004\n",
      "train loss:0.00284957888073632\n",
      "train loss:0.0006882450708674329\n",
      "train loss:0.002181503703610705\n",
      "train loss:0.002261924925597019\n",
      "train loss:0.0017976255005323\n",
      "train loss:0.00012300658615770147\n",
      "train loss:0.00011203371384721673\n",
      "train loss:0.00018287285825205744\n",
      "train loss:0.0010759926818603553\n",
      "train loss:0.0018440993631394728\n",
      "train loss:0.0022386857513736055\n",
      "train loss:1.7864565740118056e-05\n",
      "train loss:0.0019510309333071044\n",
      "train loss:0.00014194497353189713\n",
      "train loss:0.00010399019065407948\n",
      "train loss:0.000479999511373139\n",
      "train loss:0.0001498383409918174\n",
      "train loss:0.0027096913257788325\n",
      "train loss:0.0006058460448822218\n",
      "train loss:0.00043742044254212295\n",
      "train loss:0.0032109104323699315\n",
      "train loss:0.0024238368690018552\n",
      "train loss:0.0015600945061815012\n",
      "train loss:0.000311886085972533\n",
      "train loss:0.0010087716733681638\n",
      "train loss:0.0016419442554726368\n",
      "train loss:0.0005486198101786589\n",
      "train loss:8.93535304522233e-05\n",
      "train loss:0.00070758614691905\n",
      "train loss:0.0004815383163399803\n",
      "train loss:0.00025743207131801317\n",
      "train loss:0.0009022498817341254\n",
      "train loss:0.0024121128303723287\n",
      "train loss:0.001005173534914088\n",
      "train loss:0.001015429256348747\n",
      "train loss:0.0019286434162928939\n",
      "train loss:0.0006856515094227422\n",
      "train loss:0.0006291806738799584\n",
      "train loss:0.0015501456750234106\n",
      "train loss:0.0019839203265808298\n",
      "train loss:0.003794694289151446\n",
      "train loss:0.00027986664870641555\n",
      "train loss:0.0006643613030758033\n",
      "train loss:0.000419295427493874\n",
      "train loss:0.0002814173544409572\n",
      "train loss:0.00012067973619551158\n",
      "train loss:0.0021756632534631116\n",
      "train loss:0.00031789964209779313\n",
      "train loss:4.550226395095438e-05\n",
      "train loss:0.0006146957483614275\n",
      "train loss:0.0005194057721059314\n",
      "train loss:0.005931460415747238\n",
      "train loss:0.0005837346259520306\n",
      "train loss:0.0024159207862763012\n",
      "train loss:0.0023102813129446576\n",
      "train loss:0.00015746011612192523\n",
      "train loss:0.002227230382549296\n",
      "train loss:8.918361148724627e-05\n",
      "train loss:0.000986227239214307\n",
      "train loss:0.0028389169893675054\n",
      "train loss:0.003189297157431376\n",
      "train loss:0.0005726853569423924\n",
      "train loss:0.0007159228767854314\n",
      "train loss:0.0001503971145708438\n",
      "train loss:0.000852306800469517\n",
      "train loss:0.001221675559014922\n",
      "train loss:0.0006349106127522305\n",
      "train loss:0.0024774899623764184\n",
      "train loss:0.0023673094849532943\n",
      "train loss:0.0005187142279543173\n",
      "train loss:0.00021961821223983664\n",
      "train loss:0.004255956254174287\n",
      "train loss:0.00010922658212134058\n",
      "train loss:0.0007160921459111931\n",
      "train loss:0.0012984740149169396\n",
      "train loss:0.003671375068653183\n",
      "train loss:0.000117239238365144\n",
      "train loss:0.00025322988650063977\n",
      "train loss:0.0019067066291349945\n",
      "train loss:0.007895634562064748\n",
      "train loss:0.00016335561872257855\n",
      "train loss:0.0012952039621043179\n",
      "train loss:0.0025679440008289007\n",
      "train loss:0.0017243659843232135\n",
      "train loss:0.0015392271908723438\n",
      "train loss:0.00023953717795955603\n",
      "train loss:0.0008284324552044252\n",
      "train loss:0.0008611346238757091\n",
      "train loss:0.00013119736085432222\n",
      "train loss:0.000850270905571478\n",
      "train loss:0.001992658286997178\n",
      "train loss:0.002656746820189593\n",
      "train loss:0.0002669152451205109\n",
      "train loss:0.0004628586260037962\n",
      "train loss:0.005724228438307392\n",
      "train loss:0.000111298390094009\n",
      "train loss:0.0002802574319193721\n",
      "train loss:0.0010002365894388602\n",
      "train loss:1.4658660022183886e-05\n",
      "train loss:0.0019906669326895028\n",
      "train loss:0.00036769081638065985\n",
      "train loss:0.003046487103149878\n",
      "train loss:0.001160083816272097\n",
      "train loss:0.005372531462538394\n",
      "train loss:0.0026113386467675652\n",
      "train loss:0.0016436611678275006\n",
      "train loss:0.0007373472659619616\n",
      "train loss:0.002920439838650233\n",
      "train loss:0.0004921122268856971\n",
      "train loss:0.000248901307529268\n",
      "train loss:0.0022328476354558026\n",
      "train loss:0.00018787317030680807\n",
      "train loss:0.003083191013265489\n",
      "train loss:0.000797159279986865\n",
      "train loss:0.0009018343179427471\n",
      "train loss:0.010992603978468489\n",
      "train loss:0.00026131637371953567\n",
      "train loss:0.009313377409298104\n",
      "train loss:1.2444176054261821e-05\n",
      "train loss:0.0004923287922679354\n",
      "train loss:0.00158858343446742\n",
      "train loss:0.003241256927213443\n",
      "train loss:0.0013699157334412012\n",
      "train loss:0.0029808560402868824\n",
      "train loss:0.0006563467138315694\n",
      "train loss:0.0067066929445115005\n",
      "train loss:0.0031638580346498996\n",
      "train loss:0.0009225673107370528\n",
      "train loss:0.001679524825929731\n",
      "train loss:4.671326325371504e-05\n",
      "train loss:0.0004193827647647202\n",
      "train loss:0.000565415916092898\n",
      "train loss:0.0012935191877321392\n",
      "train loss:0.0002630203836338395\n",
      "train loss:0.0007869697901503549\n",
      "train loss:0.0011664847270554874\n",
      "train loss:0.00027363434264640835\n",
      "train loss:0.0014902602919015196\n",
      "train loss:0.0013970586937726254\n",
      "train loss:0.0016378345416585875\n",
      "train loss:0.0005695656468004889\n",
      "train loss:0.0032537522149090493\n",
      "train loss:0.0010515447806908394\n",
      "train loss:0.0006406474368043296\n",
      "train loss:0.0014631993414157426\n",
      "train loss:0.0033145243025637715\n",
      "train loss:0.001898194784024565\n",
      "train loss:0.002406863896668049\n",
      "train loss:0.0016590718193885076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002019200374689128\n",
      "train loss:0.00014060613699448207\n",
      "train loss:0.0006895399417551288\n",
      "train loss:0.0011883639902518538\n",
      "train loss:0.002738325265456843\n",
      "train loss:0.004169350771847173\n",
      "train loss:0.001908048419395388\n",
      "train loss:0.00029166624216220933\n",
      "train loss:0.0014134379521900467\n",
      "train loss:0.0005730637262554751\n",
      "train loss:0.002471907702595562\n",
      "train loss:0.0012366237284599298\n",
      "train loss:8.416442753343527e-05\n",
      "train loss:0.00036603292285569705\n",
      "train loss:0.0024502645130841717\n",
      "train loss:0.0001486076766285597\n",
      "train loss:1.1638254967822801e-05\n",
      "train loss:0.002999320856037535\n",
      "train loss:0.00032816189143468485\n",
      "train loss:0.0017902339160307834\n",
      "train loss:8.305383413321788e-05\n",
      "train loss:0.000938993242114651\n",
      "train loss:0.0060775485435062525\n",
      "train loss:0.0007842320182814678\n",
      "train loss:8.974519586777174e-05\n",
      "train loss:0.00011409506083928245\n",
      "train loss:0.0016917844829416222\n",
      "train loss:0.00015307738973110684\n",
      "train loss:0.0013142589454542108\n",
      "train loss:0.0023254236412378697\n",
      "train loss:0.00042319242290068807\n",
      "train loss:0.0004552082498485252\n",
      "train loss:0.00014885938592216658\n",
      "train loss:0.0007046992135616314\n",
      "train loss:0.0005954487309936391\n",
      "train loss:0.0019894256533151615\n",
      "train loss:0.0003568538923964218\n",
      "train loss:0.0005270920595901991\n",
      "train loss:0.0010484558750749932\n",
      "train loss:0.0008906247879497451\n",
      "train loss:0.00019671646017677786\n",
      "train loss:0.0005736296977532647\n",
      "train loss:0.0010298744912518485\n",
      "train loss:4.129416264441545e-05\n",
      "train loss:0.00012990170132744493\n",
      "train loss:0.0002733867883486182\n",
      "train loss:0.0006811098535773077\n",
      "train loss:0.00010176170090747547\n",
      "train loss:0.0010757210999705433\n",
      "train loss:0.002110915516006284\n",
      "train loss:0.004777321034407559\n",
      "train loss:0.0010500250575618889\n",
      "train loss:0.003583946212923001\n",
      "train loss:0.004372401863686729\n",
      "train loss:0.003237440865967967\n",
      "train loss:9.568058283048917e-05\n",
      "train loss:0.00012438717108020198\n",
      "train loss:0.002864199804889446\n",
      "train loss:0.0009087679987375418\n",
      "train loss:0.0021834119907190998\n",
      "train loss:0.00023507235460624705\n",
      "train loss:0.002457553538548919\n",
      "train loss:5.7965739857793274e-05\n",
      "train loss:0.000106207437477377\n",
      "train loss:0.0017646554911505497\n",
      "train loss:0.00011356877566086238\n",
      "train loss:0.0001224137074363422\n",
      "train loss:0.0015899468110618235\n",
      "train loss:0.00015868946694589064\n",
      "train loss:0.002266225824967597\n",
      "train loss:0.0007435714497943168\n",
      "train loss:0.0012475356388256737\n",
      "train loss:0.0008794272776022543\n",
      "train loss:0.0003055167714907591\n",
      "train loss:0.00035115234675251724\n",
      "train loss:0.0019666751346086534\n",
      "train loss:0.00012539077800988578\n",
      "train loss:0.00018728288162008183\n",
      "train loss:0.0007966960038635439\n",
      "train loss:0.0008796868006210912\n",
      "train loss:0.0023242256129863336\n",
      "train loss:0.0007964819892612202\n",
      "train loss:0.003978054620914138\n",
      "train loss:0.00012141601961300317\n",
      "train loss:0.00821459844004853\n",
      "train loss:0.0009248536298765411\n",
      "train loss:8.11688396368402e-05\n",
      "train loss:0.00012338533172907569\n",
      "train loss:0.004598302729952689\n",
      "train loss:0.00017938921373928534\n",
      "train loss:0.00011834504701833834\n",
      "train loss:0.04827457699058448\n",
      "train loss:0.000170509780583025\n",
      "train loss:0.00024077110872419211\n",
      "train loss:0.00018408589110766298\n",
      "train loss:0.0018707587994178146\n",
      "train loss:0.0006035485753221914\n",
      "train loss:0.0018320611409342123\n",
      "train loss:0.0003328346335659622\n",
      "train loss:0.006917742484893154\n",
      "train loss:0.0006166838912817681\n",
      "train loss:0.0012634949237709775\n",
      "train loss:0.0005546200112998476\n",
      "train loss:0.0026586167205200745\n",
      "train loss:0.0015976943498417929\n",
      "train loss:0.001198695752150022\n",
      "train loss:0.0039227000607590596\n",
      "train loss:0.004096793675542404\n",
      "train loss:0.002464504205138269\n",
      "train loss:0.0020143260381104994\n",
      "train loss:0.00022364378355430397\n",
      "train loss:0.00014618012005774439\n",
      "train loss:0.0008574156509404867\n",
      "train loss:0.003229022314643145\n",
      "train loss:0.003906545473611754\n",
      "train loss:0.0017873741055223031\n",
      "train loss:0.0025941390772882093\n",
      "train loss:0.00022421965823513573\n",
      "train loss:0.006808804297765433\n",
      "train loss:0.0004788338040765312\n",
      "train loss:0.0032363603898861106\n",
      "train loss:0.0005795386413836945\n",
      "train loss:0.0032352516559867378\n",
      "train loss:0.0023994927502385926\n",
      "train loss:0.0036564630004358835\n",
      "train loss:0.0023484428406990014\n",
      "train loss:0.00010499885489318143\n",
      "train loss:0.00018209958433000977\n",
      "train loss:0.0017774555382837234\n",
      "train loss:0.0012640156398207123\n",
      "train loss:0.0020307636867331856\n",
      "train loss:0.000272614895252803\n",
      "train loss:6.456604747828665e-05\n",
      "train loss:0.0007630047260738427\n",
      "train loss:1.748885749223682e-05\n",
      "train loss:0.0042292912180305195\n",
      "train loss:0.0006404148897375305\n",
      "train loss:0.0017965775467358885\n",
      "train loss:3.883504339725888e-05\n",
      "train loss:0.001142293157580621\n",
      "train loss:0.003125365052237445\n",
      "train loss:0.002397052053761296\n",
      "train loss:0.00012237334843766756\n",
      "train loss:0.0021374174542884484\n",
      "train loss:0.0002811622840413577\n",
      "train loss:0.0013760780712239475\n",
      "train loss:0.00021861128793343972\n",
      "train loss:8.251335264182763e-05\n",
      "train loss:0.0002257902340449576\n",
      "train loss:0.0014741679072388092\n",
      "train loss:8.656646717651516e-05\n",
      "train loss:0.000945692029277041\n",
      "train loss:0.002848830266920664\n",
      "train loss:0.0004955062040194995\n",
      "train loss:0.00471452279181828\n",
      "train loss:0.0005441329390643948\n",
      "train loss:0.00014982334952343647\n",
      "train loss:9.162187201035177e-05\n",
      "train loss:0.0011303312298277545\n",
      "train loss:4.797218285438638e-05\n",
      "train loss:0.0006390655483928999\n",
      "train loss:0.0005562819849516459\n",
      "train loss:0.0008003638398449728\n",
      "train loss:7.036806440760455e-05\n",
      "train loss:0.0003821025124664011\n",
      "train loss:0.002309774757321416\n",
      "train loss:0.000493286338238871\n",
      "train loss:0.0012764752623230346\n",
      "train loss:0.005990038862081871\n",
      "train loss:0.0037252025001567736\n",
      "train loss:9.701920663624342e-05\n",
      "train loss:0.00013785786315593238\n",
      "train loss:0.0006116122236038014\n",
      "train loss:0.0013048154954543626\n",
      "train loss:0.0007470916223355505\n",
      "train loss:0.0005190895971186663\n",
      "train loss:0.0027336161151562694\n",
      "train loss:2.6343933000056752e-05\n",
      "train loss:0.0010123045091672575\n",
      "train loss:0.00046187047125638593\n",
      "train loss:0.0011114703237595413\n",
      "train loss:0.005382253128882138\n",
      "train loss:0.00102083202155326\n",
      "train loss:7.96502413434456e-05\n",
      "train loss:0.0002665339618046391\n",
      "train loss:0.00018306278995049635\n",
      "train loss:0.0009602845483996532\n",
      "train loss:0.0006512102739817445\n",
      "train loss:0.0004822170208075054\n",
      "train loss:0.00014399576763225288\n",
      "train loss:0.00030104838664217986\n",
      "train loss:0.0015354060420518707\n",
      "train loss:0.0019294559330796596\n",
      "train loss:0.00021480937736540745\n",
      "train loss:0.0017650461550488285\n",
      "train loss:0.001094660500198814\n",
      "train loss:0.0009352835900558777\n",
      "train loss:0.00041734297943008024\n",
      "train loss:0.0007414532777953026\n",
      "train loss:0.001436328610244747\n",
      "train loss:0.0017258162031922103\n",
      "train loss:9.73239790953262e-05\n",
      "train loss:8.998171319983874e-05\n",
      "train loss:0.0004918227952789841\n",
      "train loss:0.00020126517596209215\n",
      "train loss:2.685311078288846e-05\n",
      "train loss:0.00027433118853492763\n",
      "train loss:0.00015348645016294166\n",
      "train loss:0.0006557708715838416\n",
      "train loss:0.0004962097589072636\n",
      "train loss:0.0012754815268960942\n",
      "train loss:5.3733096929852086e-05\n",
      "train loss:0.002683761234358993\n",
      "train loss:5.879074110112238e-05\n",
      "train loss:0.00019348091485514048\n",
      "train loss:0.0012357283610390172\n",
      "train loss:6.661754270830663e-05\n",
      "train loss:0.0007690653644924214\n",
      "train loss:0.0016707272362798842\n",
      "train loss:0.0013007131975395\n",
      "train loss:0.0003667083904177346\n",
      "train loss:0.0006709362579012346\n",
      "train loss:0.0013727097310286302\n",
      "train loss:0.0006425306547839421\n",
      "train loss:0.00028093916768470885\n",
      "train loss:0.00012172721531136065\n",
      "train loss:0.03842344041814777\n",
      "train loss:0.00019823332406083434\n",
      "train loss:0.0004281916821482731\n",
      "train loss:2.9460764705350836e-05\n",
      "train loss:0.00012971860344576874\n",
      "train loss:0.0032080130498833297\n",
      "train loss:0.0016960013686666642\n",
      "train loss:0.0003138177675213347\n",
      "train loss:0.002083798654305045\n",
      "train loss:0.001855987511121389\n",
      "train loss:0.00043595652350345937\n",
      "train loss:0.0004808402730750182\n",
      "train loss:0.0003423318635411672\n",
      "train loss:0.00014854066147630563\n",
      "train loss:0.0018769161654590492\n",
      "train loss:0.009067774984986897\n",
      "train loss:0.03507119176744473\n",
      "train loss:0.0006542995765702112\n",
      "train loss:0.0009513239281662223\n",
      "train loss:0.0005331002214509355\n",
      "train loss:0.0011690404946625372\n",
      "train loss:0.003254109340816507\n",
      "train loss:0.008723976716434968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00379655097929028\n",
      "train loss:0.0014736035774069805\n",
      "train loss:0.011825091130597438\n",
      "train loss:0.005562545137688751\n",
      "train loss:0.0006354411426090452\n",
      "train loss:0.00180044051265528\n",
      "train loss:0.00797752429900126\n",
      "train loss:8.80757782625653e-05\n",
      "train loss:0.0012474066828096423\n",
      "train loss:0.0006809250666167882\n",
      "train loss:0.0007530292665600857\n",
      "train loss:0.0021932852802317676\n",
      "train loss:0.0005585167080119398\n",
      "train loss:0.002137633145248294\n",
      "train loss:0.0063921644097279205\n",
      "train loss:0.0020379237006829527\n",
      "train loss:0.006283621932609563\n",
      "train loss:0.004690908193766309\n",
      "train loss:0.002848567354168098\n",
      "train loss:0.0006924513941656967\n",
      "train loss:0.0021814760697646046\n",
      "train loss:0.002878050546578527\n",
      "train loss:0.0010118351716347004\n",
      "train loss:0.0006528781910459642\n",
      "train loss:0.0009761490357747231\n",
      "train loss:0.0013206523392126444\n",
      "train loss:0.0015153757160641416\n",
      "train loss:0.0012079177797103791\n",
      "train loss:0.0015417351084108352\n",
      "train loss:0.009656536400768318\n",
      "train loss:0.002035398829327394\n",
      "train loss:0.01059834171647599\n",
      "train loss:0.009313658343135241\n",
      "train loss:0.0029997310491298584\n",
      "train loss:0.0011233560762276577\n",
      "train loss:0.0018473951941228297\n",
      "train loss:0.0006406621077919783\n",
      "train loss:0.0015448052001815716\n",
      "train loss:4.4141932181068274e-05\n",
      "train loss:0.0016417358740389535\n",
      "train loss:0.00031558453446868843\n",
      "train loss:0.0012277474639945248\n",
      "train loss:0.0024466461181124467\n",
      "train loss:0.0026170997032782827\n",
      "train loss:0.001961276208661737\n",
      "train loss:0.0030012707169879025\n",
      "train loss:0.004537703644013808\n",
      "train loss:0.0009114407081205199\n",
      "train loss:0.0020226260628796746\n",
      "train loss:0.00022940030714515734\n",
      "train loss:0.00044323823822243265\n",
      "train loss:0.002332876948329326\n",
      "train loss:0.0009706240356541947\n",
      "train loss:0.0003310290079548611\n",
      "train loss:0.00037133022913439734\n",
      "train loss:0.0028436129757924366\n",
      "train loss:0.0032026319852426575\n",
      "train loss:0.00748188878353044\n",
      "train loss:0.0010673340363513248\n",
      "train loss:0.001300790174753236\n",
      "train loss:0.0016603048759266305\n",
      "train loss:0.0021479341072047037\n",
      "train loss:8.907603835448463e-05\n",
      "train loss:0.009807927090487672\n",
      "train loss:0.0019692176491400153\n",
      "train loss:0.00027499099662872656\n",
      "train loss:0.004505874692936785\n",
      "train loss:0.023781349582311054\n",
      "train loss:0.0008311209603425765\n",
      "train loss:0.0006869809338163143\n",
      "train loss:0.00051499125131986\n",
      "train loss:0.0032076004442938154\n",
      "train loss:4.247509024264814e-05\n",
      "train loss:0.0013904081520917278\n",
      "train loss:0.0005711438325278953\n",
      "train loss:0.002111181643825639\n",
      "train loss:0.0022461821634232773\n",
      "train loss:0.0011406526070226839\n",
      "train loss:0.00036503860156010705\n",
      "train loss:0.0016622785467436264\n",
      "train loss:0.0008142440980736486\n",
      "train loss:0.0006269704815502684\n",
      "train loss:0.007127146187848547\n",
      "train loss:0.03119439380921521\n",
      "train loss:0.003001473895332449\n",
      "train loss:0.00026643217501776643\n",
      "train loss:0.0017508960908891574\n",
      "train loss:0.00023882481728724206\n",
      "train loss:0.000520171468621015\n",
      "train loss:0.00011664747016272705\n",
      "train loss:0.0033569543381841765\n",
      "train loss:0.00043792007914572926\n",
      "train loss:0.0019255577233823395\n",
      "train loss:0.001814637711547906\n",
      "train loss:0.003931916721116746\n",
      "train loss:0.001382514092886091\n",
      "train loss:0.0020196096177781658\n",
      "train loss:0.005201628793349665\n",
      "train loss:0.002754168953464428\n",
      "train loss:0.002156012222292458\n",
      "train loss:0.0016155703973434112\n",
      "train loss:0.0014366471652262913\n",
      "train loss:0.0006446099352193828\n",
      "train loss:0.00138355959527814\n",
      "train loss:0.002345558780553281\n",
      "train loss:0.0032079549707187114\n",
      "train loss:0.0005582137708259173\n",
      "train loss:0.0016162333357165107\n",
      "train loss:0.0022881969804815334\n",
      "train loss:4.68663551743055e-05\n",
      "train loss:0.007974044791834542\n",
      "train loss:0.006701170303506461\n",
      "train loss:0.0003555639526042594\n",
      "train loss:0.0032997728584812295\n",
      "train loss:0.0026869089139693915\n",
      "train loss:0.0003714046577030922\n",
      "train loss:0.0008428808475480686\n",
      "train loss:0.0020034635945637854\n",
      "train loss:0.00017246468648295655\n",
      "train loss:0.0007762445030134622\n",
      "train loss:0.0014245374136118995\n",
      "train loss:0.004343434617164946\n",
      "train loss:0.0013234635734859562\n",
      "train loss:0.001181875216110744\n",
      "train loss:0.0014849106376712711\n",
      "train loss:0.0007714149543446558\n",
      "train loss:0.0009641809489834117\n",
      "=== epoch:20, train acc:0.995, test acc:0.983 ===\n",
      "train loss:0.0180803853698761\n",
      "train loss:0.0015656709716006375\n",
      "train loss:0.025369424822841595\n",
      "train loss:0.0009380708431521471\n",
      "train loss:0.0006338470256357958\n",
      "train loss:0.001133702565260681\n",
      "train loss:4.731440225744292e-05\n",
      "train loss:0.0008016439327663515\n",
      "train loss:0.00021026323615847602\n",
      "train loss:0.00033700272877555746\n",
      "train loss:0.0005638263878902696\n",
      "train loss:0.0015457120423694032\n",
      "train loss:0.005123157808163501\n",
      "train loss:0.003977738152969125\n",
      "train loss:0.0003894280210484418\n",
      "train loss:0.00047621134476577944\n",
      "train loss:0.0023899865880897715\n",
      "train loss:0.02235099364143814\n",
      "train loss:0.00041073339924742406\n",
      "train loss:0.001125919532401696\n",
      "train loss:0.002781085969050793\n",
      "train loss:0.001205490537425186\n",
      "train loss:0.0003337154170041258\n",
      "train loss:0.03150084700409881\n",
      "train loss:0.0016921403332383353\n",
      "train loss:2.086697846272868e-05\n",
      "train loss:0.003084933781523731\n",
      "train loss:0.0017077722053098286\n",
      "train loss:0.005152222667617552\n",
      "train loss:0.0022221907078643502\n",
      "train loss:0.001533248626922142\n",
      "train loss:0.003987015063425653\n",
      "train loss:0.004295464008768297\n",
      "train loss:0.0012405007830002066\n",
      "train loss:0.002404547405437189\n",
      "train loss:0.006399253886665113\n",
      "train loss:0.001419780311441077\n",
      "train loss:0.0009208877007529301\n",
      "train loss:3.0477244084586886e-05\n",
      "train loss:0.0001966167853422761\n",
      "train loss:0.0014131705723494812\n",
      "train loss:0.011326654293550249\n",
      "train loss:0.023615513078239406\n",
      "train loss:0.0007926827837087338\n",
      "train loss:0.0035586057683867508\n",
      "train loss:0.000486971208272382\n",
      "train loss:0.00224405907751683\n",
      "train loss:0.0010298913388736715\n",
      "train loss:0.003615752943112519\n",
      "train loss:0.0017644952927501842\n",
      "train loss:0.01667337512213612\n",
      "train loss:0.0004837509197805241\n",
      "train loss:0.00039499581382786635\n",
      "train loss:4.219200489446372e-05\n",
      "train loss:6.967197093076891e-05\n",
      "train loss:0.0007189324451206522\n",
      "train loss:0.0004166870734611731\n",
      "train loss:0.0027843766876622838\n",
      "train loss:0.004105067095949238\n",
      "train loss:0.002925300642247408\n",
      "train loss:0.002781184812812505\n",
      "train loss:0.0013377091028306406\n",
      "train loss:0.010824491657878124\n",
      "train loss:0.0007561762174509906\n",
      "train loss:0.004176813752823844\n",
      "train loss:0.0032720134717437637\n",
      "train loss:0.0004899272712531361\n",
      "train loss:0.004149826225910485\n",
      "train loss:0.00040631712846755236\n",
      "train loss:0.0020145978552704837\n",
      "train loss:0.000525329246924782\n",
      "train loss:0.0044134267991487895\n",
      "train loss:2.8136137131445044e-05\n",
      "train loss:0.001101768824287923\n",
      "train loss:0.008859540909413575\n",
      "train loss:0.002329112881145662\n",
      "train loss:0.0013879412722014003\n",
      "train loss:0.0036001146824664004\n",
      "train loss:0.0027578840943621487\n",
      "train loss:0.007154723960203364\n",
      "train loss:0.002735912019558195\n",
      "train loss:0.00032387946751516813\n",
      "train loss:0.002547051688976117\n",
      "train loss:0.0047964641925030025\n",
      "train loss:9.020426268075886e-05\n",
      "train loss:0.0014214001060530138\n",
      "train loss:9.46129886287514e-05\n",
      "train loss:0.0001687853748557275\n",
      "train loss:0.007300043366672151\n",
      "train loss:0.001961716263693544\n",
      "train loss:7.699043821840214e-05\n",
      "train loss:0.0002339592444509763\n",
      "train loss:0.006122972042041705\n",
      "train loss:4.831908065697321e-05\n",
      "train loss:0.0002856369673407993\n",
      "train loss:0.0009349094202497653\n",
      "train loss:0.0011932061038742489\n",
      "train loss:0.002318604085082261\n",
      "train loss:1.6651175168907866e-05\n",
      "train loss:0.00037345977435294914\n",
      "train loss:0.00014807761186547188\n",
      "train loss:0.0021192064923402695\n",
      "train loss:0.0007173179560164074\n",
      "train loss:0.0026966097612737506\n",
      "train loss:0.0019241617742462756\n",
      "train loss:0.00023552603574962655\n",
      "train loss:0.0004028602105763566\n",
      "train loss:4.473791089029886e-05\n",
      "train loss:0.0038780320163419577\n",
      "train loss:0.0038000772892071697\n",
      "train loss:0.00045695370655857306\n",
      "train loss:0.00011463203080799024\n",
      "train loss:0.0013626299220926375\n",
      "train loss:0.0036728158505467067\n",
      "train loss:0.0014876326276877915\n",
      "train loss:0.0019376397308850518\n",
      "train loss:0.00022653012831888293\n",
      "train loss:0.0005141641192038362\n",
      "train loss:0.0017322331073909983\n",
      "train loss:0.001993426703846057\n",
      "train loss:0.0019636164852283714\n",
      "train loss:0.00037419615269573223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000576634585159166\n",
      "train loss:0.0023584800317578316\n",
      "train loss:0.00018926227302110886\n",
      "train loss:0.00030908405999851294\n",
      "train loss:0.0008064657740968388\n",
      "train loss:0.0013480506640042868\n",
      "train loss:0.0033235493215643948\n",
      "train loss:0.0015734716295670004\n",
      "train loss:0.001655997633983011\n",
      "train loss:0.006644333981794351\n",
      "train loss:0.00046685978041534587\n",
      "train loss:0.0025873751923110415\n",
      "train loss:0.001430674231600075\n",
      "train loss:0.000270875524865046\n",
      "train loss:0.001071896377727422\n",
      "train loss:0.00015170440277268698\n",
      "train loss:0.0024322759417964718\n",
      "train loss:0.00019604907057362814\n",
      "train loss:0.001105699937827589\n",
      "train loss:0.00034060970759989206\n",
      "train loss:0.003966899078636239\n",
      "train loss:0.00040640949911436463\n",
      "train loss:0.00797416064945667\n",
      "train loss:0.0035261048628606505\n",
      "train loss:0.00023915723491490043\n",
      "train loss:0.00010975989356199144\n",
      "train loss:0.0005939829645184694\n",
      "train loss:0.002171207180924999\n",
      "train loss:7.112186644168935e-05\n",
      "train loss:0.004280134839293921\n",
      "train loss:0.0051325167489144514\n",
      "train loss:0.00094344390069947\n",
      "train loss:0.0016422002347814596\n",
      "train loss:0.0012802713911034148\n",
      "train loss:0.001479592263827218\n",
      "train loss:0.001510358152880868\n",
      "train loss:0.0013092215330747813\n",
      "train loss:0.0006426995186658319\n",
      "train loss:0.0010575196104409155\n",
      "train loss:0.00020900237505559177\n",
      "train loss:0.002535535475585661\n",
      "train loss:0.0008413185505371819\n",
      "train loss:0.009071107739054696\n",
      "train loss:0.0006593640336731387\n",
      "train loss:0.022484028259236163\n",
      "train loss:0.004478806325197282\n",
      "train loss:0.0004916234054582935\n",
      "train loss:0.0005425335727432268\n",
      "train loss:0.00265572640527255\n",
      "train loss:0.007411829179223475\n",
      "train loss:0.00020587688514888961\n",
      "train loss:0.0015648436894914542\n",
      "train loss:0.008597480724199377\n",
      "train loss:0.00042319450562005396\n",
      "train loss:0.000292915867875417\n",
      "train loss:0.00017237711309497146\n",
      "train loss:0.0016961654740077668\n",
      "train loss:0.00044579989906027754\n",
      "train loss:0.0012872205941809052\n",
      "train loss:9.517065278072651e-05\n",
      "train loss:0.000639268376030265\n",
      "train loss:0.0018405635379018822\n",
      "train loss:0.000869005230171259\n",
      "train loss:0.0005792470800336896\n",
      "train loss:0.001185019893149771\n",
      "train loss:0.0009644811631802235\n",
      "train loss:0.001747945394318236\n",
      "train loss:0.0006137312560379286\n",
      "train loss:0.00011746342140368228\n",
      "train loss:0.0004077451733701881\n",
      "train loss:0.00010366837923115655\n",
      "train loss:0.001466551242733197\n",
      "train loss:0.00031842721173987897\n",
      "train loss:0.00047823286503290456\n",
      "train loss:0.0003087378708134512\n",
      "train loss:0.0010282588379178007\n",
      "train loss:0.0002865451996922747\n",
      "train loss:0.002255082935507237\n",
      "train loss:0.0007817072850235339\n",
      "train loss:0.01493433779450138\n",
      "train loss:0.0004502067208763434\n",
      "train loss:0.00021330479516867777\n",
      "train loss:0.0033197531802034805\n",
      "train loss:0.0016722760347476031\n",
      "train loss:0.02056306459845276\n",
      "train loss:0.001714537402955008\n",
      "train loss:0.0011896327635855062\n",
      "train loss:6.910414420445267e-05\n",
      "train loss:0.002341762694546183\n",
      "train loss:0.01605241298118232\n",
      "train loss:0.00013132666597150117\n",
      "train loss:0.001344624141341045\n",
      "train loss:0.0012509741783372893\n",
      "train loss:0.0015461862362281312\n",
      "train loss:0.0018891242547114653\n",
      "train loss:0.0018807082466394997\n",
      "train loss:0.0002883998493171851\n",
      "train loss:0.001103854746220129\n",
      "train loss:0.004084610825824513\n",
      "train loss:0.0017706134851766414\n",
      "train loss:0.001306015939356155\n",
      "train loss:0.0009002962664498204\n",
      "train loss:0.002981210016517626\n",
      "train loss:0.015898761077631968\n",
      "train loss:3.819676662566814e-05\n",
      "train loss:0.00012614044927789498\n",
      "train loss:0.0014224097753443566\n",
      "train loss:0.0012792526893696196\n",
      "train loss:0.00137463221596212\n",
      "train loss:0.0027812247385901896\n",
      "train loss:0.002610217718727229\n",
      "train loss:0.001834415581129461\n",
      "train loss:0.0010524840195301791\n",
      "train loss:0.0003608259296813347\n",
      "train loss:0.0028216756804147207\n",
      "train loss:0.014673117161161415\n",
      "train loss:0.01850628892593703\n",
      "train loss:0.0035002066775017384\n",
      "train loss:0.00011965910290536511\n",
      "train loss:0.0013999817546679982\n",
      "train loss:0.003346813498965056\n",
      "train loss:0.0059917020036158305\n",
      "train loss:0.0006545663095240897\n",
      "train loss:0.0026806293318860502\n",
      "train loss:0.003435512928576874\n",
      "train loss:0.0001450975493659658\n",
      "train loss:0.002088179063896403\n",
      "train loss:0.0004785382087459229\n",
      "train loss:0.0007762319249388089\n",
      "train loss:0.0002500887962118875\n",
      "train loss:0.0011348602321948598\n",
      "train loss:0.0007866122009073626\n",
      "train loss:0.002497604653350994\n",
      "train loss:0.0005510858045524625\n",
      "train loss:0.002001532182610998\n",
      "train loss:0.001531095317806753\n",
      "train loss:0.0010891498290567358\n",
      "train loss:0.00020347013018176736\n",
      "train loss:0.0075131530702053405\n",
      "train loss:0.00039216807131459976\n",
      "train loss:0.00034569853095968195\n",
      "train loss:0.0015457788502176472\n",
      "train loss:0.0007130851283144227\n",
      "train loss:0.0016099955143482347\n",
      "train loss:0.003014421602009375\n",
      "train loss:0.003564337824461532\n",
      "train loss:0.001198070157728438\n",
      "train loss:0.00027972033090997256\n",
      "train loss:0.01580293397991578\n",
      "train loss:0.0004922664644493488\n",
      "train loss:0.0028755346476405765\n",
      "train loss:0.00016676397062009363\n",
      "train loss:0.0005980812356594518\n",
      "train loss:0.0021702351745509093\n",
      "train loss:0.001216424557725617\n",
      "train loss:0.0006716243826535052\n",
      "train loss:0.00015902729189144809\n",
      "train loss:0.006502426307939553\n",
      "train loss:0.002440628815148222\n",
      "train loss:0.06034068373709976\n",
      "train loss:0.004517931388304993\n",
      "train loss:0.0018087759570563963\n",
      "train loss:0.0023841749218286397\n",
      "train loss:0.00013966743048441626\n",
      "train loss:4.061713367106847e-05\n",
      "train loss:0.028834058323811123\n",
      "train loss:0.0016236483490237636\n",
      "train loss:0.00023227109529497735\n",
      "train loss:0.00014890480963085584\n",
      "train loss:0.00020029840486381474\n",
      "train loss:0.0003381217269059844\n",
      "train loss:0.00010688927770280102\n",
      "train loss:0.0007836339204477298\n",
      "train loss:7.988319449231172e-05\n",
      "train loss:0.0010903844981475133\n",
      "train loss:0.0009467432805752336\n",
      "train loss:0.0016788297587431457\n",
      "train loss:0.00016120653988931015\n",
      "train loss:0.0019587709142633238\n",
      "train loss:0.002948072076597243\n",
      "train loss:0.0010050114387436396\n",
      "train loss:0.0006226083587708926\n",
      "train loss:0.0004903474134014298\n",
      "train loss:0.00016130607206820641\n",
      "train loss:0.0015667723794275507\n",
      "train loss:0.003711051208002193\n",
      "train loss:0.0033186022660707006\n",
      "train loss:0.00019540796916799787\n",
      "train loss:0.00013616234034475238\n",
      "train loss:0.0038169613230484957\n",
      "train loss:7.860783382624218e-05\n",
      "train loss:7.370181620298795e-05\n",
      "train loss:0.000696587164836062\n",
      "train loss:0.00011079770701586442\n",
      "train loss:0.005363645880687376\n",
      "train loss:0.001742624802034084\n",
      "train loss:0.00037242618764744335\n",
      "train loss:0.0007641624776537035\n",
      "train loss:0.020295209205285873\n",
      "train loss:0.0003547155818894354\n",
      "train loss:0.0019497762644473252\n",
      "train loss:0.005371879605883066\n",
      "train loss:7.949987869680199e-05\n",
      "train loss:4.048494664450338e-05\n",
      "train loss:0.0003209562273415614\n",
      "train loss:0.0018846340340953024\n",
      "train loss:6.885347393430645e-05\n",
      "train loss:0.00043386761029636184\n",
      "train loss:0.0004209088224154276\n",
      "train loss:0.0002720460318703744\n",
      "train loss:0.0015997064139671004\n",
      "train loss:0.0037420712673524436\n",
      "train loss:0.00044220869699904234\n",
      "train loss:8.204058170571143e-05\n",
      "train loss:0.001100864524495579\n",
      "train loss:0.0005940355774361384\n",
      "train loss:0.004163189734404245\n",
      "train loss:0.003635810562801676\n",
      "train loss:0.002170776117878375\n",
      "train loss:0.009708167621160894\n",
      "train loss:0.003446441498448341\n",
      "train loss:0.0021071341624235955\n",
      "train loss:0.0026627826589757614\n",
      "train loss:0.0004277561828112881\n",
      "train loss:7.926895323907341e-05\n",
      "train loss:0.0004097413319515134\n",
      "train loss:0.0025123562343584414\n",
      "train loss:0.002411161263977269\n",
      "train loss:0.0026697057445769505\n",
      "train loss:0.0001477725353414725\n",
      "train loss:0.003768713704845215\n",
      "train loss:0.0033064900153809483\n",
      "train loss:0.00011079181089638753\n",
      "train loss:0.0001605631847452383\n",
      "train loss:0.0004621491087462462\n",
      "train loss:0.0042511492044715864\n",
      "train loss:0.0010729143361767695\n",
      "train loss:0.00785046512443438\n",
      "train loss:0.00017072326457498295\n",
      "train loss:0.004230530573095507\n",
      "train loss:0.00020878316467952816\n",
      "train loss:0.0009448245898988652\n",
      "train loss:0.0009345191706732853\n",
      "train loss:0.0020452444764946175\n",
      "train loss:0.0009106950544410004\n",
      "train loss:0.0001492781581689383\n",
      "train loss:0.0010053722357580943\n",
      "train loss:0.003694897360282247\n",
      "train loss:0.0034839650568092373\n",
      "train loss:0.00543548218932921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006617512602103483\n",
      "train loss:0.0001906216512515285\n",
      "train loss:0.0040707568485565645\n",
      "train loss:0.00043551194107279627\n",
      "train loss:0.021097876697720272\n",
      "train loss:0.0005925268820223464\n",
      "train loss:0.0015531095425083054\n",
      "train loss:0.0008560858051055259\n",
      "train loss:0.010147851551549745\n",
      "train loss:0.0036228530118338907\n",
      "train loss:0.00035033998706453283\n",
      "train loss:0.000994343773788946\n",
      "train loss:0.000202693936077695\n",
      "train loss:0.0009911654740654004\n",
      "train loss:5.8753833240161654e-05\n",
      "train loss:0.001971730448244394\n",
      "train loss:0.0008994299724421839\n",
      "train loss:0.001435814347797923\n",
      "train loss:7.694217801953326e-05\n",
      "train loss:0.0005659636422891902\n",
      "train loss:0.01636602255232674\n",
      "train loss:0.00036168322476729203\n",
      "train loss:0.0006048186117971999\n",
      "train loss:0.0030021690666338706\n",
      "train loss:0.00294307367553745\n",
      "train loss:0.00010356135392284006\n",
      "train loss:0.0005256700753164086\n",
      "train loss:0.00026634165127787176\n",
      "train loss:0.0004573663755002806\n",
      "train loss:0.00037534931289048585\n",
      "train loss:0.0014490402847229314\n",
      "train loss:0.0001410838375212389\n",
      "train loss:0.002297886017361946\n",
      "train loss:0.0012748300442238661\n",
      "train loss:0.0008791320004532464\n",
      "train loss:0.0040012893929419445\n",
      "train loss:0.00024396740076602105\n",
      "train loss:0.0005289170918427767\n",
      "train loss:0.0003594409046058876\n",
      "train loss:8.65657863650191e-05\n",
      "train loss:0.0059723014796047025\n",
      "train loss:0.00110878830401828\n",
      "train loss:0.0005882309285333434\n",
      "train loss:0.0009428203578842409\n",
      "train loss:0.0002430633636868198\n",
      "train loss:0.000820831559947383\n",
      "train loss:0.0012552020163029865\n",
      "train loss:0.004606118355080619\n",
      "train loss:0.00018494933092939815\n",
      "train loss:0.0017207097812977886\n",
      "train loss:0.0004629522169235987\n",
      "train loss:0.0008502499367017196\n",
      "train loss:0.0014077962637340494\n",
      "train loss:0.0012445428601574615\n",
      "train loss:0.0006235835049294133\n",
      "train loss:0.0011487417057479486\n",
      "train loss:0.0017662860399300278\n",
      "train loss:0.0003957396681234354\n",
      "train loss:0.00013038882642823083\n",
      "train loss:0.00013752923087338755\n",
      "train loss:0.0004435574794586964\n",
      "train loss:0.0006255195282977385\n",
      "train loss:0.0014604874479977443\n",
      "train loss:0.0009553508768006576\n",
      "train loss:0.03631292167324336\n",
      "train loss:9.969482553767133e-05\n",
      "train loss:0.0006164638211836402\n",
      "train loss:0.0023207614082009064\n",
      "train loss:0.000540029843183944\n",
      "train loss:0.0001737148959585929\n",
      "train loss:0.00017195414232559024\n",
      "train loss:0.002302519424121331\n",
      "train loss:0.0007635514001361483\n",
      "train loss:0.0011189490254489523\n",
      "train loss:0.002306995217365935\n",
      "train loss:0.001890019694534644\n",
      "train loss:0.00034654103507438764\n",
      "train loss:0.0024957389848643593\n",
      "train loss:0.0010848925033936565\n",
      "train loss:0.003974692120975659\n",
      "train loss:0.00026632756881762474\n",
      "train loss:5.718406242028547e-05\n",
      "train loss:0.0009609406873532909\n",
      "train loss:0.001687439965628474\n",
      "train loss:0.0005258976323421492\n",
      "train loss:0.0011015720282024873\n",
      "train loss:0.001202945616332719\n",
      "train loss:0.00013380164739078244\n",
      "train loss:0.003636155857172292\n",
      "train loss:0.0022857829030413133\n",
      "train loss:0.00041341501600276756\n",
      "train loss:0.010444648530457684\n",
      "train loss:0.0013179928177222348\n",
      "train loss:0.00042166614744724794\n",
      "train loss:0.0007682216101638238\n",
      "train loss:0.005062771150740633\n",
      "train loss:5.1753931152040514e-05\n",
      "train loss:0.00346823841515154\n",
      "train loss:0.001301518112299423\n",
      "train loss:0.0018135307937473893\n",
      "train loss:0.00011805771960924418\n",
      "train loss:0.002009790322758345\n",
      "train loss:0.00023774437074654115\n",
      "train loss:0.00655839594938801\n",
      "train loss:0.0015501018831564656\n",
      "train loss:0.0004507568605804077\n",
      "train loss:0.0004375704432526847\n",
      "train loss:0.0007742095282001497\n",
      "train loss:0.0037523185141375578\n",
      "train loss:0.0015783965961961635\n",
      "train loss:0.0012994507275483496\n",
      "train loss:0.00019155165819587338\n",
      "train loss:0.0009626808075929037\n",
      "train loss:0.0028998944774512258\n",
      "train loss:5.5113237504311166e-05\n",
      "train loss:0.004716672070339994\n",
      "train loss:0.0008803291376571327\n",
      "train loss:0.0013590483352929124\n",
      "train loss:0.0004403936870606657\n",
      "train loss:0.0006149640032814821\n",
      "train loss:0.0009824166575647048\n",
      "train loss:0.0032273550312899614\n",
      "train loss:9.01256975364527e-05\n",
      "train loss:0.00017337662228333954\n",
      "train loss:0.0011396341921090806\n",
      "train loss:0.0027389000095605844\n",
      "train loss:0.001071587591620897\n",
      "train loss:0.0010977556318001655\n",
      "train loss:0.00018297910593032064\n",
      "train loss:0.00036703712406439376\n",
      "train loss:7.558023973977975e-05\n",
      "train loss:0.001428054177139318\n",
      "train loss:0.0009354723458590032\n",
      "train loss:0.0023083500621228817\n",
      "train loss:0.0038576006201725853\n",
      "train loss:0.0011241881103866073\n",
      "train loss:0.01819072651850898\n",
      "train loss:0.0007071543775148288\n",
      "train loss:0.008932244497656207\n",
      "train loss:4.769310321306969e-05\n",
      "train loss:0.0005651267975882897\n",
      "train loss:0.0008828017633575836\n",
      "train loss:0.0008760685135503086\n",
      "train loss:0.00040833346104079233\n",
      "train loss:0.0009802153112508064\n",
      "train loss:0.01570056608552242\n",
      "train loss:0.001542304281605738\n",
      "train loss:0.0009534193754941401\n",
      "train loss:0.0002954200863921156\n",
      "train loss:0.012182276305393664\n",
      "train loss:0.00034853817237065563\n",
      "train loss:6.457285309472413e-05\n",
      "train loss:8.374308782628813e-05\n",
      "train loss:0.004825477822186016\n",
      "train loss:0.0009466244285768208\n",
      "train loss:0.002311974408660773\n",
      "train loss:0.0001157876555270549\n",
      "train loss:4.512934306903375e-05\n",
      "train loss:0.0006789859035675355\n",
      "train loss:2.4962153917859763e-05\n",
      "train loss:0.0012897696622095544\n",
      "train loss:0.0016948446345943244\n",
      "train loss:0.00021915768658684477\n",
      "train loss:0.00034152586141869155\n",
      "train loss:0.0004695726333503739\n",
      "train loss:0.0021433446585254344\n",
      "train loss:0.00034374166190333656\n",
      "train loss:0.002090229161367152\n",
      "train loss:0.0004915154738061154\n",
      "train loss:0.0029357450863990216\n",
      "train loss:0.0004210472614585909\n",
      "train loss:0.0005973614397151616\n",
      "train loss:0.0003938321236650933\n",
      "train loss:8.100336975076524e-05\n",
      "train loss:5.603812033960663e-05\n",
      "train loss:0.0005060711105881893\n",
      "train loss:0.0003489193005634463\n",
      "train loss:0.005958445845572493\n",
      "train loss:0.0017111851756275703\n",
      "train loss:0.0001126347446279555\n",
      "train loss:0.0005987532344149146\n",
      "train loss:0.003350649622252197\n",
      "train loss:0.00019670028086680796\n",
      "train loss:8.445699966152197e-06\n",
      "train loss:0.0002947002101280589\n",
      "train loss:0.0012734030554195767\n",
      "train loss:0.06058852961675228\n",
      "train loss:0.0020006778579868753\n",
      "train loss:4.148598538485337e-05\n",
      "train loss:0.000685268838244887\n",
      "train loss:0.0002945354681667927\n",
      "train loss:0.0013283838822960117\n",
      "train loss:0.0004382092928041739\n",
      "train loss:0.00048739353102799553\n",
      "train loss:0.0010599197948012032\n",
      "train loss:0.002115830464884175\n",
      "train loss:0.0005882599313517312\n",
      "train loss:4.9170022300513173e-05\n",
      "train loss:5.4842433869380454e-05\n",
      "train loss:0.00041281708699786714\n",
      "train loss:0.00039171162886665785\n",
      "train loss:0.0010330047167523568\n",
      "train loss:0.0002051356571531862\n",
      "train loss:9.573604512584399e-05\n",
      "train loss:0.00015447638196113537\n",
      "train loss:0.00016295513001195964\n",
      "train loss:0.00013200304291198422\n",
      "train loss:0.0003475689331395388\n",
      "train loss:0.002766991243821824\n",
      "train loss:0.00013986985488379064\n",
      "train loss:1.9556574806491427e-05\n",
      "train loss:0.0003246587457920707\n",
      "train loss:0.000510422650529845\n",
      "train loss:0.0003882126109632841\n",
      "train loss:0.0004405490687429469\n",
      "train loss:0.00047709363014912374\n",
      "train loss:0.0018931281862821898\n",
      "train loss:0.0016847352720037747\n",
      "train loss:0.0003589127070036232\n",
      "train loss:0.0019346651837409898\n",
      "train loss:0.003469231623897684\n",
      "train loss:0.0027819379754862833\n",
      "train loss:0.00042348239424278564\n",
      "train loss:9.559231739272079e-05\n",
      "train loss:0.0011169760540782195\n",
      "train loss:0.0002360986783921939\n",
      "train loss:0.00012484311168582096\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.99\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09675f7",
   "metadata": {},
   "source": [
    "# CNNの可視化\n",
    "畳み込み層を可視化することによってCNNが内部で何を行っているのかを観察する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d909da13",
   "metadata": {},
   "source": [
    "## 1層目の重みの可視化\n",
    "先ほど行ったMNISTデータセットに対する学習では、フィルターはサイズが5×5でチャンネルは1のものが30個だった。つまり、30枚の5×5画素のグレースケール画像へと可視化できる。これを可視化すると次のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af2af72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学習後の重み\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c3c18",
   "metadata": {},
   "source": [
    "学習前のフィルターはランダムに初期化されているため規則性は見受けられないが、学習後には規則性が見受けられる。学習済みの畳み込み層のフィルターは、エッジやブロブ（塊）などのプリミティブな情報を抽出する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b852c58",
   "metadata": {},
   "source": [
    "## 階層構造による情報抽出\n",
    "CNNでは、層が深くなるにつれて、抽出される情報はより抽象化されていくという研究結果が示されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3fc0d",
   "metadata": {},
   "source": [
    "# 代表的なCNN\n",
    "代表的なCNNとして、1998年に初めて提案されたCNNの元祖、LeNetと、ディープラーニングの火付け役である2012年のAlexNetを紹介する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d292dd",
   "metadata": {},
   "source": [
    "## LeNet\n",
    "LeNetと現在のCNNには、いくつかの違いがある。ひとつめの違いは、活性化関数にある。LeNetではSigmoidが使用されているのに対し、現在では主にReLUが使用されている。また、オリジナルのLeNetではサブサンプリングによって中間データのサイズ縮小を行っているが、現在ではMaxプーリングによるものが主流である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59468eb0",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "AlexNetのLeNetとの違いは、活性化関数がReLUであること、LRN（Local Response Normalization）という局所的正規化を行う層を用いていること、Dropoutを用いていることにある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b562b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
